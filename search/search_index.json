{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#roboflow-python-package","title":"Roboflow Python Package","text":"<p>Roboflow provides everything you need to build and deploy computer vision models. <code>roboflow-python</code> is the official Roboflow Python package. <code>roboflow-python</code> enables you to interact with models, datasets, and projects hosted on Roboflow.</p> <p>With this Python package, you can:</p> <ol> <li>Create and manage projects;</li> <li>Upload images, annotations, and datasets to manage in Roboflow;</li> <li>Start training vision models on Roboflow;</li> <li>Run inference on models hosted on Roboflow, or Roboflow models self-hosted via Roboflow Inference, and more.</li> </ol> <p>The Python package is documented on the official Roboflow documentation site. If you are developing a feature for this Python package, or need a full Python library reference, refer to the package developer documentation.</p>"},{"location":"#installation","title":"\ud83d\udcbb Installation","text":"<p>You will need to have <code>Python 3.6</code> or higher set up to use the Roboflow Python package.</p> <p>Run the following command to install the Roboflow Python package:</p> <pre><code>pip install roboflow\n</code></pre> Install from source    You can also install the Roboflow Python package from source using the following commands:    <pre><code>git clone https://github.com/roboflow-ai/roboflow-python.git\ncd roboflow-python\npython3 -m venv env\nsource env/bin/activate\npip3 install -r requirements.txt\n</code></pre>"},{"location":"#getting-started","title":"\ud83d\ude80 Getting Started","text":"<p>To use the Roboflow Python package, you first need to authenticate with your Roboflow account. You can do this by running the following command:</p> <pre><code>import roboflow\nroboflow.login()\n</code></pre> Authenticate with an API key  You can also authenticate with an API key by using the following code:  <pre><code>import roboflow\n\nrf = roboflow.Roboflow(api_key=\"\")\n</code></pre>  [Learn how to retrieve your Roboflow API key](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key)."},{"location":"#quickstart","title":"Quickstart","text":"<p>Below are some common methods used with the Roboflow Python package, presented concisely for reference. For a full library reference, refer to the Roboflow API reference documentation.</p> <pre><code>import roboflow\n\nroboflow.login()\n\nrf = roboflow.Roboflow()\n\n# create a project\nrf.create_project(\n    project_name=\"project name\",\n    project_type=\"project-type\",\n    license=\"project-license\" # \"private\" for private projects\n)\n\nworkspace = rf.workspace(\"WORKSPACE_URL\")\nproject = workspace.project(\"PROJECT_URL\")\nversion = project.version(\"VERSION_NUMBER\")\n\n# upload a dataset\nproject.upload_dataset(\n    dataset_path=\"./dataset/\",\n    num_workers=10,\n    dataset_format=\"yolov8\", # supports yolov8, yolov5, and Pascal VOC\n    project_license=\"MIT\",\n    project_type=\"object-detection\"\n)\n\n# upload model weights\nversion.deploy(model_type=\"yolov8\", model_path=f\u201d{HOME}/runs/detect/train/\u201d)\n\n# run inference\nmodel = version.model\n\nimg_url = \"https://media.roboflow.com/quickstart/aerial_drone.jpeg\"\n\npredictions = model.predict(img_url, hosted=True).json()\n\nprint(predictions)\n</code></pre>"},{"location":"#library-structure","title":"Library Structure","text":"<p>The Roboflow Python library is structured using the same Workspace, Project, and Version ontology that you will see in the Roboflow application.</p> <pre><code>import roboflow\n\nroboflow.login()\n\nrf = roboflow.Roboflow()\n\nworkspace = rf.workspace(\"WORKSPACE_URL\")\nproject = workspace.project(\"PROJECT_URL\")\nversion = project.version(\"VERSION_NUMBER\")\n</code></pre> <p>The workspace, project, and version parameters are the same that you will find in the URL addresses at app.roboflow.com and universe.roboflow.com.</p> <p>Within the workspace object you can perform actions like making a new project, listing your projects, or performing active learning where you are using predictions from one project's model to upload images to a new project.</p> <p>Within the project object, you can retrieve metadata about the project, list versions, generate a new dataset version with preprocessing and augmentation settings, train a model in your project, and upload images and annotations to your project.</p> <p>Within the version object, you can download the dataset version in any model format, train the version on Roboflow, and deploy your own external model to Roboflow.</p>"},{"location":"#contributing","title":"\ud83c\udfc6 Contributing","text":"<p>We would love your input on how we can improve the Roboflow Python package! Please see our contributing guide to get started. Thank you \ud83d\ude4f to all our contributors!</p> <p></p>"},{"location":"core/dataset/","title":"Datasets","text":""},{"location":"core/dataset/#roboflow.core.dataset.Dataset","title":"<code>Dataset</code>","text":"<p>A Roboflow Dataset.</p> Source code in <code>roboflow/core/dataset.py</code> <pre><code>class Dataset:\n\"\"\"\n    A Roboflow Dataset.\n    \"\"\"\n\n    def __init__(self, name, version, model_format, location):\n        self.name = name\n        self.version = version\n        self.model_format = model_format\n        self.location = location\n</code></pre>"},{"location":"core/model/","title":"Models","text":""},{"location":"core/model/#roboflow.core.model.Model","title":"<code>Model</code>","text":"<p>A Roboflow model.</p> Source code in <code>roboflow/core/model.py</code> <pre><code>class Model:\n\"\"\"\n    A Roboflow model.\n    \"\"\"\n\n    def __init__(self, model):\n        self.id = model[\"id\"]\n        self.endpoint = model[\"endpoint\"]\n        self.duration = model[\"end\"] - model[\"start\"]\n        self.statistics = {\n            \"recall\": model[\"recall\"],\n            \"precision\": model[\"precision\"],\n            \"map\": model[\"map\"],\n        }\n</code></pre>"},{"location":"core/project/","title":"Projects","text":""},{"location":"core/project/#roboflow.core.project.Project","title":"<code>Project</code>","text":"<p>A Roboflow Project.</p> Source code in <code>roboflow/core/project.py</code> <pre><code>class Project:\n\"\"\"\n    A Roboflow Project.\n    \"\"\"\n\n    def __init__(self, api_key: str, a_project: str, model_format: str = None):\n\"\"\"\n        Create a Project object that represents a Project associated with a Workspace.\n\n        Args:\n            api_key (str): private roboflow api key\n            a_project (str): the project id\n            model_format (str): the model format of the project\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n        \"\"\"\n        if api_key in DEMO_KEYS:\n            self.__api_key = api_key\n            self.model_format = model_format\n        else:\n            self.__api_key = api_key\n            self.annotation = a_project[\"annotation\"]\n            self.classes = a_project[\"classes\"]\n            self.colors = a_project[\"colors\"]\n            self.created = datetime.datetime.fromtimestamp(a_project[\"created\"])\n            self.id = a_project[\"id\"]\n            self.images = a_project[\"images\"]\n            self.name = a_project[\"name\"]\n            self.public = a_project[\"public\"]\n            self.splits = a_project[\"splits\"]\n            self.type = a_project[\"type\"]\n            self.unannotated = a_project[\"unannotated\"]\n            self.updated = datetime.datetime.fromtimestamp(a_project[\"updated\"])\n            self.model_format = model_format\n\n            temp = self.id.rsplit(\"/\")\n            self.__workspace = temp[0]\n            self.__project_name = temp[1]\n\n    def get_version_information(self):\n\"\"\"\n        Retrieve all versions of a project.\n\n        Returns:\n            A list of all versions of the project.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; version_info = project.get_version_information()\n        \"\"\"\n        dataset_info = requests.get(\n            API_URL\n            + \"/\"\n            + self.__workspace\n            + \"/\"\n            + self.__project_name\n            + \"?api_key=\"\n            + self.__api_key\n        )\n\n        # Throw error if dataset isn't valid/user doesn't have permissions to access the dataset\n        if dataset_info.status_code != 200:\n            raise RuntimeError(dataset_info.text)\n\n        dataset_info = dataset_info.json()\n        return dataset_info[\"versions\"]\n\n    def list_versions(self):\n\"\"\"\n        Print out versions for that specific project.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; project.list_versions()\n        \"\"\"\n        version_info = self.get_version_information()\n        print(version_info)\n\n    def versions(self):\n\"\"\"\n        Return all versions in the project as Version objects.\n\n        Returns:\n            A list of Version objects.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; versions = project.versions()\n        \"\"\"\n        version_info = self.get_version_information()\n        version_array = []\n        for a_version in version_info:\n            version_object = Version(\n                a_version,\n                (self.type if \"model\" in a_version else None),\n                self.__api_key,\n                self.name,\n                a_version[\"id\"],\n                self.model_format,\n                local=None,\n                workspace=self.__workspace,\n                project=self.__project_name,\n                public=self.public,\n                colors=self.colors,\n            )\n            version_array.append(version_object)\n        return version_array\n\n    def generate_version(self, settings):\n\"\"\"\n        Generate a version of a dataset hosted on Roboflow.\n\n        Args:\n            settings: A Python dict with augmentation and preprocessing keys and specifications for generation. These settings mirror capabilities available via the Roboflow UI.\n                    For example:\n                        {\n                            \"augmentation\": {\n                                \"bbblur\": { \"pixels\": 1.5 },\n                                \"bbbrightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },\n                                \"bbcrop\": { \"min\": 12, \"max\": 71 },\n                                \"bbexposure\": { \"percent\": 30 },\n                                \"bbflip\": { \"horizontal\": true, \"vertical\": false },\n                                \"bbnoise\": { \"percent\": 50 },\n                                \"bbninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },\n                                \"bbrotate\": { \"degrees\": 45 },\n                                \"bbshear\": { \"horizontal\": 45, \"vertical\": 45 },\n                                \"blur\": { \"pixels\": 1.5 },\n                                \"brightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },\n                                \"crop\": { \"min\": 12, \"max\": 71 },\n                                \"cutout\": { \"count\": 26, \"percent\": 71 },\n                                \"exposure\": { \"percent\": 30 },\n                                \"flip\": { \"horizontal\": true, \"vertical\": false },\n                                \"hue\": { \"degrees\": 180 },\n                                \"image\": { \"versions\": 32 },\n                                \"mosaic\": true,\n                                \"ninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },\n                                \"noise\": { \"percent\": 50 },\n                                \"rgrayscale\": { \"percent\": 50 },\n                                \"rotate\": { \"degrees\": 45 },\n                                \"saturation\": { \"percent\": 50 },\n                                \"shear\": { \"horizontal\": 45, \"vertical\": 45 }\n                            },\n                            \"preprocessing\": {\n                                \"auto-orient\": true,\n                                \"contrast\": { \"type\": \"Contrast Stretching\" },\n                                \"filter-null\": { \"percent\": 50 },\n                                \"grayscale\": true,\n                                \"isolate\": true,\n                                \"remap\": { \"original_class_name\": \"new_class_name\" },\n                                \"resize\": { \"width\": 200, \"height\": 200, \"format\": \"Stretch to\" },\n                                \"static-crop\": { \"x_min\": 10, \"x_max\": 90, \"y_min\": 10, \"y_max\": 90 },\n                                \"tile\": { \"rows\": 2, \"columns\": 2 }\n                            }\n                        }\n\n        Returns:\n            int: The version number that is being generated.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; versions = project.generate_version(settings={...})\n        \"\"\"\n\n        if not {\"augmentation\", \"preprocessing\"} &lt;= settings.keys():\n            raise (\n                RuntimeError(\n                    \"augmentation and preprocessing keys are required to generate. If none are desired specify empty dict associated with that key.\"\n                )\n            )\n\n        r = requests.post(\n            f\"{API_URL}/{self.__workspace}/{self.__project_name}/generate?api_key={self.__api_key}\",\n            json=settings,\n        )\n\n        try:\n            r_json = r.json()\n        except:\n            raise (\"Error when requesting to generate a new version for project.\")\n\n        # if the generation succeeds, return the version that is being generated\n        if r.status_code == 200:\n            sys.stdout.write(\n                \"\\r\"\n                + r_json[\"message\"]\n                + \" for new version \"\n                + str(r_json[\"version\"])\n                + \".\"\n            )\n            sys.stdout.write(\"\\n\")\n            sys.stdout.flush()\n            return int(r_json[\"version\"])\n        else:\n            if \"error\" in r_json.keys():\n                raise RuntimeError(r_json[\"error\"])\n            else:\n                raise RuntimeError(json.dumps(r_json))\n\n    def train(\n        self,\n        new_version_settings={\n            \"preprocessing\": {\n                \"auto-orient\": True,\n                \"resize\": {\"width\": 640, \"height\": 640, \"format\": \"Stretch to\"},\n            },\n            \"augmentation\": {},\n        },\n        speed=None,\n        checkpoint=None,\n        plot_in_notebook=False,\n    ) -&gt; bool:\n\"\"\"\n        Ask the Roboflow API to train a previously exported version's dataset.\n\n        Args:\n            speed: Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is `fast`.\n            checkpoint: A string representing the checkpoint to use while training\n            plot: Whether to plot the training loss curve. Default is False.\n\n        Returns:\n            True\n\n        Raises:\n            RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n            HTTPError: If the Network/Roboflow API fails and does not return JSON\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; version = project.version(1)\n\n            &gt;&gt;&gt; version.train()\n        \"\"\"\n\n        new_version = self.generate_version(settings=new_version_settings)\n        new_version = self.version(new_version)\n        new_model = new_version.train(\n            speed=speed, checkpoint=checkpoint, plot_in_notebook=plot_in_notebook\n        )\n\n        return new_model\n\n    def version(self, version_number: int, local: str = None):\n\"\"\"\n        Retrieves information about a specific version and returns a Version() object.\n\n        Args:\n            version_number (int): the version number that you want to retrieve\n            local (str): specifies the localhost address and port if pointing towards local inference engine\n\n        Returns:\n            Version() object\n        \"\"\"\n\n        if self.__api_key in DEMO_KEYS:\n            name = \"\"\n            if self.__api_key == \"coco-128-sample\":\n                name = \"coco-128\"\n            else:\n                name = \"chess-pieces-new\"\n            return Version(\n                {},\n                \"type\",\n                self.__api_key,\n                name,\n                version_number,\n                self.model_format,\n                local=None,\n                workspace=\"\",\n                project=\"\",\n            )\n\n        version_info = self.get_version_information()\n\n        for version_object in version_info:\n            current_version_num = os.path.basename(version_object[\"id\"])\n            if current_version_num == str(version_number):\n                vers = Version(\n                    version_object,\n                    self.type,\n                    self.__api_key,\n                    self.name,\n                    current_version_num,\n                    self.model_format,\n                    local=local,\n                    workspace=self.__workspace,\n                    project=self.__project_name,\n                    public=self.public,\n                    colors=self.colors,\n                )\n                return vers\n\n        raise RuntimeError(\"Version number {} is not found.\".format(version_number))\n\n    def __image_upload(\n        self,\n        image_path: str,\n        hosted_image: bool = False,\n        split: str = \"train\",\n        batch_name: str = DEFAULT_BATCH_NAME,\n        tag_names: list = [],\n        **kwargs,\n    ):\n\"\"\"\n        Upload an image to a specific project.\n\n        Args:\n            image_path (str): path to image you'd like to upload\n            hosted_image (bool): whether the image is hosted on Roboflow\n            split (str): the dataset split the image to\n        \"\"\"\n\n        # If image is not a hosted image\n        if not hosted_image:\n            batch_name = (\n                batch_name\n                if batch_name and isinstance(batch_name, str)\n                else DEFAULT_BATCH_NAME\n            )\n\n            project_name = self.id.rsplit(\"/\")[1]\n            image_name = os.path.basename(image_path)\n\n            # Construct URL for local image upload\n            self.image_upload_url = \"\".join(\n                [\n                    API_URL + \"/dataset/\",\n                    project_name,\n                    \"/upload\",\n                    \"?api_key=\",\n                    self.__api_key,\n                    \"&amp;batch=\",\n                    batch_name,\n                ]\n            )\n            for key, value in kwargs.items():\n                self.image_upload_url += \"&amp;\" + str(key) + \"=\" + str(value)\n\n            for tag in tag_names:\n                self.image_upload_url = self.image_upload_url + f\"&amp;tag={tag}\"\n\n            # Convert to PIL Image\n            img = cv2.imread(image_path)\n            image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            pilImage = Image.fromarray(image)\n\n            # Convert to JPEG Buffer\n            buffered = io.BytesIO()\n            pilImage.save(buffered, quality=100, format=\"JPEG\")\n\n            # Build multipart form and post request\n            m = MultipartEncoder(\n                fields={\n                    \"name\": image_name,\n                    \"split\": split,\n                    \"file\": (\"imageToUpload\", buffered.getvalue(), \"image/jpeg\"),\n                }\n            )\n            response = requests.post(\n                self.image_upload_url, data=m, headers={\"Content-Type\": m.content_type}\n            )\n\n        else:\n            # Hosted image upload url\n            project_name = self.id.rsplit(\"/\")[1]\n\n            upload_url = \"\".join(\n                [\n                    API_URL + \"/dataset/\" + self.project_name + \"/upload\",\n                    \"?api_key=\" + self.__api_key,\n                    \"&amp;name=\" + os.path.basename(image_path),\n                    \"&amp;split=\" + split,\n                    \"&amp;image=\" + urllib.parse.quote_plus(image_path),\n                ]\n            )\n            # Get response\n            response = requests.post(upload_url)\n        responsejson = None\n        try:\n            responsejson = response.json()\n        except:\n            pass\n        if response.status_code == 200:\n            if responsejson:\n                if \"duplicate\" in responsejson.keys():\n                    print(f\"Duplicate image not uploaded: {image_path}\")\n                elif not responsejson.get(\"success\"):\n                    raise UploadError(f\"Server rejected image: {responsejson}\")\n                return responsejson.get(\"id\")\n            else:\n                warnings.warn(\n                    f\"upload image {image_path} 200 OK, weird response: {response}\"\n                )\n                return None\n        else:\n            if responsejson:\n                raise UploadError(\n                    f\"Bad response: {response.status_code}: {responsejson}\"\n                )\n            else:\n                raise UploadError(f\"Bad response: {response}\")\n\n    def __annotation_upload(\n        self, annotation_path: str, image_id: str, is_prediction: bool = False\n    ):\n\"\"\"\n        Upload an annotation to a specific project.\n\n        Args:\n            annotation_path (str): path to annotation you'd like to upload\n            image_id (str): image id you'd like to upload that has annotations for it.\n        \"\"\"\n\n        # stop on empty string\n        if len(annotation_path) == 0:\n            print(\"Please provide a non-empty string for annotation_path.\")\n            return {\"result\": \"Please provide a non-empty string for annotation_path.\"}\n\n        # check if annotation file exists\n        elif os.path.exists(annotation_path):\n            # print(\"-&gt; found given annotation file\")\n            annotation_string = open(annotation_path, \"r\").read()\n\n        # if not annotation file, check if user wants to upload regular as classification annotation\n        elif self.type == \"classification\":\n            print(f\"-&gt; using {annotation_path} as classname for classification project\")\n            annotation_string = annotation_path\n\n        # don't attempt upload otherwise\n        else:\n            print(\n                \"File not found or uploading to non-classification type project with invalid string\"\n            )\n            return {\n                \"result\": \"File not found or uploading to non-classification type project with invalid string\"\n            }\n\n        self.annotation_upload_url = \"\".join(\n            [\n                API_URL + \"/dataset/\",\n                self.__project_name,\n                \"/annotate/\",\n                image_id,\n                \"?api_key=\",\n                self.__api_key,\n                \"&amp;name=\" + os.path.basename(annotation_path),\n                \"&amp;prediction=true\" if is_prediction else \"\",\n            ]\n        )\n\n        response = requests.post(\n            self.annotation_upload_url,\n            data=annotation_string,\n            headers={\"Content-Type\": \"text/plain\"},\n        )\n        responsejson = None\n        try:\n            responsejson = response.json()\n        except:\n            pass\n        if response.status_code == 200:\n            if responsejson:\n                if responsejson.get(\"error\"):\n                    raise UploadError(\n                        f\"Failed to save annotation for {image_id}: {responsejson['error']}\"\n                    )\n                elif not responsejson.get(\"success\"):\n                    raise UploadError(\n                        f\"Failed to save annotation for {image_id}: {responsejson}\"\n                    )\n            else:\n                warnings.warn(\n                    f\"save annotation {annotation_path} 200 OK, weird response: {response}\"\n                )\n        elif response.status_code == 409 and \"already annotated\" in (\n            responsejson or {}\n        ).get(\"error\", {}).get(\"message\"):\n            print(f\"image already annotated: {annotation_path}\")\n        else:\n            if responsejson:\n                if responsejson.get(\"error\"):\n                    raise UploadError(\n                        f\"save annotation for {image_id} / bad response: {response.status_code}: {responsejson['error']}\"\n                    )\n                else:\n                    raise UploadError(\n                        f\"save annotation for {image_id} / bad response: {response.status_code}: {responsejson}\"\n                    )\n            else:\n                raise UploadError(\n                    f\"save annotation for {image_id} bad response: {response}\"\n                )\n\n    def check_valid_image(self, image_path: str):\n\"\"\"\n        Check if an image is valid. Useful before attempting to upload an image to Roboflow.\n\n        Args:\n            image_path (str): path to image you'd like to check\n\n        Returns:\n            bool: whether the image is valid or not\n        \"\"\"\n        try:\n            img = Image.open(image_path)\n            valid = img.format in ACCEPTED_IMAGE_FORMATS\n            img.close()\n        except UnidentifiedImageError:\n            return False\n\n        return valid\n\n    def upload(\n        self,\n        image_path: str = None,\n        annotation_path: str = None,\n        hosted_image: bool = False,\n        image_id: str = None,\n        split: str = \"train\",\n        num_retry_uploads: int = 0,\n        batch_name: str = DEFAULT_BATCH_NAME,\n        tag_names: list = [],\n        is_prediction: bool = False,\n        **kwargs,\n    ):\n\"\"\"\n        Upload an image or annotation to the Roboflow API.\n\n        Args:\n            image_path (str): path to image you'd like to upload\n            annotation_path (str): if you're upload annotation, path to it\n            hosted_image (bool): whether the image is hosted\n            image_id (str): id of the image\n            split (str): to upload the image to\n            num_retry_uploads (int): how many times to retry upload on failure\n            batch_name (str): name of batch to upload to within project\n            tag_names (list[str]): tags to be applied to an image\n            is_prediction (bool): whether the annotation data is a prediction rather than ground truth\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; project.upload(image_path=\"YOUR_IMAGE.jpg\")\n        \"\"\"\n\n        is_hosted = image_path.startswith(\"http://\") or image_path.startswith(\n            \"https://\"\n        )\n\n        is_file = os.path.isfile(image_path) or is_hosted\n        is_dir = os.path.isdir(image_path)\n\n        if not is_file and not is_dir:\n            raise RuntimeError(\n                \"The provided image path [ {} ] is not a valid path. Please provide a path to an image or a directory.\".format(\n                    image_path\n                )\n            )\n\n        if is_file:\n            is_image = self.check_valid_image(image_path) or is_hosted\n\n            if not is_image:\n                raise RuntimeError(\n                    \"The image you provided {} is not a supported file format. We currently support: {}.\".format(\n                        image_path, \", \".join(ACCEPTED_IMAGE_FORMATS)\n                    )\n                )\n\n            self.single_upload(\n                image_path=image_path,\n                annotation_path=annotation_path,\n                hosted_image=hosted_image,\n                image_id=image_id,\n                split=split,\n                num_retry_uploads=num_retry_uploads,\n                batch_name=batch_name,\n                tag_names=tag_names,\n                is_prediction=is_prediction,\n                **kwargs,\n            )\n\n        else:\n            images = os.listdir(image_path)\n            for image in images:\n                path = image_path + \"/\" + image\n                if self.check_valid_image(image):\n                    self.single_upload(\n                        image_path=path,\n                        annotation_path=annotation_path,\n                        hosted_image=hosted_image,\n                        image_id=image_id,\n                        split=split,\n                        num_retry_uploads=num_retry_uploads,\n                        batch_name=batch_name,\n                        tag_names=tag_names,\n                        is_prediction=is_prediction,\n                        **kwargs,\n                    )\n                    print(\"[ \" + path + \" ] was uploaded succesfully.\")\n                else:\n                    print(\"[ \" + path + \" ] was skipped.\")\n                    continue\n\n    def single_upload(\n        self,\n        image_path=None,\n        annotation_path=None,\n        hosted_image=False,\n        image_id=None,\n        split=\"train\",\n        num_retry_uploads=0,\n        batch_name=DEFAULT_BATCH_NAME,\n        tag_names=[],\n        is_prediction: bool = False,\n        **kwargs,\n    ):\n        success = False\n        annotation_success = False\n        if image_path is not None:\n            try:\n                image_id = retry(\n                    num_retry_uploads,\n                    Exception,\n                    self.__image_upload,\n                    image_path,\n                    hosted_image=hosted_image,\n                    split=split,\n                    batch_name=batch_name,\n                    tag_names=tag_names,\n                    **kwargs,\n                )\n                success = True\n            except BaseException as e:\n                print(\n                    f\"{image_path} ERROR uploading image after {num_retry_uploads} retries: {e}\",\n                    file=sys.stderr,\n                )\n                return\n\n        # Upload only annotations to image based on image Id (no image)\n        if annotation_path is not None and image_id is not None and success:\n            # Get annotation upload response\n            try:\n                self.__annotation_upload(\n                    annotation_path, image_id, is_prediction=is_prediction\n                )\n                annotation_success = True\n            except BaseException as e:\n                print(\n                    f\"{annotation_path} ERROR saving annotation: {e}\", file=sys.stderr\n                )\n                return False\n            # Give user warning that annotation failed to upload\n            if not annotation_success:\n                warnings.warn(\n                    \"Annotation, \"\n                    + annotation_path\n                    + \"failed to upload!\\n Upload correct annotation file to image_id: \"\n                    + image_id\n                )\n        else:\n            annotation_success = True\n\n        overall_success = success and annotation_success\n        return overall_success\n\n    def search(\n        self,\n        like_image: str = None,\n        prompt: str = None,\n        offset: int = 0,\n        limit: int = 100,\n        tag: str = None,\n        class_name: str = None,\n        in_dataset: str = None,\n        batch: bool = False,\n        batch_id: str = None,\n        fields: list = [\"id\", \"created\", \"name\", \"labels\"],\n    ):\n\"\"\"\n        Search for images in a project.\n\n        Args:\n            like_image (str): name of an image in your dataset to use if you want to find images similar to that one\n            prompt (str): search prompt\n            offset (int): offset of results\n            limit (int): limit of results\n            tag (str): tag that an image must have\n            class_name (str): class name that an image must have\n            in_dataset (str): dataset that an image must be in\n            batch (bool): whether the image must be in a batch\n            batch_id (str): batch id that an image must be in\n            fields (list): fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])\n\n        Returns:\n            A list of images that match the search criteria.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; results = project.search(query=\"cat\", limit=10)\n        \"\"\"\n        payload = {}\n\n        if like_image is not None:\n            payload[\"like_image\"] = like_image\n\n        if prompt is not None:\n            payload[\"prompt\"] = prompt\n\n        if offset is not None:\n            payload[\"offset\"] = offset\n\n        if limit is not None:\n            payload[\"limit\"] = limit\n\n        if tag is not None:\n            payload[\"tag\"] = tag\n\n        if class_name is not None:\n            payload[\"class_name\"] = class_name\n\n        if in_dataset is not None:\n            payload[\"in_dataset\"] = in_dataset\n\n        if batch is not None:\n            payload[\"batch\"] = batch\n\n        if batch_id is not None:\n            payload[\"batch_id\"] = batch_id\n\n        payload[\"fields\"] = fields\n\n        data = requests.post(\n            API_URL\n            + \"/\"\n            + self.__workspace\n            + \"/\"\n            + self.__project_name\n            + \"/search?api_key=\"\n            + self.__api_key,\n            json=payload,\n        )\n\n        return data.json()[\"results\"]\n\n    def search_all(\n        self,\n        like_image: str = None,\n        prompt: str = None,\n        offset: int = 0,\n        limit: int = 100,\n        tag: str = None,\n        class_name: str = None,\n        in_dataset: str = None,\n        batch: bool = False,\n        batch_id: str = None,\n        fields: list = [\"id\", \"created\"],\n    ):\n\"\"\"\n        Create a paginated list of search results for use in searching the images in a project.\n\n        Args:\n            like_image (str): name of an image in your dataset to use if you want to find images similar to that one\n            prompt (str): search prompt\n            offset (int): offset of results\n            limit (int): limit of results\n            tag (str): tag that an image must have\n            class_name (str): class name that an image must have\n            in_dataset (str): dataset that an image must be in\n            batch (bool): whether the image must be in a batch\n            batch_id (str): batch id that an image must be in\n            fields (list): fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])\n\n        Returns:\n            A list of images that match the search criteria.\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; results = project.search_all(query=\"cat\", limit=10)\n\n            &gt;&gt;&gt; for result in results:\n\n            &gt;&gt;&gt;     print(result)\n        \"\"\"\n        while True:\n            data = self.search(\n                like_image=like_image,\n                prompt=prompt,\n                offset=offset,\n                limit=limit,\n                tag=tag,\n                class_name=class_name,\n                in_dataset=in_dataset,\n                batch=batch,\n                batch_id=batch_id,\n                fields=fields,\n            )\n\n            yield data\n\n            if len(data) &lt; limit:\n                break\n\n            offset += limit\n\n    def __str__(self):\n\"\"\"\n        Show a string representation of a Project object.\n        \"\"\"\n        # String representation of project\n        json_str = {\"name\": self.name, \"type\": self.type, \"workspace\": self.__workspace}\n\n        return json.dumps(json_str, indent=2)\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.__annotation_upload","title":"<code>__annotation_upload(annotation_path, image_id, is_prediction=False)</code>","text":"<p>Upload an annotation to a specific project.</p> <p>Parameters:</p> Name Type Description Default <code>annotation_path</code> <code>str</code> <p>path to annotation you'd like to upload</p> required <code>image_id</code> <code>str</code> <p>image id you'd like to upload that has annotations for it.</p> required Source code in <code>roboflow/core/project.py</code> <pre><code>def __annotation_upload(\n    self, annotation_path: str, image_id: str, is_prediction: bool = False\n):\n\"\"\"\n    Upload an annotation to a specific project.\n\n    Args:\n        annotation_path (str): path to annotation you'd like to upload\n        image_id (str): image id you'd like to upload that has annotations for it.\n    \"\"\"\n\n    # stop on empty string\n    if len(annotation_path) == 0:\n        print(\"Please provide a non-empty string for annotation_path.\")\n        return {\"result\": \"Please provide a non-empty string for annotation_path.\"}\n\n    # check if annotation file exists\n    elif os.path.exists(annotation_path):\n        # print(\"-&gt; found given annotation file\")\n        annotation_string = open(annotation_path, \"r\").read()\n\n    # if not annotation file, check if user wants to upload regular as classification annotation\n    elif self.type == \"classification\":\n        print(f\"-&gt; using {annotation_path} as classname for classification project\")\n        annotation_string = annotation_path\n\n    # don't attempt upload otherwise\n    else:\n        print(\n            \"File not found or uploading to non-classification type project with invalid string\"\n        )\n        return {\n            \"result\": \"File not found or uploading to non-classification type project with invalid string\"\n        }\n\n    self.annotation_upload_url = \"\".join(\n        [\n            API_URL + \"/dataset/\",\n            self.__project_name,\n            \"/annotate/\",\n            image_id,\n            \"?api_key=\",\n            self.__api_key,\n            \"&amp;name=\" + os.path.basename(annotation_path),\n            \"&amp;prediction=true\" if is_prediction else \"\",\n        ]\n    )\n\n    response = requests.post(\n        self.annotation_upload_url,\n        data=annotation_string,\n        headers={\"Content-Type\": \"text/plain\"},\n    )\n    responsejson = None\n    try:\n        responsejson = response.json()\n    except:\n        pass\n    if response.status_code == 200:\n        if responsejson:\n            if responsejson.get(\"error\"):\n                raise UploadError(\n                    f\"Failed to save annotation for {image_id}: {responsejson['error']}\"\n                )\n            elif not responsejson.get(\"success\"):\n                raise UploadError(\n                    f\"Failed to save annotation for {image_id}: {responsejson}\"\n                )\n        else:\n            warnings.warn(\n                f\"save annotation {annotation_path} 200 OK, weird response: {response}\"\n            )\n    elif response.status_code == 409 and \"already annotated\" in (\n        responsejson or {}\n    ).get(\"error\", {}).get(\"message\"):\n        print(f\"image already annotated: {annotation_path}\")\n    else:\n        if responsejson:\n            if responsejson.get(\"error\"):\n                raise UploadError(\n                    f\"save annotation for {image_id} / bad response: {response.status_code}: {responsejson['error']}\"\n                )\n            else:\n                raise UploadError(\n                    f\"save annotation for {image_id} / bad response: {response.status_code}: {responsejson}\"\n                )\n        else:\n            raise UploadError(\n                f\"save annotation for {image_id} bad response: {response}\"\n            )\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.__image_upload","title":"<code>__image_upload(image_path, hosted_image=False, split='train', batch_name=DEFAULT_BATCH_NAME, tag_names=[], **kwargs)</code>","text":"<p>Upload an image to a specific project.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to image you'd like to upload</p> required <code>hosted_image</code> <code>bool</code> <p>whether the image is hosted on Roboflow</p> <code>False</code> <code>split</code> <code>str</code> <p>the dataset split the image to</p> <code>'train'</code> Source code in <code>roboflow/core/project.py</code> <pre><code>def __image_upload(\n    self,\n    image_path: str,\n    hosted_image: bool = False,\n    split: str = \"train\",\n    batch_name: str = DEFAULT_BATCH_NAME,\n    tag_names: list = [],\n    **kwargs,\n):\n\"\"\"\n    Upload an image to a specific project.\n\n    Args:\n        image_path (str): path to image you'd like to upload\n        hosted_image (bool): whether the image is hosted on Roboflow\n        split (str): the dataset split the image to\n    \"\"\"\n\n    # If image is not a hosted image\n    if not hosted_image:\n        batch_name = (\n            batch_name\n            if batch_name and isinstance(batch_name, str)\n            else DEFAULT_BATCH_NAME\n        )\n\n        project_name = self.id.rsplit(\"/\")[1]\n        image_name = os.path.basename(image_path)\n\n        # Construct URL for local image upload\n        self.image_upload_url = \"\".join(\n            [\n                API_URL + \"/dataset/\",\n                project_name,\n                \"/upload\",\n                \"?api_key=\",\n                self.__api_key,\n                \"&amp;batch=\",\n                batch_name,\n            ]\n        )\n        for key, value in kwargs.items():\n            self.image_upload_url += \"&amp;\" + str(key) + \"=\" + str(value)\n\n        for tag in tag_names:\n            self.image_upload_url = self.image_upload_url + f\"&amp;tag={tag}\"\n\n        # Convert to PIL Image\n        img = cv2.imread(image_path)\n        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        pilImage = Image.fromarray(image)\n\n        # Convert to JPEG Buffer\n        buffered = io.BytesIO()\n        pilImage.save(buffered, quality=100, format=\"JPEG\")\n\n        # Build multipart form and post request\n        m = MultipartEncoder(\n            fields={\n                \"name\": image_name,\n                \"split\": split,\n                \"file\": (\"imageToUpload\", buffered.getvalue(), \"image/jpeg\"),\n            }\n        )\n        response = requests.post(\n            self.image_upload_url, data=m, headers={\"Content-Type\": m.content_type}\n        )\n\n    else:\n        # Hosted image upload url\n        project_name = self.id.rsplit(\"/\")[1]\n\n        upload_url = \"\".join(\n            [\n                API_URL + \"/dataset/\" + self.project_name + \"/upload\",\n                \"?api_key=\" + self.__api_key,\n                \"&amp;name=\" + os.path.basename(image_path),\n                \"&amp;split=\" + split,\n                \"&amp;image=\" + urllib.parse.quote_plus(image_path),\n            ]\n        )\n        # Get response\n        response = requests.post(upload_url)\n    responsejson = None\n    try:\n        responsejson = response.json()\n    except:\n        pass\n    if response.status_code == 200:\n        if responsejson:\n            if \"duplicate\" in responsejson.keys():\n                print(f\"Duplicate image not uploaded: {image_path}\")\n            elif not responsejson.get(\"success\"):\n                raise UploadError(f\"Server rejected image: {responsejson}\")\n            return responsejson.get(\"id\")\n        else:\n            warnings.warn(\n                f\"upload image {image_path} 200 OK, weird response: {response}\"\n            )\n            return None\n    else:\n        if responsejson:\n            raise UploadError(\n                f\"Bad response: {response.status_code}: {responsejson}\"\n            )\n        else:\n            raise UploadError(f\"Bad response: {response}\")\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.__init__","title":"<code>__init__(api_key, a_project, model_format=None)</code>","text":"<p>Create a Project object that represents a Project associated with a Workspace.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>private roboflow api key</p> required <code>a_project</code> <code>str</code> <p>the project id</p> required <code>model_format</code> <code>str</code> <p>the model format of the project</p> <code>None</code> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def __init__(self, api_key: str, a_project: str, model_format: str = None):\n\"\"\"\n    Create a Project object that represents a Project associated with a Workspace.\n\n    Args:\n        api_key (str): private roboflow api key\n        a_project (str): the project id\n        model_format (str): the model format of the project\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n    \"\"\"\n    if api_key in DEMO_KEYS:\n        self.__api_key = api_key\n        self.model_format = model_format\n    else:\n        self.__api_key = api_key\n        self.annotation = a_project[\"annotation\"]\n        self.classes = a_project[\"classes\"]\n        self.colors = a_project[\"colors\"]\n        self.created = datetime.datetime.fromtimestamp(a_project[\"created\"])\n        self.id = a_project[\"id\"]\n        self.images = a_project[\"images\"]\n        self.name = a_project[\"name\"]\n        self.public = a_project[\"public\"]\n        self.splits = a_project[\"splits\"]\n        self.type = a_project[\"type\"]\n        self.unannotated = a_project[\"unannotated\"]\n        self.updated = datetime.datetime.fromtimestamp(a_project[\"updated\"])\n        self.model_format = model_format\n\n        temp = self.id.rsplit(\"/\")\n        self.__workspace = temp[0]\n        self.__project_name = temp[1]\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.__str__","title":"<code>__str__()</code>","text":"<p>Show a string representation of a Project object.</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def __str__(self):\n\"\"\"\n    Show a string representation of a Project object.\n    \"\"\"\n    # String representation of project\n    json_str = {\"name\": self.name, \"type\": self.type, \"workspace\": self.__workspace}\n\n    return json.dumps(json_str, indent=2)\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.check_valid_image","title":"<code>check_valid_image(image_path)</code>","text":"<p>Check if an image is valid. Useful before attempting to upload an image to Roboflow.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to image you'd like to check</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>whether the image is valid or not</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def check_valid_image(self, image_path: str):\n\"\"\"\n    Check if an image is valid. Useful before attempting to upload an image to Roboflow.\n\n    Args:\n        image_path (str): path to image you'd like to check\n\n    Returns:\n        bool: whether the image is valid or not\n    \"\"\"\n    try:\n        img = Image.open(image_path)\n        valid = img.format in ACCEPTED_IMAGE_FORMATS\n        img.close()\n    except UnidentifiedImageError:\n        return False\n\n    return valid\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.generate_version","title":"<code>generate_version(settings)</code>","text":"<p>Generate a version of a dataset hosted on Roboflow.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <p>A Python dict with augmentation and preprocessing keys and specifications for generation. These settings mirror capabilities available via the Roboflow UI.     For example:         {             \"augmentation\": {                 \"bbblur\": { \"pixels\": 1.5 },                 \"bbbrightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },                 \"bbcrop\": { \"min\": 12, \"max\": 71 },                 \"bbexposure\": { \"percent\": 30 },                 \"bbflip\": { \"horizontal\": true, \"vertical\": false },                 \"bbnoise\": { \"percent\": 50 },                 \"bbninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },                 \"bbrotate\": { \"degrees\": 45 },                 \"bbshear\": { \"horizontal\": 45, \"vertical\": 45 },                 \"blur\": { \"pixels\": 1.5 },                 \"brightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },                 \"crop\": { \"min\": 12, \"max\": 71 },                 \"cutout\": { \"count\": 26, \"percent\": 71 },                 \"exposure\": { \"percent\": 30 },                 \"flip\": { \"horizontal\": true, \"vertical\": false },                 \"hue\": { \"degrees\": 180 },                 \"image\": { \"versions\": 32 },                 \"mosaic\": true,                 \"ninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },                 \"noise\": { \"percent\": 50 },                 \"rgrayscale\": { \"percent\": 50 },                 \"rotate\": { \"degrees\": 45 },                 \"saturation\": { \"percent\": 50 },                 \"shear\": { \"horizontal\": 45, \"vertical\": 45 }             },             \"preprocessing\": {                 \"auto-orient\": true,                 \"contrast\": { \"type\": \"Contrast Stretching\" },                 \"filter-null\": { \"percent\": 50 },                 \"grayscale\": true,                 \"isolate\": true,                 \"remap\": { \"original_class_name\": \"new_class_name\" },                 \"resize\": { \"width\": 200, \"height\": 200, \"format\": \"Stretch to\" },                 \"static-crop\": { \"x_min\": 10, \"x_max\": 90, \"y_min\": 10, \"y_max\": 90 },                 \"tile\": { \"rows\": 2, \"columns\": 2 }             }         }</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The version number that is being generated.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>versions = project.generate_version(settings={...})</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def generate_version(self, settings):\n\"\"\"\n    Generate a version of a dataset hosted on Roboflow.\n\n    Args:\n        settings: A Python dict with augmentation and preprocessing keys and specifications for generation. These settings mirror capabilities available via the Roboflow UI.\n                For example:\n                    {\n                        \"augmentation\": {\n                            \"bbblur\": { \"pixels\": 1.5 },\n                            \"bbbrightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },\n                            \"bbcrop\": { \"min\": 12, \"max\": 71 },\n                            \"bbexposure\": { \"percent\": 30 },\n                            \"bbflip\": { \"horizontal\": true, \"vertical\": false },\n                            \"bbnoise\": { \"percent\": 50 },\n                            \"bbninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },\n                            \"bbrotate\": { \"degrees\": 45 },\n                            \"bbshear\": { \"horizontal\": 45, \"vertical\": 45 },\n                            \"blur\": { \"pixels\": 1.5 },\n                            \"brightness\": { \"brighten\": true, \"darken\": false, \"percent\": 91 },\n                            \"crop\": { \"min\": 12, \"max\": 71 },\n                            \"cutout\": { \"count\": 26, \"percent\": 71 },\n                            \"exposure\": { \"percent\": 30 },\n                            \"flip\": { \"horizontal\": true, \"vertical\": false },\n                            \"hue\": { \"degrees\": 180 },\n                            \"image\": { \"versions\": 32 },\n                            \"mosaic\": true,\n                            \"ninety\": { \"clockwise\": true, \"counter-clockwise\": false, \"upside-down\": false },\n                            \"noise\": { \"percent\": 50 },\n                            \"rgrayscale\": { \"percent\": 50 },\n                            \"rotate\": { \"degrees\": 45 },\n                            \"saturation\": { \"percent\": 50 },\n                            \"shear\": { \"horizontal\": 45, \"vertical\": 45 }\n                        },\n                        \"preprocessing\": {\n                            \"auto-orient\": true,\n                            \"contrast\": { \"type\": \"Contrast Stretching\" },\n                            \"filter-null\": { \"percent\": 50 },\n                            \"grayscale\": true,\n                            \"isolate\": true,\n                            \"remap\": { \"original_class_name\": \"new_class_name\" },\n                            \"resize\": { \"width\": 200, \"height\": 200, \"format\": \"Stretch to\" },\n                            \"static-crop\": { \"x_min\": 10, \"x_max\": 90, \"y_min\": 10, \"y_max\": 90 },\n                            \"tile\": { \"rows\": 2, \"columns\": 2 }\n                        }\n                    }\n\n    Returns:\n        int: The version number that is being generated.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; versions = project.generate_version(settings={...})\n    \"\"\"\n\n    if not {\"augmentation\", \"preprocessing\"} &lt;= settings.keys():\n        raise (\n            RuntimeError(\n                \"augmentation and preprocessing keys are required to generate. If none are desired specify empty dict associated with that key.\"\n            )\n        )\n\n    r = requests.post(\n        f\"{API_URL}/{self.__workspace}/{self.__project_name}/generate?api_key={self.__api_key}\",\n        json=settings,\n    )\n\n    try:\n        r_json = r.json()\n    except:\n        raise (\"Error when requesting to generate a new version for project.\")\n\n    # if the generation succeeds, return the version that is being generated\n    if r.status_code == 200:\n        sys.stdout.write(\n            \"\\r\"\n            + r_json[\"message\"]\n            + \" for new version \"\n            + str(r_json[\"version\"])\n            + \".\"\n        )\n        sys.stdout.write(\"\\n\")\n        sys.stdout.flush()\n        return int(r_json[\"version\"])\n    else:\n        if \"error\" in r_json.keys():\n            raise RuntimeError(r_json[\"error\"])\n        else:\n            raise RuntimeError(json.dumps(r_json))\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.get_version_information","title":"<code>get_version_information()</code>","text":"<p>Retrieve all versions of a project.</p> <p>Returns:</p> Type Description <p>A list of all versions of the project.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>version_info = project.get_version_information()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def get_version_information(self):\n\"\"\"\n    Retrieve all versions of a project.\n\n    Returns:\n        A list of all versions of the project.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; version_info = project.get_version_information()\n    \"\"\"\n    dataset_info = requests.get(\n        API_URL\n        + \"/\"\n        + self.__workspace\n        + \"/\"\n        + self.__project_name\n        + \"?api_key=\"\n        + self.__api_key\n    )\n\n    # Throw error if dataset isn't valid/user doesn't have permissions to access the dataset\n    if dataset_info.status_code != 200:\n        raise RuntimeError(dataset_info.text)\n\n    dataset_info = dataset_info.json()\n    return dataset_info[\"versions\"]\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.list_versions","title":"<code>list_versions()</code>","text":"<p>Print out versions for that specific project.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>project.list_versions()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def list_versions(self):\n\"\"\"\n    Print out versions for that specific project.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; project.list_versions()\n    \"\"\"\n    version_info = self.get_version_information()\n    print(version_info)\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.search","title":"<code>search(like_image=None, prompt=None, offset=0, limit=100, tag=None, class_name=None, in_dataset=None, batch=False, batch_id=None, fields=['id', 'created', 'name', 'labels'])</code>","text":"<p>Search for images in a project.</p> <p>Parameters:</p> Name Type Description Default <code>like_image</code> <code>str</code> <p>name of an image in your dataset to use if you want to find images similar to that one</p> <code>None</code> <code>prompt</code> <code>str</code> <p>search prompt</p> <code>None</code> <code>offset</code> <code>int</code> <p>offset of results</p> <code>0</code> <code>limit</code> <code>int</code> <p>limit of results</p> <code>100</code> <code>tag</code> <code>str</code> <p>tag that an image must have</p> <code>None</code> <code>class_name</code> <code>str</code> <p>class name that an image must have</p> <code>None</code> <code>in_dataset</code> <code>str</code> <p>dataset that an image must be in</p> <code>None</code> <code>batch</code> <code>bool</code> <p>whether the image must be in a batch</p> <code>False</code> <code>batch_id</code> <code>str</code> <p>batch id that an image must be in</p> <code>None</code> <code>fields</code> <code>list</code> <p>fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])</p> <code>['id', 'created', 'name', 'labels']</code> <p>Returns:</p> Type Description <p>A list of images that match the search criteria.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>results = project.search(query=\"cat\", limit=10)</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def search(\n    self,\n    like_image: str = None,\n    prompt: str = None,\n    offset: int = 0,\n    limit: int = 100,\n    tag: str = None,\n    class_name: str = None,\n    in_dataset: str = None,\n    batch: bool = False,\n    batch_id: str = None,\n    fields: list = [\"id\", \"created\", \"name\", \"labels\"],\n):\n\"\"\"\n    Search for images in a project.\n\n    Args:\n        like_image (str): name of an image in your dataset to use if you want to find images similar to that one\n        prompt (str): search prompt\n        offset (int): offset of results\n        limit (int): limit of results\n        tag (str): tag that an image must have\n        class_name (str): class name that an image must have\n        in_dataset (str): dataset that an image must be in\n        batch (bool): whether the image must be in a batch\n        batch_id (str): batch id that an image must be in\n        fields (list): fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])\n\n    Returns:\n        A list of images that match the search criteria.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; results = project.search(query=\"cat\", limit=10)\n    \"\"\"\n    payload = {}\n\n    if like_image is not None:\n        payload[\"like_image\"] = like_image\n\n    if prompt is not None:\n        payload[\"prompt\"] = prompt\n\n    if offset is not None:\n        payload[\"offset\"] = offset\n\n    if limit is not None:\n        payload[\"limit\"] = limit\n\n    if tag is not None:\n        payload[\"tag\"] = tag\n\n    if class_name is not None:\n        payload[\"class_name\"] = class_name\n\n    if in_dataset is not None:\n        payload[\"in_dataset\"] = in_dataset\n\n    if batch is not None:\n        payload[\"batch\"] = batch\n\n    if batch_id is not None:\n        payload[\"batch_id\"] = batch_id\n\n    payload[\"fields\"] = fields\n\n    data = requests.post(\n        API_URL\n        + \"/\"\n        + self.__workspace\n        + \"/\"\n        + self.__project_name\n        + \"/search?api_key=\"\n        + self.__api_key,\n        json=payload,\n    )\n\n    return data.json()[\"results\"]\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.search_all","title":"<code>search_all(like_image=None, prompt=None, offset=0, limit=100, tag=None, class_name=None, in_dataset=None, batch=False, batch_id=None, fields=['id', 'created'])</code>","text":"<p>Create a paginated list of search results for use in searching the images in a project.</p> <p>Parameters:</p> Name Type Description Default <code>like_image</code> <code>str</code> <p>name of an image in your dataset to use if you want to find images similar to that one</p> <code>None</code> <code>prompt</code> <code>str</code> <p>search prompt</p> <code>None</code> <code>offset</code> <code>int</code> <p>offset of results</p> <code>0</code> <code>limit</code> <code>int</code> <p>limit of results</p> <code>100</code> <code>tag</code> <code>str</code> <p>tag that an image must have</p> <code>None</code> <code>class_name</code> <code>str</code> <p>class name that an image must have</p> <code>None</code> <code>in_dataset</code> <code>str</code> <p>dataset that an image must be in</p> <code>None</code> <code>batch</code> <code>bool</code> <p>whether the image must be in a batch</p> <code>False</code> <code>batch_id</code> <code>str</code> <p>batch id that an image must be in</p> <code>None</code> <code>fields</code> <code>list</code> <p>fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])</p> <code>['id', 'created']</code> <p>Returns:</p> Type Description <p>A list of images that match the search criteria.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>results = project.search_all(query=\"cat\", limit=10)</p> <p>for result in results:</p> <pre><code>print(result)\n</code></pre> Source code in <code>roboflow/core/project.py</code> <pre><code>def search_all(\n    self,\n    like_image: str = None,\n    prompt: str = None,\n    offset: int = 0,\n    limit: int = 100,\n    tag: str = None,\n    class_name: str = None,\n    in_dataset: str = None,\n    batch: bool = False,\n    batch_id: str = None,\n    fields: list = [\"id\", \"created\"],\n):\n\"\"\"\n    Create a paginated list of search results for use in searching the images in a project.\n\n    Args:\n        like_image (str): name of an image in your dataset to use if you want to find images similar to that one\n        prompt (str): search prompt\n        offset (int): offset of results\n        limit (int): limit of results\n        tag (str): tag that an image must have\n        class_name (str): class name that an image must have\n        in_dataset (str): dataset that an image must be in\n        batch (bool): whether the image must be in a batch\n        batch_id (str): batch id that an image must be in\n        fields (list): fields to return in results (default: [\"id\", \"created\", \"name\", \"labels\"])\n\n    Returns:\n        A list of images that match the search criteria.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; results = project.search_all(query=\"cat\", limit=10)\n\n        &gt;&gt;&gt; for result in results:\n\n        &gt;&gt;&gt;     print(result)\n    \"\"\"\n    while True:\n        data = self.search(\n            like_image=like_image,\n            prompt=prompt,\n            offset=offset,\n            limit=limit,\n            tag=tag,\n            class_name=class_name,\n            in_dataset=in_dataset,\n            batch=batch,\n            batch_id=batch_id,\n            fields=fields,\n        )\n\n        yield data\n\n        if len(data) &lt; limit:\n            break\n\n        offset += limit\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.train","title":"<code>train(new_version_settings={'preprocessing': {'auto-orient': True, 'resize': {'width': 640, 'height': 640, 'format': 'Stretch to'}}, 'augmentation': {}}, speed=None, checkpoint=None, plot_in_notebook=False)</code>","text":"<p>Ask the Roboflow API to train a previously exported version's dataset.</p> <p>Parameters:</p> Name Type Description Default <code>speed</code> <p>Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is <code>fast</code>.</p> <code>None</code> <code>checkpoint</code> <p>A string representing the checkpoint to use while training</p> <code>None</code> <code>plot</code> <p>Whether to plot the training loss curve. Default is False.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the Roboflow API returns an error with a helpful JSON body</p> <code>HTTPError</code> <p>If the Network/Roboflow API fails and does not return JSON</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>version = project.version(1)</p> <p>version.train()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def train(\n    self,\n    new_version_settings={\n        \"preprocessing\": {\n            \"auto-orient\": True,\n            \"resize\": {\"width\": 640, \"height\": 640, \"format\": \"Stretch to\"},\n        },\n        \"augmentation\": {},\n    },\n    speed=None,\n    checkpoint=None,\n    plot_in_notebook=False,\n) -&gt; bool:\n\"\"\"\n    Ask the Roboflow API to train a previously exported version's dataset.\n\n    Args:\n        speed: Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is `fast`.\n        checkpoint: A string representing the checkpoint to use while training\n        plot: Whether to plot the training loss curve. Default is False.\n\n    Returns:\n        True\n\n    Raises:\n        RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n        HTTPError: If the Network/Roboflow API fails and does not return JSON\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; version = project.version(1)\n\n        &gt;&gt;&gt; version.train()\n    \"\"\"\n\n    new_version = self.generate_version(settings=new_version_settings)\n    new_version = self.version(new_version)\n    new_model = new_version.train(\n        speed=speed, checkpoint=checkpoint, plot_in_notebook=plot_in_notebook\n    )\n\n    return new_model\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.upload","title":"<code>upload(image_path=None, annotation_path=None, hosted_image=False, image_id=None, split='train', num_retry_uploads=0, batch_name=DEFAULT_BATCH_NAME, tag_names=[], is_prediction=False, **kwargs)</code>","text":"<p>Upload an image or annotation to the Roboflow API.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to image you'd like to upload</p> <code>None</code> <code>annotation_path</code> <code>str</code> <p>if you're upload annotation, path to it</p> <code>None</code> <code>hosted_image</code> <code>bool</code> <p>whether the image is hosted</p> <code>False</code> <code>image_id</code> <code>str</code> <p>id of the image</p> <code>None</code> <code>split</code> <code>str</code> <p>to upload the image to</p> <code>'train'</code> <code>num_retry_uploads</code> <code>int</code> <p>how many times to retry upload on failure</p> <code>0</code> <code>batch_name</code> <code>str</code> <p>name of batch to upload to within project</p> <code>DEFAULT_BATCH_NAME</code> <code>tag_names</code> <code>list[str]</code> <p>tags to be applied to an image</p> <code>[]</code> <code>is_prediction</code> <code>bool</code> <p>whether the annotation data is a prediction rather than ground truth</p> <code>False</code> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>project.upload(image_path=\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def upload(\n    self,\n    image_path: str = None,\n    annotation_path: str = None,\n    hosted_image: bool = False,\n    image_id: str = None,\n    split: str = \"train\",\n    num_retry_uploads: int = 0,\n    batch_name: str = DEFAULT_BATCH_NAME,\n    tag_names: list = [],\n    is_prediction: bool = False,\n    **kwargs,\n):\n\"\"\"\n    Upload an image or annotation to the Roboflow API.\n\n    Args:\n        image_path (str): path to image you'd like to upload\n        annotation_path (str): if you're upload annotation, path to it\n        hosted_image (bool): whether the image is hosted\n        image_id (str): id of the image\n        split (str): to upload the image to\n        num_retry_uploads (int): how many times to retry upload on failure\n        batch_name (str): name of batch to upload to within project\n        tag_names (list[str]): tags to be applied to an image\n        is_prediction (bool): whether the annotation data is a prediction rather than ground truth\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; project.upload(image_path=\"YOUR_IMAGE.jpg\")\n    \"\"\"\n\n    is_hosted = image_path.startswith(\"http://\") or image_path.startswith(\n        \"https://\"\n    )\n\n    is_file = os.path.isfile(image_path) or is_hosted\n    is_dir = os.path.isdir(image_path)\n\n    if not is_file and not is_dir:\n        raise RuntimeError(\n            \"The provided image path [ {} ] is not a valid path. Please provide a path to an image or a directory.\".format(\n                image_path\n            )\n        )\n\n    if is_file:\n        is_image = self.check_valid_image(image_path) or is_hosted\n\n        if not is_image:\n            raise RuntimeError(\n                \"The image you provided {} is not a supported file format. We currently support: {}.\".format(\n                    image_path, \", \".join(ACCEPTED_IMAGE_FORMATS)\n                )\n            )\n\n        self.single_upload(\n            image_path=image_path,\n            annotation_path=annotation_path,\n            hosted_image=hosted_image,\n            image_id=image_id,\n            split=split,\n            num_retry_uploads=num_retry_uploads,\n            batch_name=batch_name,\n            tag_names=tag_names,\n            is_prediction=is_prediction,\n            **kwargs,\n        )\n\n    else:\n        images = os.listdir(image_path)\n        for image in images:\n            path = image_path + \"/\" + image\n            if self.check_valid_image(image):\n                self.single_upload(\n                    image_path=path,\n                    annotation_path=annotation_path,\n                    hosted_image=hosted_image,\n                    image_id=image_id,\n                    split=split,\n                    num_retry_uploads=num_retry_uploads,\n                    batch_name=batch_name,\n                    tag_names=tag_names,\n                    is_prediction=is_prediction,\n                    **kwargs,\n                )\n                print(\"[ \" + path + \" ] was uploaded succesfully.\")\n            else:\n                print(\"[ \" + path + \" ] was skipped.\")\n                continue\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.version","title":"<code>version(version_number, local=None)</code>","text":"<p>Retrieves information about a specific version and returns a Version() object.</p> <p>Parameters:</p> Name Type Description Default <code>version_number</code> <code>int</code> <p>the version number that you want to retrieve</p> required <code>local</code> <code>str</code> <p>specifies the localhost address and port if pointing towards local inference engine</p> <code>None</code> <p>Returns:</p> Type Description <p>Version() object</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def version(self, version_number: int, local: str = None):\n\"\"\"\n    Retrieves information about a specific version and returns a Version() object.\n\n    Args:\n        version_number (int): the version number that you want to retrieve\n        local (str): specifies the localhost address and port if pointing towards local inference engine\n\n    Returns:\n        Version() object\n    \"\"\"\n\n    if self.__api_key in DEMO_KEYS:\n        name = \"\"\n        if self.__api_key == \"coco-128-sample\":\n            name = \"coco-128\"\n        else:\n            name = \"chess-pieces-new\"\n        return Version(\n            {},\n            \"type\",\n            self.__api_key,\n            name,\n            version_number,\n            self.model_format,\n            local=None,\n            workspace=\"\",\n            project=\"\",\n        )\n\n    version_info = self.get_version_information()\n\n    for version_object in version_info:\n        current_version_num = os.path.basename(version_object[\"id\"])\n        if current_version_num == str(version_number):\n            vers = Version(\n                version_object,\n                self.type,\n                self.__api_key,\n                self.name,\n                current_version_num,\n                self.model_format,\n                local=local,\n                workspace=self.__workspace,\n                project=self.__project_name,\n                public=self.public,\n                colors=self.colors,\n            )\n            return vers\n\n    raise RuntimeError(\"Version number {} is not found.\".format(version_number))\n</code></pre>"},{"location":"core/project/#roboflow.core.project.Project.versions","title":"<code>versions()</code>","text":"<p>Return all versions in the project as Version objects.</p> <p>Returns:</p> Type Description <p>A list of Version objects.</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>versions = project.versions()</p> Source code in <code>roboflow/core/project.py</code> <pre><code>def versions(self):\n\"\"\"\n    Return all versions in the project as Version objects.\n\n    Returns:\n        A list of Version objects.\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; versions = project.versions()\n    \"\"\"\n    version_info = self.get_version_information()\n    version_array = []\n    for a_version in version_info:\n        version_object = Version(\n            a_version,\n            (self.type if \"model\" in a_version else None),\n            self.__api_key,\n            self.name,\n            a_version[\"id\"],\n            self.model_format,\n            local=None,\n            workspace=self.__workspace,\n            project=self.__project_name,\n            public=self.public,\n            colors=self.colors,\n        )\n        version_array.append(version_object)\n    return version_array\n</code></pre>"},{"location":"core/version/","title":"Versions","text":""},{"location":"core/version/#roboflow.core.version.Version","title":"<code>Version</code>","text":"<p>Class representing a Roboflow dataset version.</p> Source code in <code>roboflow/core/version.py</code> <pre><code>class Version:\n\"\"\"\n    Class representing a Roboflow dataset version.\n    \"\"\"\n\n    def __init__(\n        self,\n        version_dict,\n        type,\n        api_key,\n        name,\n        version,\n        model_format,\n        local,\n        workspace,\n        project,\n        public,\n        colors=None,\n    ):\n\"\"\"\n        Initialize a Version object.\n        \"\"\"\n        if api_key in DEMO_KEYS:\n            if api_key == \"coco-128-sample\":\n                self.__api_key = api_key\n                self.model_format = model_format\n                self.name = \"coco-128\"\n                self.version = \"1\"\n            else:\n                self.__api_key = api_key\n                self.model_format = model_format\n                self.name = \"chess-pieces-new\"\n                self.version = \"23\"\n                self.id = \"joseph-nelson/chess-pieces-new\"\n        else:\n            self.__api_key = api_key\n            self.name = name\n\n            # FIXME: the version argument is inconsistently passed into this object.\n            # Sometimes it is passed as: test-workspace/test-project/2\n            # Other times, it is passed as: 2\n            self.version = version\n            self.type = type\n            self.augmentation = version_dict[\"augmentation\"]\n            self.created = version_dict[\"created\"]\n            self.id = version_dict[\"id\"]\n            self.images = version_dict[\"images\"]\n            self.preprocessing = version_dict[\"preprocessing\"]\n            self.splits = version_dict[\"splits\"]\n            self.model_format = model_format\n            self.workspace = workspace\n            self.project = project\n            self.public = public\n            self.colors = {} if colors is None else colors\n\n            self.colors = colors\n            if \"exports\" in version_dict.keys():\n                self.exports = version_dict[\"exports\"]\n            else:\n                self.exports = []\n\n            version_without_workspace = os.path.basename(str(version))\n\n            if self.type == TYPE_OBJECT_DETECTION:\n                self.model = ObjectDetectionModel(\n                    self.__api_key,\n                    self.id,\n                    self.name,\n                    version_without_workspace,\n                    local=local,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                )\n            elif self.type == TYPE_CLASSICATION:\n                self.model = ClassificationModel(\n                    self.__api_key,\n                    self.id,\n                    self.name,\n                    version_without_workspace,\n                    local=local,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                )\n            elif self.type == TYPE_INSTANCE_SEGMENTATION:\n                self.model = InstanceSegmentationModel(\n                    self.__api_key,\n                    self.id,\n                    colors=self.colors,\n                    preprocessing=self.preprocessing,\n                    local=local,\n                )\n            elif self.type == TYPE_SEMANTIC_SEGMENTATION:\n                self.model = SemanticSegmentationModel(self.__api_key, self.id)\n            else:\n                self.model = None\n\n    def __check_if_generating(self):\n        # check Roboflow API to see if this version is still generating\n\n        url = f\"{API_URL}/{self.workspace}/{self.project}/{self.version}?nocache=true\"\n        response = requests.get(url, params={\"api_key\": self.__api_key})\n        response.raise_for_status()\n\n        if response.json()[\"version\"][\"progress\"] == None:\n            progress = 0.0\n        else:\n            progress = float(response.json()[\"version\"][\"progress\"])\n\n        return response.json()[\"version\"][\"generating\"], progress\n\n    def __wait_if_generating(self, recurse=False):\n        # checks if a given version is still in the progress of generating\n\n        still_generating, progress = self.__check_if_generating()\n\n        if still_generating:\n            progress_message = (\n                \"Generating version still in progress. Progress: \"\n                + str(round(progress * 100, 2))\n                + \"%\"\n            )\n            sys.stdout.write(\"\\r\" + progress_message)\n            sys.stdout.flush()\n            time.sleep(5)\n            return self.__wait_if_generating(recurse=True)\n\n        else:\n            if recurse:\n                sys.stdout.write(\"\\n\")\n                sys.stdout.flush()\n            return\n\n    def download(self, model_format=None, location=None, overwrite: bool = True):\n\"\"\"\n        Download and extract a ZIP of a version's dataset in a given format\n\n        :param model_format: A format to use for downloading\n        :param location: An optional path for saving the file\n        :param overwrite: An optional flag to prevent dataset overwrite when dataset is already downloaded\n\n        Args:\n            model_format (str): A format to use for downloading\n            location (str): An optional path for saving the file\n            overwrite (bool): An optional flag to prevent dataset overwrite when dataset is already downloaded\n\n        Returns:\n            Dataset Object\n\n        Raises:\n            RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n            HTTPError: If the Network/Roboflow API fails and does not return JSON\n        \"\"\"\n\n        self.__wait_if_generating()\n\n        if model_format == \"yolov8\":\n            # if ultralytics is installed, we will assume users will want to use yolov8 and we check for the supported version\n            try:\n                import_module(\"ultralytics\")\n                print_warn_for_wrong_dependencies_versions(\n                    [(\"ultralytics\", \"==\", \"8.0.134\")]\n                )\n            except ImportError as e:\n                print(\n                    \"[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.134`, to intall it `pip install ultralytics==8.0.134`.\"\n                )\n                # silently fail\n                pass\n\n        model_format = self.__get_format_identifier(model_format)\n\n        if model_format not in self.exports:\n            self.export(model_format)\n\n        # if model_format is not in\n\n        if location is None:\n            location = self.__get_download_location()\n        if os.path.exists(location) and not overwrite:\n            return Dataset(\n                self.name, self.version, model_format, os.path.abspath(location)\n            )\n\n        if self.__api_key == \"coco-128-sample\":\n            link = \"https://app.roboflow.com/ds/n9QwXwUK42?key=NnVCe2yMxP\"\n        else:\n            url = self.__get_download_url(model_format)\n            response = requests.get(url, params={\"api_key\": self.__api_key})\n            if response.status_code == 200:\n                link = response.json()[\"export\"][\"link\"]\n            else:\n                try:\n                    raise RuntimeError(response.json())\n                except requests.exceptions.JSONDecodeError:\n                    response.raise_for_status()\n\n        self.__download_zip(link, location, model_format)\n        self.__extract_zip(location, model_format)\n        self.__reformat_yaml(location, model_format)\n\n        return Dataset(self.name, self.version, model_format, os.path.abspath(location))\n\n    def export(self, model_format=None):\n\"\"\"\n        Ask the Roboflow API to generate a version's dataset in a given format so that it can be downloaded via the `download()` method.\n\n        The export will be asynchronously generated and available for download after some amount of seconds - depending on dataset size.\n\n        Args:\n            model_format (str): A format to use for downloading\n\n        Returns:\n            True\n\n        Raises:\n            RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n            HTTPError: If the Network/Roboflow API fails and does not return JSON\n        \"\"\"\n\n        model_format = self.__get_format_identifier(model_format)\n\n        self.__wait_if_generating()\n\n        url = self.__get_download_url(model_format)\n        response = requests.get(url, params={\"api_key\": self.__api_key})\n        if not response.ok:\n            try:\n                raise RuntimeError(response.json())\n            except requests.exceptions.JSONDecodeError:\n                response.raise_for_status()\n\n        # the rest api returns 202 if the export is still in progress\n        if response.status_code == 202:\n            status_code_check = 202\n            while status_code_check == 202:\n                time.sleep(1)\n                response = requests.get(url, params={\"api_key\": self.__api_key})\n                status_code_check = response.status_code\n                if status_code_check == 202:\n                    progress = response.json()[\"progress\"]\n                    progress_message = (\n                        \"Exporting format \"\n                        + model_format\n                        + \" in progress : \"\n                        + str(round(progress * 100, 2))\n                        + \"%\"\n                    )\n                    sys.stdout.write(\"\\r\" + progress_message)\n                    sys.stdout.flush()\n\n        if response.status_code == 200:\n            sys.stdout.write(\"\\n\")\n            print(\"\\r\" + \"Version export complete for \" + model_format + \" format\")\n            sys.stdout.flush()\n            return True\n        else:\n            try:\n                raise RuntimeError(response.json())\n            except requests.exceptions.JSONDecodeError:\n                response.raise_for_status()\n\n    def train(self, speed=None, checkpoint=None, plot_in_notebook=False) -&gt; bool:\n\"\"\"\n        Ask the Roboflow API to train a previously exported version's dataset.\n\n        Args:\n            speed: Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is `fast`.\n            checkpoint: A string representing the checkpoint to use while training\n            plot: Whether to plot the training results. Default is `False`.\n\n        Returns:\n            An instance of the trained model class\n\n        Raises:\n            RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n            HTTPError: If the Network/Roboflow API fails and does not return JSON\n        \"\"\"\n\n        self.__wait_if_generating()\n\n        train_model_format = \"yolov5pytorch\"\n\n        if self.type == TYPE_CLASSICATION:\n            train_model_format = \"folder\"\n\n        if self.type == TYPE_INSTANCE_SEGMENTATION:\n            train_model_format = \"yolov5pytorch\"\n\n        if self.type == TYPE_SEMANTIC_SEGMENTATION:\n            train_model_format = \"png-mask-semantic\"\n\n        # if classification\n        if train_model_format not in self.exports:\n            self.export(train_model_format)\n\n        workspace, project, *_ = self.id.rsplit(\"/\")\n        url = f\"{API_URL}/{workspace}/{project}/{self.version}/train\"\n\n        data = {}\n        if speed:\n            data[\"speed\"] = speed\n\n        if checkpoint:\n            data[\"checkpoint\"] = checkpoint\n\n        write_line(\"Reaching out to Roboflow to start training...\")\n\n        response = requests.post(url, json=data, params={\"api_key\": self.__api_key})\n        if not response.ok:\n            try:\n                raise RuntimeError(response.json())\n            except requests.exceptions.JSONDecodeError:\n                response.raise_for_status()\n\n        status = \"training\"\n\n        if plot_in_notebook:\n            import collections\n\n            from IPython.display import clear_output\n            from matplotlib import pyplot as plt\n\n            def live_plot(epochs, mAP, loss, title=\"\"):\n                clear_output(wait=True)\n\n                plt.subplot(2, 1, 1)\n                plt.plot(epochs, mAP, \"#00FFCE\")\n                plt.title(title)\n                plt.ylabel(\"mAP\")\n\n                plt.subplot(2, 1, 2)\n                plt.plot(epochs, loss, \"#A351FB\")\n                plt.xlabel(\"epochs\")\n                plt.ylabel(\"loss\")\n                plt.show()\n\n        first_graph_write = False\n        previous_epochs = []\n        num_machine_spin_dots = []\n\n        while status == \"training\" or status == \"running\":\n            url = (\n                f\"{API_URL}/{self.workspace}/{self.project}/{self.version}?nocache=true\"\n            )\n            response = requests.get(url, params={\"api_key\": self.__api_key})\n            response.raise_for_status()\n            version = response.json()[\"version\"]\n            if \"models\" in version.keys():\n                models = version[\"models\"]\n            else:\n                models = {}\n\n            if \"train\" in version.keys():\n                if \"results\" in version[\"train\"].keys():\n                    status = \"finished\"\n                    break\n                if \"status\" in version[\"train\"].keys():\n                    if version[\"train\"][\"status\"] == \"failed\":\n                        write_line(line=\"Training failed\")\n                        break\n\n            if \"roboflow-train\" in models.keys():\n                # training has started\n                epochs = np.array(\n                    [\n                        int(epoch[\"epoch\"])\n                        for epoch in models[\"roboflow-train\"][\"epochs\"]\n                    ]\n                )\n                mAP = np.array(\n                    [\n                        float(epoch[\"mAP\"])\n                        for epoch in models[\"roboflow-train\"][\"epochs\"]\n                    ]\n                )\n                loss = np.array(\n                    [\n                        (\n                            float(epoch[\"box_loss\"])\n                            + float(epoch[\"class_loss\"])\n                            + float(epoch[\"obj_loss\"])\n                        )\n                        for epoch in models[\"roboflow-train\"][\"epochs\"]\n                    ]\n                )\n\n                title = \"Training in Progress\"\n                # plottling logic\n            else:\n                num_machine_spin_dots.append(\".\")\n                if len(num_machine_spin_dots) &gt; 5:\n                    num_machine_spin_dots = [\".\"]\n                title = \"Training Machine Spinning Up\" + \"\".join(num_machine_spin_dots)\n\n                epochs = []\n                mAP = []\n                loss = []\n\n            if (len(epochs) &gt; len(previous_epochs)) or (len(epochs) == 0):\n                if plot_in_notebook:\n                    live_plot(epochs, mAP, loss, title)\n                else:\n                    if len(epochs) &gt; 0:\n                        title = (\n                            title\n                            + \": Epoch: \"\n                            + str(epochs[-1])\n                            + \" mAP: \"\n                            + str(mAP[-1])\n                            + \" loss: \"\n                            + str(loss[-1])\n                        )\n                    if not first_graph_write:\n                        write_line(title)\n                        first_graph_write = True\n\n            previous_epochs = copy.deepcopy(epochs)\n\n            time.sleep(5)\n\n        # return the model object\n        return self.model\n\n    # @warn_for_wrong_dependencies_versions([(\"ultralytics\", \"==\", \"8.0.134\")])\n    def deploy(self, model_type: str, model_path: str) -&gt; None:\n\"\"\"Uploads provided weights file to Roboflow\n\n        Args:\n            model_path (str): File path to model weights to be uploaded\n        \"\"\"\n\n        supported_models = [\"yolov5\", \"yolov7-seg\", \"yolov8\"]\n\n        if not any(\n            supported_model in model_type for supported_model in supported_models\n        ):\n            raise (\n                ValueError(\n                    f\"Model type {model_type} not supported. Supported models are {supported_models}\"\n                )\n            )\n\n        if \"yolov8\" in model_type:\n            try:\n                import torch\n                import ultralytics\n\n            except ImportError as e:\n                raise (\n                    \"The ultralytics python package is required to deploy yolov8 models. Please install it with `pip install ultralytics`\"\n                )\n\n            print_warn_for_wrong_dependencies_versions(\n                [(\"ultralytics\", \"==\", \"8.0.134\")]\n            )\n\n        elif \"yolov5\" in model_type or \"yolov7\" in model_type:\n            try:\n                import torch\n            except ImportError as e:\n                raise (\n                    \"The torch python package is required to deploy yolov5 models. Please install it with `pip install torch`\"\n                )\n\n        model = torch.load(os.path.join(model_path, \"weights/best.pt\"))\n\n        if isinstance(model[\"model\"].names, list):\n            class_names = model[\"model\"].names\n        else:\n            class_names = []\n            for i, val in enumerate(model[\"model\"].names):\n                class_names.append((val, model[\"model\"].names[val]))\n            class_names.sort(key=lambda x: x[0])\n            class_names = [x[1] for x in class_names]\n\n        if \"yolov8\" in model_type:\n            # try except for backwards compatibility with older versions of ultralytics\n            if \"-cls\" in model_type:\n                nc = model[\"model\"].yaml[\"nc\"]\n                args = model[\"train_args\"]\n            else:\n                nc = model[\"model\"].nc\n                args = model[\"model\"].args\n            try:\n                model_artifacts = {\n                    \"names\": class_names,\n                    \"yaml\": model[\"model\"].yaml,\n                    \"nc\": nc,\n                    \"args\": {\n                        k: val\n                        for k, val in args.items()\n                        if ((k == \"model\") or (k == \"imgsz\") or (k == \"batch\"))\n                    },\n                    \"ultralytics_version\": ultralytics.__version__,\n                    \"model_type\": model_type,\n                }\n            except:\n                model_artifacts = {\n                    \"names\": class_names,\n                    \"yaml\": model[\"model\"].yaml,\n                    \"nc\": nc,\n                    \"args\": {\n                        k: val\n                        for k, val in args.__dict__.items()\n                        if ((k == \"model\") or (k == \"imgsz\") or (k == \"batch\"))\n                    },\n                    \"ultralytics_version\": ultralytics.__version__,\n                    \"model_type\": model_type,\n                }\n        elif \"yolov5\" in model_type or \"yolov7\" in model_type:\n            # parse from yaml for yolov5\n\n            with open(os.path.join(model_path, \"opt.yaml\"), \"r\") as stream:\n                opts = yaml.safe_load(stream)\n\n            model_artifacts = {\n                \"names\": class_names,\n                \"nc\": model[\"model\"].nc,\n                \"args\": {\n                    \"imgsz\": opts[\"imgsz\"] if \"imgsz\" in opts else opts[\"img_size\"],\n                    \"batch\": opts[\"batch_size\"],\n                },\n                \"model_type\": model_type,\n            }\n            if hasattr(model[\"model\"], \"yaml\"):\n                model_artifacts[\"yaml\"] = model[\"model\"].yaml\n\n        with open(os.path.join(model_path, \"model_artifacts.json\"), \"w\") as fp:\n            json.dump(model_artifacts, fp)\n\n        torch.save(\n            model[\"model\"].state_dict(), os.path.join(model_path, \"state_dict.pt\")\n        )\n\n        lista_files = [\n            \"results.csv\",\n            \"results.png\",\n            \"model_artifacts.json\",\n            \"state_dict.pt\",\n        ]\n\n        with zipfile.ZipFile(\n            os.path.join(model_path, \"roboflow_deploy.zip\"), \"w\"\n        ) as zipMe:\n            for file in lista_files:\n                if os.path.exists(os.path.join(model_path, file)):\n                    zipMe.write(\n                        os.path.join(model_path, file),\n                        arcname=file,\n                        compress_type=zipfile.ZIP_DEFLATED,\n                    )\n                else:\n                    if file in [\"model_artifacts.json\", \"state_dict.pt\"]:\n                        raise (\n                            ValueError(\n                                f\"File {file} not found. Please make sure to provide a valid model path.\"\n                            )\n                        )\n\n        res = requests.get(\n            f\"{API_URL}/{self.workspace}/{self.project}/{self.version}/uploadModel?api_key={self.__api_key}&amp;modelType={model_type}&amp;nocache=true\"\n        )\n        try:\n            if res.status_code == 429:\n                raise RuntimeError(\n                    f\"This version already has a trained model. Please generate and train a new version in order to upload model to Roboflow.\"\n                )\n            else:\n                res.raise_for_status()\n        except Exception as e:\n            print(f\"An error occured when getting the model upload URL: {e}\")\n            return\n\n        res = requests.put(\n            res.json()[\"url\"],\n            data=open(os.path.join(model_path, \"roboflow_deploy.zip\"), \"rb\"),\n        )\n        try:\n            res.raise_for_status()\n\n            if self.public:\n                print(\n                    f\"View the status of your deployment at: {APP_URL}/{self.workspace}/{self.project}/{self.version}\"\n                )\n                print(\n                    f\"Share your model with the world at: {UNIVERSE_URL}/{self.workspace}/{self.project}/model/{self.version}\"\n                )\n            else:\n                print(\n                    f\"View the status of your deployment at: {APP_URL}/{self.workspace}/{self.project}/{self.version}\"\n                )\n\n        except Exception as e:\n            print(f\"An error occured when uploading the model: {e}\")\n\n    def __download_zip(self, link, location, format):\n\"\"\"\n        Download a dataset's zip file from the given URL and save it in the desired location\n\n        Args:\n            link (str): link the URL of the remote zip file\n            location (str): filepath of the data directory to save the zip file to\n            format (str): the format identifier string\n        \"\"\"\n        if not os.path.exists(location):\n            os.makedirs(location)\n\n        def bar_progress(current, total, width=80):\n            progress_message = (\n                \"Downloading Dataset Version Zip in \"\n                + location\n                + \" to \"\n                + format\n                + \": %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n            )\n            sys.stdout.write(\"\\r\" + progress_message)\n            sys.stdout.flush()\n\n        try:\n            wget.download(link, out=location + \"/roboflow.zip\", bar=bar_progress)\n        except Exception as e:\n            print(f\"Error when trying to download dataset @ {link}\")\n            raise e\n        sys.stdout.write(\"\\n\")\n        sys.stdout.flush()\n\n    def __extract_zip(self, location, format):\n\"\"\"\n        Extracts the contents of a downloaded ZIP file and then deletes the zipped file.\n\n        Args:\n            location (str): filepath of the data directory that contains the ZIP file\n            format (str): the format identifier string\n\n        Raises:\n            RuntimeError: If there is an error unzipping the file\n        \"\"\"\n        with zipfile.ZipFile(location + \"/roboflow.zip\", \"r\") as zip_ref:\n            for member in tqdm(\n                zip_ref.infolist(),\n                desc=f\"Extracting Dataset Version Zip to {location} in {format}:\",\n            ):\n                try:\n                    zip_ref.extract(member, location)\n                except zipfile.error:\n                    raise RuntimeError(\"Error unzipping download\")\n\n        os.remove(location + \"/roboflow.zip\")\n\n    def __get_download_location(self):\n\"\"\"\n        Get the local path to save a downloaded dataset to\n\n        Returns:\n            str: the local path\n        \"\"\"\n        version_slug = self.name.replace(\" \", \"-\")\n        filename = f\"{version_slug}-{self.version}\"\n\n        directory = os.environ.get(\"DATASET_DIRECTORY\")\n        if directory:\n            return f\"{directory}/{filename}\"\n\n        return filename\n\n    def __get_download_url(self, format):\n\"\"\"\n        Get the Roboflow API URL for downloading (and exporting downloadable zips)\n\n        Args:\n            format (str): the format identifier string\n\n        Returns:\n            str: the Roboflow API URL\n        \"\"\"\n        workspace, project, *_ = self.id.rsplit(\"/\")\n        return f\"{API_URL}/{workspace}/{project}/{self.version}/{format}\"\n\n    def __get_format_identifier(self, format):\n\"\"\"\n        If `format` is none, fall back to the instance's `model_format` value.\n\n        If a human readable format name was passed, return the identifier that should be used for Roboflow API calls\n\n        Otherwise, assume that the passed in format is also the identifier\n\n        Args:\n            format (str): a human readable format string\n\n        Returns:\n            str: format identifier string\n        \"\"\"\n        if not format:\n            format = self.model_format\n\n        if not format:\n            raise RuntimeError(\n                \"You must pass a format argument to version.download() or define a model in your Roboflow object\"\n            )\n\n        friendly_formats = {\"yolov5\": \"yolov5pytorch\", \"yolov7\": \"yolov7pytorch\"}\n\n        return friendly_formats.get(format, format)\n\n    def __reformat_yaml(self, location: str, format: str):\n\"\"\"\n        Certain formats seem to require reformatting the downloaded YAML.\n\n        Args:\n            location (str): filepath of the data directory that contains the yaml file\n            format (str): the format identifier string\n        \"\"\"\n        data_path = os.path.join(location, \"data.yaml\")\n\n        def data_yaml_callback(content: dict) -&gt; dict:\n            if format == \"mt-yolov6\":\n                content[\"train\"] = location + content[\"train\"].lstrip(\".\")\n                content[\"val\"] = location + content[\"val\"].lstrip(\".\")\n                content[\"test\"] = location + content[\"test\"].lstrip(\".\")\n            if format in [\"yolov5pytorch\", \"yolov7pytorch\", \"yolov8\"]:\n                content[\"train\"] = location + content[\"train\"].lstrip(\"..\")\n                content[\"val\"] = location + content[\"val\"].lstrip(\"..\")\n            try:\n                # get_wrong_dependencies_versions raises exception if ultralytics is not installed at all\n                if format == \"yolov8\" and not get_wrong_dependencies_versions(\n                    dependencies_versions=[(\"ultralytics\", \"==\", \"8.0.134\")]\n                ):\n                    content[\"train\"] = \"train/images\"\n                    content[\"val\"] = \"valid/images\"\n                    content[\"test\"] = \"test/images\"\n            except ModuleNotFoundError:\n                pass\n            return content\n\n        if format in [\"yolov5pytorch\", \"mt-yolov6\", \"yolov7pytorch\", \"yolov8\"]:\n            amend_data_yaml(path=data_path, callback=data_yaml_callback)\n\n    def __str__(self):\n\"\"\"\n        String representation of version object.\n        \"\"\"\n        json_value = {\n            \"name\": self.name,\n            \"type\": self.type,\n            \"version\": self.version,\n            \"augmentation\": self.augmentation,\n            \"created\": self.created,\n            \"preprocessing\": self.preprocessing,\n            \"splits\": self.splits,\n            \"workspace\": self.workspace,\n        }\n        return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__download_zip","title":"<code>__download_zip(link, location, format)</code>","text":"<p>Download a dataset's zip file from the given URL and save it in the desired location</p> <p>Parameters:</p> Name Type Description Default <code>link</code> <code>str</code> <p>link the URL of the remote zip file</p> required <code>location</code> <code>str</code> <p>filepath of the data directory to save the zip file to</p> required <code>format</code> <code>str</code> <p>the format identifier string</p> required Source code in <code>roboflow/core/version.py</code> <pre><code>def __download_zip(self, link, location, format):\n\"\"\"\n    Download a dataset's zip file from the given URL and save it in the desired location\n\n    Args:\n        link (str): link the URL of the remote zip file\n        location (str): filepath of the data directory to save the zip file to\n        format (str): the format identifier string\n    \"\"\"\n    if not os.path.exists(location):\n        os.makedirs(location)\n\n    def bar_progress(current, total, width=80):\n        progress_message = (\n            \"Downloading Dataset Version Zip in \"\n            + location\n            + \" to \"\n            + format\n            + \": %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n        )\n        sys.stdout.write(\"\\r\" + progress_message)\n        sys.stdout.flush()\n\n    try:\n        wget.download(link, out=location + \"/roboflow.zip\", bar=bar_progress)\n    except Exception as e:\n        print(f\"Error when trying to download dataset @ {link}\")\n        raise e\n    sys.stdout.write(\"\\n\")\n    sys.stdout.flush()\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__extract_zip","title":"<code>__extract_zip(location, format)</code>","text":"<p>Extracts the contents of a downloaded ZIP file and then deletes the zipped file.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>filepath of the data directory that contains the ZIP file</p> required <code>format</code> <code>str</code> <p>the format identifier string</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If there is an error unzipping the file</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __extract_zip(self, location, format):\n\"\"\"\n    Extracts the contents of a downloaded ZIP file and then deletes the zipped file.\n\n    Args:\n        location (str): filepath of the data directory that contains the ZIP file\n        format (str): the format identifier string\n\n    Raises:\n        RuntimeError: If there is an error unzipping the file\n    \"\"\"\n    with zipfile.ZipFile(location + \"/roboflow.zip\", \"r\") as zip_ref:\n        for member in tqdm(\n            zip_ref.infolist(),\n            desc=f\"Extracting Dataset Version Zip to {location} in {format}:\",\n        ):\n            try:\n                zip_ref.extract(member, location)\n            except zipfile.error:\n                raise RuntimeError(\"Error unzipping download\")\n\n    os.remove(location + \"/roboflow.zip\")\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__get_download_location","title":"<code>__get_download_location()</code>","text":"<p>Get the local path to save a downloaded dataset to</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the local path</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __get_download_location(self):\n\"\"\"\n    Get the local path to save a downloaded dataset to\n\n    Returns:\n        str: the local path\n    \"\"\"\n    version_slug = self.name.replace(\" \", \"-\")\n    filename = f\"{version_slug}-{self.version}\"\n\n    directory = os.environ.get(\"DATASET_DIRECTORY\")\n    if directory:\n        return f\"{directory}/{filename}\"\n\n    return filename\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__get_download_url","title":"<code>__get_download_url(format)</code>","text":"<p>Get the Roboflow API URL for downloading (and exporting downloadable zips)</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>the format identifier string</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>the Roboflow API URL</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __get_download_url(self, format):\n\"\"\"\n    Get the Roboflow API URL for downloading (and exporting downloadable zips)\n\n    Args:\n        format (str): the format identifier string\n\n    Returns:\n        str: the Roboflow API URL\n    \"\"\"\n    workspace, project, *_ = self.id.rsplit(\"/\")\n    return f\"{API_URL}/{workspace}/{project}/{self.version}/{format}\"\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__get_format_identifier","title":"<code>__get_format_identifier(format)</code>","text":"<p>If <code>format</code> is none, fall back to the instance's <code>model_format</code> value.</p> <p>If a human readable format name was passed, return the identifier that should be used for Roboflow API calls</p> <p>Otherwise, assume that the passed in format is also the identifier</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>a human readable format string</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>format identifier string</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __get_format_identifier(self, format):\n\"\"\"\n    If `format` is none, fall back to the instance's `model_format` value.\n\n    If a human readable format name was passed, return the identifier that should be used for Roboflow API calls\n\n    Otherwise, assume that the passed in format is also the identifier\n\n    Args:\n        format (str): a human readable format string\n\n    Returns:\n        str: format identifier string\n    \"\"\"\n    if not format:\n        format = self.model_format\n\n    if not format:\n        raise RuntimeError(\n            \"You must pass a format argument to version.download() or define a model in your Roboflow object\"\n        )\n\n    friendly_formats = {\"yolov5\": \"yolov5pytorch\", \"yolov7\": \"yolov7pytorch\"}\n\n    return friendly_formats.get(format, format)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__init__","title":"<code>__init__(version_dict, type, api_key, name, version, model_format, local, workspace, project, public, colors=None)</code>","text":"<p>Initialize a Version object.</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __init__(\n    self,\n    version_dict,\n    type,\n    api_key,\n    name,\n    version,\n    model_format,\n    local,\n    workspace,\n    project,\n    public,\n    colors=None,\n):\n\"\"\"\n    Initialize a Version object.\n    \"\"\"\n    if api_key in DEMO_KEYS:\n        if api_key == \"coco-128-sample\":\n            self.__api_key = api_key\n            self.model_format = model_format\n            self.name = \"coco-128\"\n            self.version = \"1\"\n        else:\n            self.__api_key = api_key\n            self.model_format = model_format\n            self.name = \"chess-pieces-new\"\n            self.version = \"23\"\n            self.id = \"joseph-nelson/chess-pieces-new\"\n    else:\n        self.__api_key = api_key\n        self.name = name\n\n        # FIXME: the version argument is inconsistently passed into this object.\n        # Sometimes it is passed as: test-workspace/test-project/2\n        # Other times, it is passed as: 2\n        self.version = version\n        self.type = type\n        self.augmentation = version_dict[\"augmentation\"]\n        self.created = version_dict[\"created\"]\n        self.id = version_dict[\"id\"]\n        self.images = version_dict[\"images\"]\n        self.preprocessing = version_dict[\"preprocessing\"]\n        self.splits = version_dict[\"splits\"]\n        self.model_format = model_format\n        self.workspace = workspace\n        self.project = project\n        self.public = public\n        self.colors = {} if colors is None else colors\n\n        self.colors = colors\n        if \"exports\" in version_dict.keys():\n            self.exports = version_dict[\"exports\"]\n        else:\n            self.exports = []\n\n        version_without_workspace = os.path.basename(str(version))\n\n        if self.type == TYPE_OBJECT_DETECTION:\n            self.model = ObjectDetectionModel(\n                self.__api_key,\n                self.id,\n                self.name,\n                version_without_workspace,\n                local=local,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n            )\n        elif self.type == TYPE_CLASSICATION:\n            self.model = ClassificationModel(\n                self.__api_key,\n                self.id,\n                self.name,\n                version_without_workspace,\n                local=local,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n            )\n        elif self.type == TYPE_INSTANCE_SEGMENTATION:\n            self.model = InstanceSegmentationModel(\n                self.__api_key,\n                self.id,\n                colors=self.colors,\n                preprocessing=self.preprocessing,\n                local=local,\n            )\n        elif self.type == TYPE_SEMANTIC_SEGMENTATION:\n            self.model = SemanticSegmentationModel(self.__api_key, self.id)\n        else:\n            self.model = None\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__reformat_yaml","title":"<code>__reformat_yaml(location, format)</code>","text":"<p>Certain formats seem to require reformatting the downloaded YAML.</p> <p>Parameters:</p> Name Type Description Default <code>location</code> <code>str</code> <p>filepath of the data directory that contains the yaml file</p> required <code>format</code> <code>str</code> <p>the format identifier string</p> required Source code in <code>roboflow/core/version.py</code> <pre><code>def __reformat_yaml(self, location: str, format: str):\n\"\"\"\n    Certain formats seem to require reformatting the downloaded YAML.\n\n    Args:\n        location (str): filepath of the data directory that contains the yaml file\n        format (str): the format identifier string\n    \"\"\"\n    data_path = os.path.join(location, \"data.yaml\")\n\n    def data_yaml_callback(content: dict) -&gt; dict:\n        if format == \"mt-yolov6\":\n            content[\"train\"] = location + content[\"train\"].lstrip(\".\")\n            content[\"val\"] = location + content[\"val\"].lstrip(\".\")\n            content[\"test\"] = location + content[\"test\"].lstrip(\".\")\n        if format in [\"yolov5pytorch\", \"yolov7pytorch\", \"yolov8\"]:\n            content[\"train\"] = location + content[\"train\"].lstrip(\"..\")\n            content[\"val\"] = location + content[\"val\"].lstrip(\"..\")\n        try:\n            # get_wrong_dependencies_versions raises exception if ultralytics is not installed at all\n            if format == \"yolov8\" and not get_wrong_dependencies_versions(\n                dependencies_versions=[(\"ultralytics\", \"==\", \"8.0.134\")]\n            ):\n                content[\"train\"] = \"train/images\"\n                content[\"val\"] = \"valid/images\"\n                content[\"test\"] = \"test/images\"\n        except ModuleNotFoundError:\n            pass\n        return content\n\n    if format in [\"yolov5pytorch\", \"mt-yolov6\", \"yolov7pytorch\", \"yolov8\"]:\n        amend_data_yaml(path=data_path, callback=data_yaml_callback)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.__str__","title":"<code>__str__()</code>","text":"<p>String representation of version object.</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def __str__(self):\n\"\"\"\n    String representation of version object.\n    \"\"\"\n    json_value = {\n        \"name\": self.name,\n        \"type\": self.type,\n        \"version\": self.version,\n        \"augmentation\": self.augmentation,\n        \"created\": self.created,\n        \"preprocessing\": self.preprocessing,\n        \"splits\": self.splits,\n        \"workspace\": self.workspace,\n    }\n    return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.deploy","title":"<code>deploy(model_type, model_path)</code>","text":"<p>Uploads provided weights file to Roboflow</p> <p>Parameters:</p> Name Type Description Default <code>model_path</code> <code>str</code> <p>File path to model weights to be uploaded</p> required Source code in <code>roboflow/core/version.py</code> <pre><code>def deploy(self, model_type: str, model_path: str) -&gt; None:\n\"\"\"Uploads provided weights file to Roboflow\n\n    Args:\n        model_path (str): File path to model weights to be uploaded\n    \"\"\"\n\n    supported_models = [\"yolov5\", \"yolov7-seg\", \"yolov8\"]\n\n    if not any(\n        supported_model in model_type for supported_model in supported_models\n    ):\n        raise (\n            ValueError(\n                f\"Model type {model_type} not supported. Supported models are {supported_models}\"\n            )\n        )\n\n    if \"yolov8\" in model_type:\n        try:\n            import torch\n            import ultralytics\n\n        except ImportError as e:\n            raise (\n                \"The ultralytics python package is required to deploy yolov8 models. Please install it with `pip install ultralytics`\"\n            )\n\n        print_warn_for_wrong_dependencies_versions(\n            [(\"ultralytics\", \"==\", \"8.0.134\")]\n        )\n\n    elif \"yolov5\" in model_type or \"yolov7\" in model_type:\n        try:\n            import torch\n        except ImportError as e:\n            raise (\n                \"The torch python package is required to deploy yolov5 models. Please install it with `pip install torch`\"\n            )\n\n    model = torch.load(os.path.join(model_path, \"weights/best.pt\"))\n\n    if isinstance(model[\"model\"].names, list):\n        class_names = model[\"model\"].names\n    else:\n        class_names = []\n        for i, val in enumerate(model[\"model\"].names):\n            class_names.append((val, model[\"model\"].names[val]))\n        class_names.sort(key=lambda x: x[0])\n        class_names = [x[1] for x in class_names]\n\n    if \"yolov8\" in model_type:\n        # try except for backwards compatibility with older versions of ultralytics\n        if \"-cls\" in model_type:\n            nc = model[\"model\"].yaml[\"nc\"]\n            args = model[\"train_args\"]\n        else:\n            nc = model[\"model\"].nc\n            args = model[\"model\"].args\n        try:\n            model_artifacts = {\n                \"names\": class_names,\n                \"yaml\": model[\"model\"].yaml,\n                \"nc\": nc,\n                \"args\": {\n                    k: val\n                    for k, val in args.items()\n                    if ((k == \"model\") or (k == \"imgsz\") or (k == \"batch\"))\n                },\n                \"ultralytics_version\": ultralytics.__version__,\n                \"model_type\": model_type,\n            }\n        except:\n            model_artifacts = {\n                \"names\": class_names,\n                \"yaml\": model[\"model\"].yaml,\n                \"nc\": nc,\n                \"args\": {\n                    k: val\n                    for k, val in args.__dict__.items()\n                    if ((k == \"model\") or (k == \"imgsz\") or (k == \"batch\"))\n                },\n                \"ultralytics_version\": ultralytics.__version__,\n                \"model_type\": model_type,\n            }\n    elif \"yolov5\" in model_type or \"yolov7\" in model_type:\n        # parse from yaml for yolov5\n\n        with open(os.path.join(model_path, \"opt.yaml\"), \"r\") as stream:\n            opts = yaml.safe_load(stream)\n\n        model_artifacts = {\n            \"names\": class_names,\n            \"nc\": model[\"model\"].nc,\n            \"args\": {\n                \"imgsz\": opts[\"imgsz\"] if \"imgsz\" in opts else opts[\"img_size\"],\n                \"batch\": opts[\"batch_size\"],\n            },\n            \"model_type\": model_type,\n        }\n        if hasattr(model[\"model\"], \"yaml\"):\n            model_artifacts[\"yaml\"] = model[\"model\"].yaml\n\n    with open(os.path.join(model_path, \"model_artifacts.json\"), \"w\") as fp:\n        json.dump(model_artifacts, fp)\n\n    torch.save(\n        model[\"model\"].state_dict(), os.path.join(model_path, \"state_dict.pt\")\n    )\n\n    lista_files = [\n        \"results.csv\",\n        \"results.png\",\n        \"model_artifacts.json\",\n        \"state_dict.pt\",\n    ]\n\n    with zipfile.ZipFile(\n        os.path.join(model_path, \"roboflow_deploy.zip\"), \"w\"\n    ) as zipMe:\n        for file in lista_files:\n            if os.path.exists(os.path.join(model_path, file)):\n                zipMe.write(\n                    os.path.join(model_path, file),\n                    arcname=file,\n                    compress_type=zipfile.ZIP_DEFLATED,\n                )\n            else:\n                if file in [\"model_artifacts.json\", \"state_dict.pt\"]:\n                    raise (\n                        ValueError(\n                            f\"File {file} not found. Please make sure to provide a valid model path.\"\n                        )\n                    )\n\n    res = requests.get(\n        f\"{API_URL}/{self.workspace}/{self.project}/{self.version}/uploadModel?api_key={self.__api_key}&amp;modelType={model_type}&amp;nocache=true\"\n    )\n    try:\n        if res.status_code == 429:\n            raise RuntimeError(\n                f\"This version already has a trained model. Please generate and train a new version in order to upload model to Roboflow.\"\n            )\n        else:\n            res.raise_for_status()\n    except Exception as e:\n        print(f\"An error occured when getting the model upload URL: {e}\")\n        return\n\n    res = requests.put(\n        res.json()[\"url\"],\n        data=open(os.path.join(model_path, \"roboflow_deploy.zip\"), \"rb\"),\n    )\n    try:\n        res.raise_for_status()\n\n        if self.public:\n            print(\n                f\"View the status of your deployment at: {APP_URL}/{self.workspace}/{self.project}/{self.version}\"\n            )\n            print(\n                f\"Share your model with the world at: {UNIVERSE_URL}/{self.workspace}/{self.project}/model/{self.version}\"\n            )\n        else:\n            print(\n                f\"View the status of your deployment at: {APP_URL}/{self.workspace}/{self.project}/{self.version}\"\n            )\n\n    except Exception as e:\n        print(f\"An error occured when uploading the model: {e}\")\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.download","title":"<code>download(model_format=None, location=None, overwrite=True)</code>","text":"<p>Download and extract a ZIP of a version's dataset in a given format</p> <p>:param model_format: A format to use for downloading :param location: An optional path for saving the file :param overwrite: An optional flag to prevent dataset overwrite when dataset is already downloaded</p> <p>Parameters:</p> Name Type Description Default <code>model_format</code> <code>str</code> <p>A format to use for downloading</p> <code>None</code> <code>location</code> <code>str</code> <p>An optional path for saving the file</p> <code>None</code> <code>overwrite</code> <code>bool</code> <p>An optional flag to prevent dataset overwrite when dataset is already downloaded</p> <code>True</code> <p>Returns:</p> Type Description <p>Dataset Object</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the Roboflow API returns an error with a helpful JSON body</p> <code>HTTPError</code> <p>If the Network/Roboflow API fails and does not return JSON</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def download(self, model_format=None, location=None, overwrite: bool = True):\n\"\"\"\n    Download and extract a ZIP of a version's dataset in a given format\n\n    :param model_format: A format to use for downloading\n    :param location: An optional path for saving the file\n    :param overwrite: An optional flag to prevent dataset overwrite when dataset is already downloaded\n\n    Args:\n        model_format (str): A format to use for downloading\n        location (str): An optional path for saving the file\n        overwrite (bool): An optional flag to prevent dataset overwrite when dataset is already downloaded\n\n    Returns:\n        Dataset Object\n\n    Raises:\n        RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n        HTTPError: If the Network/Roboflow API fails and does not return JSON\n    \"\"\"\n\n    self.__wait_if_generating()\n\n    if model_format == \"yolov8\":\n        # if ultralytics is installed, we will assume users will want to use yolov8 and we check for the supported version\n        try:\n            import_module(\"ultralytics\")\n            print_warn_for_wrong_dependencies_versions(\n                [(\"ultralytics\", \"==\", \"8.0.134\")]\n            )\n        except ImportError as e:\n            print(\n                \"[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.134`, to intall it `pip install ultralytics==8.0.134`.\"\n            )\n            # silently fail\n            pass\n\n    model_format = self.__get_format_identifier(model_format)\n\n    if model_format not in self.exports:\n        self.export(model_format)\n\n    # if model_format is not in\n\n    if location is None:\n        location = self.__get_download_location()\n    if os.path.exists(location) and not overwrite:\n        return Dataset(\n            self.name, self.version, model_format, os.path.abspath(location)\n        )\n\n    if self.__api_key == \"coco-128-sample\":\n        link = \"https://app.roboflow.com/ds/n9QwXwUK42?key=NnVCe2yMxP\"\n    else:\n        url = self.__get_download_url(model_format)\n        response = requests.get(url, params={\"api_key\": self.__api_key})\n        if response.status_code == 200:\n            link = response.json()[\"export\"][\"link\"]\n        else:\n            try:\n                raise RuntimeError(response.json())\n            except requests.exceptions.JSONDecodeError:\n                response.raise_for_status()\n\n    self.__download_zip(link, location, model_format)\n    self.__extract_zip(location, model_format)\n    self.__reformat_yaml(location, model_format)\n\n    return Dataset(self.name, self.version, model_format, os.path.abspath(location))\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.export","title":"<code>export(model_format=None)</code>","text":"<p>Ask the Roboflow API to generate a version's dataset in a given format so that it can be downloaded via the <code>download()</code> method.</p> <p>The export will be asynchronously generated and available for download after some amount of seconds - depending on dataset size.</p> <p>Parameters:</p> Name Type Description Default <code>model_format</code> <code>str</code> <p>A format to use for downloading</p> <code>None</code> <p>Returns:</p> Type Description <p>True</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the Roboflow API returns an error with a helpful JSON body</p> <code>HTTPError</code> <p>If the Network/Roboflow API fails and does not return JSON</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def export(self, model_format=None):\n\"\"\"\n    Ask the Roboflow API to generate a version's dataset in a given format so that it can be downloaded via the `download()` method.\n\n    The export will be asynchronously generated and available for download after some amount of seconds - depending on dataset size.\n\n    Args:\n        model_format (str): A format to use for downloading\n\n    Returns:\n        True\n\n    Raises:\n        RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n        HTTPError: If the Network/Roboflow API fails and does not return JSON\n    \"\"\"\n\n    model_format = self.__get_format_identifier(model_format)\n\n    self.__wait_if_generating()\n\n    url = self.__get_download_url(model_format)\n    response = requests.get(url, params={\"api_key\": self.__api_key})\n    if not response.ok:\n        try:\n            raise RuntimeError(response.json())\n        except requests.exceptions.JSONDecodeError:\n            response.raise_for_status()\n\n    # the rest api returns 202 if the export is still in progress\n    if response.status_code == 202:\n        status_code_check = 202\n        while status_code_check == 202:\n            time.sleep(1)\n            response = requests.get(url, params={\"api_key\": self.__api_key})\n            status_code_check = response.status_code\n            if status_code_check == 202:\n                progress = response.json()[\"progress\"]\n                progress_message = (\n                    \"Exporting format \"\n                    + model_format\n                    + \" in progress : \"\n                    + str(round(progress * 100, 2))\n                    + \"%\"\n                )\n                sys.stdout.write(\"\\r\" + progress_message)\n                sys.stdout.flush()\n\n    if response.status_code == 200:\n        sys.stdout.write(\"\\n\")\n        print(\"\\r\" + \"Version export complete for \" + model_format + \" format\")\n        sys.stdout.flush()\n        return True\n    else:\n        try:\n            raise RuntimeError(response.json())\n        except requests.exceptions.JSONDecodeError:\n            response.raise_for_status()\n</code></pre>"},{"location":"core/version/#roboflow.core.version.Version.train","title":"<code>train(speed=None, checkpoint=None, plot_in_notebook=False)</code>","text":"<p>Ask the Roboflow API to train a previously exported version's dataset.</p> <p>Parameters:</p> Name Type Description Default <code>speed</code> <p>Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is <code>fast</code>.</p> <code>None</code> <code>checkpoint</code> <p>A string representing the checkpoint to use while training</p> <code>None</code> <code>plot</code> <p>Whether to plot the training results. Default is <code>False</code>.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>An instance of the trained model class</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the Roboflow API returns an error with a helpful JSON body</p> <code>HTTPError</code> <p>If the Network/Roboflow API fails and does not return JSON</p> Source code in <code>roboflow/core/version.py</code> <pre><code>def train(self, speed=None, checkpoint=None, plot_in_notebook=False) -&gt; bool:\n\"\"\"\n    Ask the Roboflow API to train a previously exported version's dataset.\n\n    Args:\n        speed: Whether to train quickly or accurately. Note: accurate training is a paid feature. Default speed is `fast`.\n        checkpoint: A string representing the checkpoint to use while training\n        plot: Whether to plot the training results. Default is `False`.\n\n    Returns:\n        An instance of the trained model class\n\n    Raises:\n        RuntimeError: If the Roboflow API returns an error with a helpful JSON body\n        HTTPError: If the Network/Roboflow API fails and does not return JSON\n    \"\"\"\n\n    self.__wait_if_generating()\n\n    train_model_format = \"yolov5pytorch\"\n\n    if self.type == TYPE_CLASSICATION:\n        train_model_format = \"folder\"\n\n    if self.type == TYPE_INSTANCE_SEGMENTATION:\n        train_model_format = \"yolov5pytorch\"\n\n    if self.type == TYPE_SEMANTIC_SEGMENTATION:\n        train_model_format = \"png-mask-semantic\"\n\n    # if classification\n    if train_model_format not in self.exports:\n        self.export(train_model_format)\n\n    workspace, project, *_ = self.id.rsplit(\"/\")\n    url = f\"{API_URL}/{workspace}/{project}/{self.version}/train\"\n\n    data = {}\n    if speed:\n        data[\"speed\"] = speed\n\n    if checkpoint:\n        data[\"checkpoint\"] = checkpoint\n\n    write_line(\"Reaching out to Roboflow to start training...\")\n\n    response = requests.post(url, json=data, params={\"api_key\": self.__api_key})\n    if not response.ok:\n        try:\n            raise RuntimeError(response.json())\n        except requests.exceptions.JSONDecodeError:\n            response.raise_for_status()\n\n    status = \"training\"\n\n    if plot_in_notebook:\n        import collections\n\n        from IPython.display import clear_output\n        from matplotlib import pyplot as plt\n\n        def live_plot(epochs, mAP, loss, title=\"\"):\n            clear_output(wait=True)\n\n            plt.subplot(2, 1, 1)\n            plt.plot(epochs, mAP, \"#00FFCE\")\n            plt.title(title)\n            plt.ylabel(\"mAP\")\n\n            plt.subplot(2, 1, 2)\n            plt.plot(epochs, loss, \"#A351FB\")\n            plt.xlabel(\"epochs\")\n            plt.ylabel(\"loss\")\n            plt.show()\n\n    first_graph_write = False\n    previous_epochs = []\n    num_machine_spin_dots = []\n\n    while status == \"training\" or status == \"running\":\n        url = (\n            f\"{API_URL}/{self.workspace}/{self.project}/{self.version}?nocache=true\"\n        )\n        response = requests.get(url, params={\"api_key\": self.__api_key})\n        response.raise_for_status()\n        version = response.json()[\"version\"]\n        if \"models\" in version.keys():\n            models = version[\"models\"]\n        else:\n            models = {}\n\n        if \"train\" in version.keys():\n            if \"results\" in version[\"train\"].keys():\n                status = \"finished\"\n                break\n            if \"status\" in version[\"train\"].keys():\n                if version[\"train\"][\"status\"] == \"failed\":\n                    write_line(line=\"Training failed\")\n                    break\n\n        if \"roboflow-train\" in models.keys():\n            # training has started\n            epochs = np.array(\n                [\n                    int(epoch[\"epoch\"])\n                    for epoch in models[\"roboflow-train\"][\"epochs\"]\n                ]\n            )\n            mAP = np.array(\n                [\n                    float(epoch[\"mAP\"])\n                    for epoch in models[\"roboflow-train\"][\"epochs\"]\n                ]\n            )\n            loss = np.array(\n                [\n                    (\n                        float(epoch[\"box_loss\"])\n                        + float(epoch[\"class_loss\"])\n                        + float(epoch[\"obj_loss\"])\n                    )\n                    for epoch in models[\"roboflow-train\"][\"epochs\"]\n                ]\n            )\n\n            title = \"Training in Progress\"\n            # plottling logic\n        else:\n            num_machine_spin_dots.append(\".\")\n            if len(num_machine_spin_dots) &gt; 5:\n                num_machine_spin_dots = [\".\"]\n            title = \"Training Machine Spinning Up\" + \"\".join(num_machine_spin_dots)\n\n            epochs = []\n            mAP = []\n            loss = []\n\n        if (len(epochs) &gt; len(previous_epochs)) or (len(epochs) == 0):\n            if plot_in_notebook:\n                live_plot(epochs, mAP, loss, title)\n            else:\n                if len(epochs) &gt; 0:\n                    title = (\n                        title\n                        + \": Epoch: \"\n                        + str(epochs[-1])\n                        + \" mAP: \"\n                        + str(mAP[-1])\n                        + \" loss: \"\n                        + str(loss[-1])\n                    )\n                if not first_graph_write:\n                    write_line(title)\n                    first_graph_write = True\n\n        previous_epochs = copy.deepcopy(epochs)\n\n        time.sleep(5)\n\n    # return the model object\n    return self.model\n</code></pre>"},{"location":"core/workspace/","title":"Workspaces","text":""},{"location":"core/workspace/#roboflow.core.workspace.Workspace","title":"<code>Workspace</code>","text":"<p>Manage a Roboflow workspace.</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>class Workspace:\n\"\"\"\n    Manage a Roboflow workspace.\n    \"\"\"\n\n    def __init__(self, info, api_key, default_workspace, model_format):\n        if api_key in DEMO_KEYS:\n            self.__api_key = api_key\n            self.model_format = model_format\n            self.project_list = []\n        else:\n            workspace_info = info[\"workspace\"]\n            self.name = workspace_info[\"name\"]\n            self.project_list = workspace_info[\"projects\"]\n            if \"members\" in workspace_info.keys():\n                self.members = workspace_info[\"members\"]\n            self.url = workspace_info[\"url\"]\n            self.model_format = model_format\n\n            self.__api_key = api_key\n\n    def list_projects(self):\n\"\"\"\n        Print all projects in the workspace to the console.\n        \"\"\"\n        print(self.project_list)\n\n    def projects(self):\n\"\"\"\n        Retrieve all projects in the workspace.\n\n        Returns:\n            List of Project objects.\n        \"\"\"\n        projects_array = []\n        for a_project in self.project_list:\n            proj = Project(self.__api_key, a_project, self.model_format)\n            projects_array.append(proj.id)\n\n        return projects_array\n\n    def project(self, project_name):\n\"\"\"\n        Retrieve a Project() object that represents a project in the workspace.\n\n        This object can be used to retrieve the model through which to run inference.\n\n        Args:\n            project_name (str): name of the project\n\n        Returns:\n            Project Object\n        \"\"\"\n        sys.stdout.write(\"\\r\" + \"loading Roboflow project...\")\n        sys.stdout.write(\"\\n\")\n        sys.stdout.flush()\n\n        if self.__api_key in DEMO_KEYS:\n            return Project(self.__api_key, {}, self.model_format)\n\n        project_name = project_name.replace(self.url + \"/\", \"\")\n\n        if \"/\" in project_name:\n            raise RuntimeError(\n                \"The {} project is not available in this ({}) workspace\".format(\n                    project_name, self.url\n                )\n            )\n\n        dataset_info = requests.get(\n            API_URL + \"/\" + self.url + \"/\" + project_name + \"?api_key=\" + self.__api_key\n        )\n\n        # Throw error if dataset isn't valid/user doesn't have permissions to access the dataset\n        if dataset_info.status_code != 200:\n            raise RuntimeError(dataset_info.text)\n\n        dataset_info = dataset_info.json()[\"project\"]\n\n        return Project(self.__api_key, dataset_info, self.model_format)\n\n    def create_project(self, project_name, project_type, project_license, annotation):\n\"\"\"\n        Create a project in a Roboflow workspace.\n\n        Args:\n            project_name (str): name of the project\n            project_type (str): type of the project\n            project_license (str): license of the project (set to `private` for private projects, only available for paid customers)\n            annotation (str): annotation of the project\n\n        Returns:\n            Project Object\n        \"\"\"\n        data = {\n            \"name\": project_name,\n            \"type\": project_type,\n            \"license\": project_license,\n            \"annotation\": annotation,\n        }\n\n        r = requests.post(\n            API_URL + \"/\" + self.url + \"/projects?api_key=\" + self.__api_key, json=data\n        )\n\n        r.raise_for_status()\n\n        if \"error\" in r.json().keys():\n            raise RuntimeError(r.json()[\"error\"])\n\n        return self.project(r.json()[\"id\"].split(\"/\")[-1])\n\n    def clip_compare(\n        self, dir: str = \"\", image_ext: str = \".png\", target_image: str = \"\"\n    ) -&gt; dict:\n\"\"\"\n        Compare all images in a directory to a target image using CLIP\n\n        Args:\n            dir (str): name reference to a directory of images for comparison\n            image_ext (str): file format for expected images (don't include the . before the file type name)\n            target_image (str): name reference for target image to compare individual images from directory against\n\n        Returns:\n            dict: a key:value mapping of image_name:comparison_score_to_target\n        \"\"\"\n\n        # list to store comparison results in\n        comparisons = []\n        # grab all images in a given directory with ext type\n        for image in glob.glob(f\"./{dir}/*{image_ext}\"):\n            # compare image\n            similarity = clip_encode(image, target_image)\n            # map image name to similarity score\n            comparisons.append({image: similarity})\n            comparisons = sorted(comparisons, key=lambda item: -list(item.values())[0])\n        return comparisons\n\n    def two_stage(\n        self,\n        image: str = \"\",\n        first_stage_model_name: str = \"\",\n        first_stage_model_version: int = 0,\n        second_stage_model_name: str = \"\",\n        second_stage_model_version: int = 0,\n    ) -&gt; dict:\n\"\"\"\n        For each prediction in a first stage detection, perform detection with the second stage model\n\n        Args:\n            image (str): name of the image to be processed\n            first_stage_model_name (str): name of the first stage detection model\n            first_stage_model_version (int): version number for the first stage model\n            second_stage_mode (str): name of the second stage detection model\n            second_stage_model_version (int): version number for the second stage model\n\n        Returns:\n            dict: a json obj containing the results of the second stage detection\n        \"\"\"\n        results = []\n\n        # create PIL image for cropping\n        pil_image = Image.open(image).convert(\"RGB\")\n\n        # grab first and second stage model from project\n        stage_one_project = self.project(first_stage_model_name)\n        stage_one_model = stage_one_project.version(first_stage_model_version).model\n        stage_two_project = self.project(second_stage_model_name)\n        stage_two_model = stage_two_project.version(second_stage_model_version).model\n\n        print(self.project(first_stage_model_name))\n\n        # perform first inference\n        predictions = stage_one_model.predict(image)\n\n        if (\n            stage_one_project.type == \"object-detection\"\n            and stage_two_project == \"classification\"\n        ):\n            # interact with each detected object from stage one inference results\n            for boundingbox in predictions:\n                # rip bounding box coordinates from json1\n                # note: infer returns center points of box as (x,y) and width, height\n                # ----- but pillow crop requires the top left and bottom right points to crop\n                box = (\n                    boundingbox[\"x\"] - boundingbox[\"width\"] / 2,\n                    boundingbox[\"y\"] - boundingbox[\"height\"] / 2,\n                    boundingbox[\"x\"] + boundingbox[\"width\"] / 2,\n                    boundingbox[\"y\"] + boundingbox[\"height\"] / 2,\n                )\n\n                # create a new cropped image using the first stage prediction coordinates (for each box!)\n                croppedImg = pil_image.crop(box)\n                croppedImg.save(\"./temp.png\")\n\n                # capture results of second stage inference from cropped image\n                results.append(stage_two_model.predict(\"./temp.png\")[0])\n\n            # delete the written image artifact\n            try:\n                os.remove(\"./temp.png\")\n            except FileNotFoundError:\n                print(\"no detections\")\n\n        else:\n            print(\n                \"please use an object detection model for the first stage--can only perform two stage with bounding box results\",\n                \"please use a classification model for the second stage\",\n            )\n\n        return results\n\n    def two_stage_ocr(\n        self,\n        image: str = \"\",\n        first_stage_model_name: str = \"\",\n        first_stage_model_version: int = 0,\n    ) -&gt; dict:\n\"\"\"\n        For each prediction in the first stage object detection, perform OCR as second stage.\n\n        Args:\n            image (str): name of the image to be processed\n            first_stage_model_name (str): name of the first stage detection model\n            first_stage_model_version (int): version number for the first stage model\n\n        Returns:\n            dict: a json obj containing the results of the second stage detection\n        \"\"\"\n        results = []\n\n        # create PIL image for cropping\n        pil_image = Image.open(image).convert(\"RGB\")\n\n        # grab first and second stage model from project\n        stage_one_project = self.project(first_stage_model_name)\n        stage_one_model = stage_one_project.version(first_stage_model_version).model\n\n        # perform first inference\n        predictions = stage_one_model.predict(image)\n\n        # interact with each detected object from stage one inference results\n        if stage_one_project.type == \"object-detection\":\n            for boundingbox in predictions:\n                # rip bounding box coordinates from json1\n                # note: infer returns center points of box as (x,y) and width, height\n                # ----- but pillow crop requires the top left and bottom right points to crop\n                box = (\n                    boundingbox[\"x\"] - boundingbox[\"width\"] / 2,\n                    boundingbox[\"y\"] - boundingbox[\"height\"] / 2,\n                    boundingbox[\"x\"] + boundingbox[\"width\"] / 2,\n                    boundingbox[\"y\"] + boundingbox[\"height\"] / 2,\n                )\n\n                # create a new cropped image using the first stage prediction coordinates (for each box!)\n                croppedImg = pil_image.crop(box)\n\n                # capture OCR results from cropped image\n                results.append(ocr_infer(croppedImg)[\"results\"])\n        else:\n            print(\n                \"please use an object detection model--can only perform two stage with bounding box results\"\n            )\n\n        return results\n\n    def upload_dataset(\n        self,\n        dataset_path: str,\n        project_name: str,\n        num_workers: int = 10,\n        dataset_format: str = \"yolov8\",\n        project_license: str = \"MIT\",\n        project_type: str = \"object-detection\",\n    ):\n\"\"\"\n        Upload a dataset to Roboflow.\n\n        Args:\n            dataset_path (str): path to the dataset\n            project_name (str): name of the project\n            num_workers (int): number of workers to use for parallel uploads\n            dataset_format (str): format of the dataset (`voc`, `yolov8`, `yolov5`)\n            project_license (str): license of the project (set to `private` for private projects, only available for paid customers)\n            project_type (str): type of the project (only `object-detection` is supported)\n        \"\"\"\n        if project_type != \"object-detection\":\n            raise (\"upload_dataset only supported for object-detection projects\")\n\n        if dataset_format not in [\"voc\", \"yolov8\", \"yolov5\"]:\n            raise (\n                \"dataset_format not supported - please use voc, yolov8, yolov5. PS, you can always convert your dataset in the Roboflow UI\"\n            )\n\n        # check type stuff and convert\n        if dataset_format == \"yolov8\" or dataset_format == \"yolov5\":\n            # convert to voc\n            for split in [\"train\", \"valid\", \"test\"]:\n                dataset = sv.DetectionDataset.from_yolo(\n                    images_directory_path=dataset_path + \"/\" + split + \"/images\",\n                    annotations_directory_path=dataset_path + \"/\" + split + \"/labels\",\n                    data_yaml_path=dataset_path + \"/data.yaml\",\n                )\n\n                dataset.as_pascal_voc(\n                    images_directory_path=dataset_path + \"_voc\" + \"/\" + split,\n                    annotations_directory_path=dataset_path + \"_voc\" + \"/\" + split,\n                )\n\n            dataset_path = dataset_path + \"_voc\"\n\n        if project_name in [p[\"name\"] for p in self.project_list]:\n            dataset_upload_project = self.project(project_name)\n            print(f\"Uploading to existing project {dataset_upload_project.id}\")\n        else:\n            dataset_upload_project = self.create_project(\n                project_name,\n                project_license=project_license,\n                annotation=project_name,\n                project_type=project_type,\n            )\n            print(f\"Created project {dataset_upload_project.id}\")\n\n        def upload_file(img_file: str, split: str):\n\"\"\"\n            Upload an image or annotation to a project.\n\n            Args:\n                img_file (str): path to the image\n                split (str): split to which the the image should be added (train, valid, test)\n            \"\"\"\n            label_file = img_file.replace(\".jpg\", \".xml\")\n            dataset_upload_project.upload(\n                image_path=img_file, annotation_path=label_file, split=split\n            )\n\n        def parallel_upload(file_list, split):\n            with concurrent.futures.ThreadPoolExecutor(\n                max_workers=num_workers\n            ) as executor:\n                list(\n                    tqdm(\n                        executor.map(upload_file, file_list, [split] * len(file_list)),\n                        total=len(file_list),\n                        file=sys.stdout,\n                    )\n                )\n\n        write_line(\"uploading training set...\")\n        file_list = glob.glob(dataset_path + \"/train/*.jpg\")\n        parallel_upload(file_list, \"train\")\n\n        write_line(\"uploading validation set...\")\n        file_list = glob.glob(dataset_path + \"/valid/*.jpg\")\n        parallel_upload(file_list, \"valid\")\n\n        write_line(\"uploading test set...\")\n        file_list = glob.glob(dataset_path + \"/test/*.jpg\")\n        parallel_upload(file_list, \"test\")\n\n    def active_learning(\n        self,\n        raw_data_location: str = \"\",\n        raw_data_extension: str = \"\",\n        inference_endpoint: list = [],\n        upload_destination: str = \"\",\n        conditionals: dict = {},\n        use_localhost: bool = False,\n    ) -&gt; str:\n\"\"\"perform inference on each image in directory and upload based on conditions\n        @params:\n            raw_data_location: (str) = folder of frames to be processed\n            raw_data_extension: (str) = extension of frames to be processed\n            inference_endpoint: (List[str, int]) = name of the project\n            upload_destination: (str) = name of the upload project\n            conditionals: (dict) = dictionary of upload conditions\n            use_localhost: (bool) = determines if local http format used or remote endpoint\n        \"\"\"\n        prediction_results = []\n\n        # ensure that all fields of conditionals have a key:value pair\n        conditionals[\"target_classes\"] = (\n            []\n            if \"target_classes\" not in conditionals\n            else conditionals[\"target_classes\"]\n        )\n        conditionals[\"confidence_interval\"] = (\n            [30, 99]\n            if \"confidence_interval\" not in conditionals\n            else conditionals[\"confidence_interval\"]\n        )\n        conditionals[\"required_class_variance_count\"] = (\n            1\n            if \"required_class_variance_count\" not in conditionals\n            else conditionals[\"required_class_variance_count\"]\n        )\n        conditionals[\"required_objects_count\"] = (\n            1\n            if \"required_objects_count\" not in conditionals\n            else conditionals[\"required_objects_count\"]\n        )\n        conditionals[\"required_class_count\"] = (\n            0\n            if \"required_class_count\" not in conditionals\n            else conditionals[\"required_class_count\"]\n        )\n        conditionals[\"minimum_size_requirement\"] = (\n            float(\"-inf\")\n            if \"minimum_size_requirement\" not in conditionals\n            else conditionals[\"minimum_size_requirement\"]\n        )\n        conditionals[\"maximum_size_requirement\"] = (\n            float(\"inf\")\n            if \"maximum_size_requirement\" not in conditionals\n            else conditionals[\"maximum_size_requirement\"]\n        )\n\n        # check if inference_model references endpoint or local\n        local = \"http://localhost:9001/\" if use_localhost else None\n\n        inference_model = (\n            self.project(inference_endpoint[0])\n            .version(version_number=inference_endpoint[1], local=local)\n            .model\n        )\n        upload_project = self.project(upload_destination)\n\n        print(\"inference reference point: \", inference_model)\n        print(\"upload destination: \", upload_project)\n\n        # check if raw data type is cv2 frame\n        if type(raw_data_location is type(ndarray)):\n            globbed_files = [raw_data_location]\n        else:\n            globbed_files = glob.glob(raw_data_location + \"/*\" + raw_data_extension)\n\n        image1 = globbed_files[0]\n        similarity_timeout_counter = 0\n\n        for index, image in enumerate(globbed_files):\n            try:\n                print(\n                    \"*** Processing image [\"\n                    + str(index + 1)\n                    + \"/\"\n                    + str(len(globbed_files))\n                    + \"] - \"\n                    + image\n                    + \" ***\"\n                )\n            except:\n                pass\n\n            if \"similarity_confidence_threshold\" in conditionals.keys():\n                image2 = image\n                # measure the similarity of two images using CLIP (hits an endpoint hosted by Roboflow)\n                similarity = clip_encode(image1, image2, CLIP_FEATURIZE_URL)\n                similarity_timeout_counter += 1\n\n                if (\n                    similarity &lt;= conditionals[\"similarity_confidence_threshold\"]\n                    or similarity_timeout_counter\n                    == conditionals[\"similarity_timeout_limit\"]\n                ):\n                    image1 = image\n                    similarity_timeout_counter = 0\n                else:\n                    print(image2 + \" --&gt; similarity too high to --&gt; \" + image1)\n                    continue  # skip this image if too similar or counter hits limit\n\n            predictions = inference_model.predict(image).json()[\"predictions\"]\n            # collect all predictions to return to user at end\n            prediction_results.append({\"image\": image, \"predictions\": predictions})\n\n            # compare object and class count of predictions if enabled, continue if not enough occurances\n            if not count_comparisons(\n                predictions,\n                conditionals[\"required_objects_count\"],\n                conditionals[\"required_class_count\"],\n                conditionals[\"target_classes\"],\n            ):\n                print(\" [X] image failed count cases\")\n                continue\n\n            # iterate through all predictions\n            for i, prediction in enumerate(predictions):\n                print(i)\n\n                # check if box size of detection fits requirements\n                if not check_box_size(\n                    prediction,\n                    conditionals[\"minimum_size_requirement\"],\n                    conditionals[\"maximum_size_requirement\"],\n                ):\n                    print(\" [X] prediction failed box size cases\")\n                    continue\n\n                # compare confidence of detected object to confidence thresholds\n                # confidence comes in as a .XXX instead of XXX%\n                if (\n                    prediction[\"confidence\"] * 100\n                    &gt;= conditionals[\"confidence_interval\"][0]\n                    and prediction[\"confidence\"] * 100\n                    &lt;= conditionals[\"confidence_interval\"][1]\n                ):\n                    # filter out non-target_class uploads if enabled\n                    if (\n                        len(conditionals[\"target_classes\"]) &gt; 0\n                        and prediction[\"class\"] not in conditionals[\"target_classes\"]\n                    ):\n                        print(\" [X] prediction failed target_classes\")\n                        continue\n\n                    # upload on success!\n                    print(\" &gt;&gt; image uploaded!\")\n                    upload_project.upload(image, num_retry_uploads=3)\n                    break\n\n        # return predictions with filenames if globbed images from dir, otherwise return latest prediction result\n        return (\n            prediction_results\n            if type(raw_data_location) is not ndarray\n            else prediction_results[-1][\"predictions\"]\n        )\n\n    def __str__(self):\n        projects = self.projects()\n        json_value = {\"name\": self.name, \"url\": self.url, \"projects\": projects}\n\n        return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.active_learning","title":"<code>active_learning(raw_data_location='', raw_data_extension='', inference_endpoint=[], upload_destination='', conditionals={}, use_localhost=False)</code>","text":"<p>perform inference on each image in directory and upload based on conditions @params:     raw_data_location: (str) = folder of frames to be processed     raw_data_extension: (str) = extension of frames to be processed     inference_endpoint: (List[str, int]) = name of the project     upload_destination: (str) = name of the upload project     conditionals: (dict) = dictionary of upload conditions     use_localhost: (bool) = determines if local http format used or remote endpoint</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def active_learning(\n    self,\n    raw_data_location: str = \"\",\n    raw_data_extension: str = \"\",\n    inference_endpoint: list = [],\n    upload_destination: str = \"\",\n    conditionals: dict = {},\n    use_localhost: bool = False,\n) -&gt; str:\n\"\"\"perform inference on each image in directory and upload based on conditions\n    @params:\n        raw_data_location: (str) = folder of frames to be processed\n        raw_data_extension: (str) = extension of frames to be processed\n        inference_endpoint: (List[str, int]) = name of the project\n        upload_destination: (str) = name of the upload project\n        conditionals: (dict) = dictionary of upload conditions\n        use_localhost: (bool) = determines if local http format used or remote endpoint\n    \"\"\"\n    prediction_results = []\n\n    # ensure that all fields of conditionals have a key:value pair\n    conditionals[\"target_classes\"] = (\n        []\n        if \"target_classes\" not in conditionals\n        else conditionals[\"target_classes\"]\n    )\n    conditionals[\"confidence_interval\"] = (\n        [30, 99]\n        if \"confidence_interval\" not in conditionals\n        else conditionals[\"confidence_interval\"]\n    )\n    conditionals[\"required_class_variance_count\"] = (\n        1\n        if \"required_class_variance_count\" not in conditionals\n        else conditionals[\"required_class_variance_count\"]\n    )\n    conditionals[\"required_objects_count\"] = (\n        1\n        if \"required_objects_count\" not in conditionals\n        else conditionals[\"required_objects_count\"]\n    )\n    conditionals[\"required_class_count\"] = (\n        0\n        if \"required_class_count\" not in conditionals\n        else conditionals[\"required_class_count\"]\n    )\n    conditionals[\"minimum_size_requirement\"] = (\n        float(\"-inf\")\n        if \"minimum_size_requirement\" not in conditionals\n        else conditionals[\"minimum_size_requirement\"]\n    )\n    conditionals[\"maximum_size_requirement\"] = (\n        float(\"inf\")\n        if \"maximum_size_requirement\" not in conditionals\n        else conditionals[\"maximum_size_requirement\"]\n    )\n\n    # check if inference_model references endpoint or local\n    local = \"http://localhost:9001/\" if use_localhost else None\n\n    inference_model = (\n        self.project(inference_endpoint[0])\n        .version(version_number=inference_endpoint[1], local=local)\n        .model\n    )\n    upload_project = self.project(upload_destination)\n\n    print(\"inference reference point: \", inference_model)\n    print(\"upload destination: \", upload_project)\n\n    # check if raw data type is cv2 frame\n    if type(raw_data_location is type(ndarray)):\n        globbed_files = [raw_data_location]\n    else:\n        globbed_files = glob.glob(raw_data_location + \"/*\" + raw_data_extension)\n\n    image1 = globbed_files[0]\n    similarity_timeout_counter = 0\n\n    for index, image in enumerate(globbed_files):\n        try:\n            print(\n                \"*** Processing image [\"\n                + str(index + 1)\n                + \"/\"\n                + str(len(globbed_files))\n                + \"] - \"\n                + image\n                + \" ***\"\n            )\n        except:\n            pass\n\n        if \"similarity_confidence_threshold\" in conditionals.keys():\n            image2 = image\n            # measure the similarity of two images using CLIP (hits an endpoint hosted by Roboflow)\n            similarity = clip_encode(image1, image2, CLIP_FEATURIZE_URL)\n            similarity_timeout_counter += 1\n\n            if (\n                similarity &lt;= conditionals[\"similarity_confidence_threshold\"]\n                or similarity_timeout_counter\n                == conditionals[\"similarity_timeout_limit\"]\n            ):\n                image1 = image\n                similarity_timeout_counter = 0\n            else:\n                print(image2 + \" --&gt; similarity too high to --&gt; \" + image1)\n                continue  # skip this image if too similar or counter hits limit\n\n        predictions = inference_model.predict(image).json()[\"predictions\"]\n        # collect all predictions to return to user at end\n        prediction_results.append({\"image\": image, \"predictions\": predictions})\n\n        # compare object and class count of predictions if enabled, continue if not enough occurances\n        if not count_comparisons(\n            predictions,\n            conditionals[\"required_objects_count\"],\n            conditionals[\"required_class_count\"],\n            conditionals[\"target_classes\"],\n        ):\n            print(\" [X] image failed count cases\")\n            continue\n\n        # iterate through all predictions\n        for i, prediction in enumerate(predictions):\n            print(i)\n\n            # check if box size of detection fits requirements\n            if not check_box_size(\n                prediction,\n                conditionals[\"minimum_size_requirement\"],\n                conditionals[\"maximum_size_requirement\"],\n            ):\n                print(\" [X] prediction failed box size cases\")\n                continue\n\n            # compare confidence of detected object to confidence thresholds\n            # confidence comes in as a .XXX instead of XXX%\n            if (\n                prediction[\"confidence\"] * 100\n                &gt;= conditionals[\"confidence_interval\"][0]\n                and prediction[\"confidence\"] * 100\n                &lt;= conditionals[\"confidence_interval\"][1]\n            ):\n                # filter out non-target_class uploads if enabled\n                if (\n                    len(conditionals[\"target_classes\"]) &gt; 0\n                    and prediction[\"class\"] not in conditionals[\"target_classes\"]\n                ):\n                    print(\" [X] prediction failed target_classes\")\n                    continue\n\n                # upload on success!\n                print(\" &gt;&gt; image uploaded!\")\n                upload_project.upload(image, num_retry_uploads=3)\n                break\n\n    # return predictions with filenames if globbed images from dir, otherwise return latest prediction result\n    return (\n        prediction_results\n        if type(raw_data_location) is not ndarray\n        else prediction_results[-1][\"predictions\"]\n    )\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.clip_compare","title":"<code>clip_compare(dir='', image_ext='.png', target_image='')</code>","text":"<p>Compare all images in a directory to a target image using CLIP</p> <p>Parameters:</p> Name Type Description Default <code>dir</code> <code>str</code> <p>name reference to a directory of images for comparison</p> <code>''</code> <code>image_ext</code> <code>str</code> <p>file format for expected images (don't include the . before the file type name)</p> <code>'.png'</code> <code>target_image</code> <code>str</code> <p>name reference for target image to compare individual images from directory against</p> <code>''</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>a key:value mapping of image_name:comparison_score_to_target</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def clip_compare(\n    self, dir: str = \"\", image_ext: str = \".png\", target_image: str = \"\"\n) -&gt; dict:\n\"\"\"\n    Compare all images in a directory to a target image using CLIP\n\n    Args:\n        dir (str): name reference to a directory of images for comparison\n        image_ext (str): file format for expected images (don't include the . before the file type name)\n        target_image (str): name reference for target image to compare individual images from directory against\n\n    Returns:\n        dict: a key:value mapping of image_name:comparison_score_to_target\n    \"\"\"\n\n    # list to store comparison results in\n    comparisons = []\n    # grab all images in a given directory with ext type\n    for image in glob.glob(f\"./{dir}/*{image_ext}\"):\n        # compare image\n        similarity = clip_encode(image, target_image)\n        # map image name to similarity score\n        comparisons.append({image: similarity})\n        comparisons = sorted(comparisons, key=lambda item: -list(item.values())[0])\n    return comparisons\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.create_project","title":"<code>create_project(project_name, project_type, project_license, annotation)</code>","text":"<p>Create a project in a Roboflow workspace.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>name of the project</p> required <code>project_type</code> <code>str</code> <p>type of the project</p> required <code>project_license</code> <code>str</code> <p>license of the project (set to <code>private</code> for private projects, only available for paid customers)</p> required <code>annotation</code> <code>str</code> <p>annotation of the project</p> required <p>Returns:</p> Type Description <p>Project Object</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def create_project(self, project_name, project_type, project_license, annotation):\n\"\"\"\n    Create a project in a Roboflow workspace.\n\n    Args:\n        project_name (str): name of the project\n        project_type (str): type of the project\n        project_license (str): license of the project (set to `private` for private projects, only available for paid customers)\n        annotation (str): annotation of the project\n\n    Returns:\n        Project Object\n    \"\"\"\n    data = {\n        \"name\": project_name,\n        \"type\": project_type,\n        \"license\": project_license,\n        \"annotation\": annotation,\n    }\n\n    r = requests.post(\n        API_URL + \"/\" + self.url + \"/projects?api_key=\" + self.__api_key, json=data\n    )\n\n    r.raise_for_status()\n\n    if \"error\" in r.json().keys():\n        raise RuntimeError(r.json()[\"error\"])\n\n    return self.project(r.json()[\"id\"].split(\"/\")[-1])\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.list_projects","title":"<code>list_projects()</code>","text":"<p>Print all projects in the workspace to the console.</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def list_projects(self):\n\"\"\"\n    Print all projects in the workspace to the console.\n    \"\"\"\n    print(self.project_list)\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.project","title":"<code>project(project_name)</code>","text":"<p>Retrieve a Project() object that represents a project in the workspace.</p> <p>This object can be used to retrieve the model through which to run inference.</p> <p>Parameters:</p> Name Type Description Default <code>project_name</code> <code>str</code> <p>name of the project</p> required <p>Returns:</p> Type Description <p>Project Object</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def project(self, project_name):\n\"\"\"\n    Retrieve a Project() object that represents a project in the workspace.\n\n    This object can be used to retrieve the model through which to run inference.\n\n    Args:\n        project_name (str): name of the project\n\n    Returns:\n        Project Object\n    \"\"\"\n    sys.stdout.write(\"\\r\" + \"loading Roboflow project...\")\n    sys.stdout.write(\"\\n\")\n    sys.stdout.flush()\n\n    if self.__api_key in DEMO_KEYS:\n        return Project(self.__api_key, {}, self.model_format)\n\n    project_name = project_name.replace(self.url + \"/\", \"\")\n\n    if \"/\" in project_name:\n        raise RuntimeError(\n            \"The {} project is not available in this ({}) workspace\".format(\n                project_name, self.url\n            )\n        )\n\n    dataset_info = requests.get(\n        API_URL + \"/\" + self.url + \"/\" + project_name + \"?api_key=\" + self.__api_key\n    )\n\n    # Throw error if dataset isn't valid/user doesn't have permissions to access the dataset\n    if dataset_info.status_code != 200:\n        raise RuntimeError(dataset_info.text)\n\n    dataset_info = dataset_info.json()[\"project\"]\n\n    return Project(self.__api_key, dataset_info, self.model_format)\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.projects","title":"<code>projects()</code>","text":"<p>Retrieve all projects in the workspace.</p> <p>Returns:</p> Type Description <p>List of Project objects.</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def projects(self):\n\"\"\"\n    Retrieve all projects in the workspace.\n\n    Returns:\n        List of Project objects.\n    \"\"\"\n    projects_array = []\n    for a_project in self.project_list:\n        proj = Project(self.__api_key, a_project, self.model_format)\n        projects_array.append(proj.id)\n\n    return projects_array\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.two_stage","title":"<code>two_stage(image='', first_stage_model_name='', first_stage_model_version=0, second_stage_model_name='', second_stage_model_version=0)</code>","text":"<p>For each prediction in a first stage detection, perform detection with the second stage model</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>name of the image to be processed</p> <code>''</code> <code>first_stage_model_name</code> <code>str</code> <p>name of the first stage detection model</p> <code>''</code> <code>first_stage_model_version</code> <code>int</code> <p>version number for the first stage model</p> <code>0</code> <code>second_stage_mode</code> <code>str</code> <p>name of the second stage detection model</p> required <code>second_stage_model_version</code> <code>int</code> <p>version number for the second stage model</p> <code>0</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>a json obj containing the results of the second stage detection</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def two_stage(\n    self,\n    image: str = \"\",\n    first_stage_model_name: str = \"\",\n    first_stage_model_version: int = 0,\n    second_stage_model_name: str = \"\",\n    second_stage_model_version: int = 0,\n) -&gt; dict:\n\"\"\"\n    For each prediction in a first stage detection, perform detection with the second stage model\n\n    Args:\n        image (str): name of the image to be processed\n        first_stage_model_name (str): name of the first stage detection model\n        first_stage_model_version (int): version number for the first stage model\n        second_stage_mode (str): name of the second stage detection model\n        second_stage_model_version (int): version number for the second stage model\n\n    Returns:\n        dict: a json obj containing the results of the second stage detection\n    \"\"\"\n    results = []\n\n    # create PIL image for cropping\n    pil_image = Image.open(image).convert(\"RGB\")\n\n    # grab first and second stage model from project\n    stage_one_project = self.project(first_stage_model_name)\n    stage_one_model = stage_one_project.version(first_stage_model_version).model\n    stage_two_project = self.project(second_stage_model_name)\n    stage_two_model = stage_two_project.version(second_stage_model_version).model\n\n    print(self.project(first_stage_model_name))\n\n    # perform first inference\n    predictions = stage_one_model.predict(image)\n\n    if (\n        stage_one_project.type == \"object-detection\"\n        and stage_two_project == \"classification\"\n    ):\n        # interact with each detected object from stage one inference results\n        for boundingbox in predictions:\n            # rip bounding box coordinates from json1\n            # note: infer returns center points of box as (x,y) and width, height\n            # ----- but pillow crop requires the top left and bottom right points to crop\n            box = (\n                boundingbox[\"x\"] - boundingbox[\"width\"] / 2,\n                boundingbox[\"y\"] - boundingbox[\"height\"] / 2,\n                boundingbox[\"x\"] + boundingbox[\"width\"] / 2,\n                boundingbox[\"y\"] + boundingbox[\"height\"] / 2,\n            )\n\n            # create a new cropped image using the first stage prediction coordinates (for each box!)\n            croppedImg = pil_image.crop(box)\n            croppedImg.save(\"./temp.png\")\n\n            # capture results of second stage inference from cropped image\n            results.append(stage_two_model.predict(\"./temp.png\")[0])\n\n        # delete the written image artifact\n        try:\n            os.remove(\"./temp.png\")\n        except FileNotFoundError:\n            print(\"no detections\")\n\n    else:\n        print(\n            \"please use an object detection model for the first stage--can only perform two stage with bounding box results\",\n            \"please use a classification model for the second stage\",\n        )\n\n    return results\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.two_stage_ocr","title":"<code>two_stage_ocr(image='', first_stage_model_name='', first_stage_model_version=0)</code>","text":"<p>For each prediction in the first stage object detection, perform OCR as second stage.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>str</code> <p>name of the image to be processed</p> <code>''</code> <code>first_stage_model_name</code> <code>str</code> <p>name of the first stage detection model</p> <code>''</code> <code>first_stage_model_version</code> <code>int</code> <p>version number for the first stage model</p> <code>0</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>a json obj containing the results of the second stage detection</p> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def two_stage_ocr(\n    self,\n    image: str = \"\",\n    first_stage_model_name: str = \"\",\n    first_stage_model_version: int = 0,\n) -&gt; dict:\n\"\"\"\n    For each prediction in the first stage object detection, perform OCR as second stage.\n\n    Args:\n        image (str): name of the image to be processed\n        first_stage_model_name (str): name of the first stage detection model\n        first_stage_model_version (int): version number for the first stage model\n\n    Returns:\n        dict: a json obj containing the results of the second stage detection\n    \"\"\"\n    results = []\n\n    # create PIL image for cropping\n    pil_image = Image.open(image).convert(\"RGB\")\n\n    # grab first and second stage model from project\n    stage_one_project = self.project(first_stage_model_name)\n    stage_one_model = stage_one_project.version(first_stage_model_version).model\n\n    # perform first inference\n    predictions = stage_one_model.predict(image)\n\n    # interact with each detected object from stage one inference results\n    if stage_one_project.type == \"object-detection\":\n        for boundingbox in predictions:\n            # rip bounding box coordinates from json1\n            # note: infer returns center points of box as (x,y) and width, height\n            # ----- but pillow crop requires the top left and bottom right points to crop\n            box = (\n                boundingbox[\"x\"] - boundingbox[\"width\"] / 2,\n                boundingbox[\"y\"] - boundingbox[\"height\"] / 2,\n                boundingbox[\"x\"] + boundingbox[\"width\"] / 2,\n                boundingbox[\"y\"] + boundingbox[\"height\"] / 2,\n            )\n\n            # create a new cropped image using the first stage prediction coordinates (for each box!)\n            croppedImg = pil_image.crop(box)\n\n            # capture OCR results from cropped image\n            results.append(ocr_infer(croppedImg)[\"results\"])\n    else:\n        print(\n            \"please use an object detection model--can only perform two stage with bounding box results\"\n        )\n\n    return results\n</code></pre>"},{"location":"core/workspace/#roboflow.core.workspace.Workspace.upload_dataset","title":"<code>upload_dataset(dataset_path, project_name, num_workers=10, dataset_format='yolov8', project_license='MIT', project_type='object-detection')</code>","text":"<p>Upload a dataset to Roboflow.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str</code> <p>path to the dataset</p> required <code>project_name</code> <code>str</code> <p>name of the project</p> required <code>num_workers</code> <code>int</code> <p>number of workers to use for parallel uploads</p> <code>10</code> <code>dataset_format</code> <code>str</code> <p>format of the dataset (<code>voc</code>, <code>yolov8</code>, <code>yolov5</code>)</p> <code>'yolov8'</code> <code>project_license</code> <code>str</code> <p>license of the project (set to <code>private</code> for private projects, only available for paid customers)</p> <code>'MIT'</code> <code>project_type</code> <code>str</code> <p>type of the project (only <code>object-detection</code> is supported)</p> <code>'object-detection'</code> Source code in <code>roboflow/core/workspace.py</code> <pre><code>def upload_dataset(\n    self,\n    dataset_path: str,\n    project_name: str,\n    num_workers: int = 10,\n    dataset_format: str = \"yolov8\",\n    project_license: str = \"MIT\",\n    project_type: str = \"object-detection\",\n):\n\"\"\"\n    Upload a dataset to Roboflow.\n\n    Args:\n        dataset_path (str): path to the dataset\n        project_name (str): name of the project\n        num_workers (int): number of workers to use for parallel uploads\n        dataset_format (str): format of the dataset (`voc`, `yolov8`, `yolov5`)\n        project_license (str): license of the project (set to `private` for private projects, only available for paid customers)\n        project_type (str): type of the project (only `object-detection` is supported)\n    \"\"\"\n    if project_type != \"object-detection\":\n        raise (\"upload_dataset only supported for object-detection projects\")\n\n    if dataset_format not in [\"voc\", \"yolov8\", \"yolov5\"]:\n        raise (\n            \"dataset_format not supported - please use voc, yolov8, yolov5. PS, you can always convert your dataset in the Roboflow UI\"\n        )\n\n    # check type stuff and convert\n    if dataset_format == \"yolov8\" or dataset_format == \"yolov5\":\n        # convert to voc\n        for split in [\"train\", \"valid\", \"test\"]:\n            dataset = sv.DetectionDataset.from_yolo(\n                images_directory_path=dataset_path + \"/\" + split + \"/images\",\n                annotations_directory_path=dataset_path + \"/\" + split + \"/labels\",\n                data_yaml_path=dataset_path + \"/data.yaml\",\n            )\n\n            dataset.as_pascal_voc(\n                images_directory_path=dataset_path + \"_voc\" + \"/\" + split,\n                annotations_directory_path=dataset_path + \"_voc\" + \"/\" + split,\n            )\n\n        dataset_path = dataset_path + \"_voc\"\n\n    if project_name in [p[\"name\"] for p in self.project_list]:\n        dataset_upload_project = self.project(project_name)\n        print(f\"Uploading to existing project {dataset_upload_project.id}\")\n    else:\n        dataset_upload_project = self.create_project(\n            project_name,\n            project_license=project_license,\n            annotation=project_name,\n            project_type=project_type,\n        )\n        print(f\"Created project {dataset_upload_project.id}\")\n\n    def upload_file(img_file: str, split: str):\n\"\"\"\n        Upload an image or annotation to a project.\n\n        Args:\n            img_file (str): path to the image\n            split (str): split to which the the image should be added (train, valid, test)\n        \"\"\"\n        label_file = img_file.replace(\".jpg\", \".xml\")\n        dataset_upload_project.upload(\n            image_path=img_file, annotation_path=label_file, split=split\n        )\n\n    def parallel_upload(file_list, split):\n        with concurrent.futures.ThreadPoolExecutor(\n            max_workers=num_workers\n        ) as executor:\n            list(\n                tqdm(\n                    executor.map(upload_file, file_list, [split] * len(file_list)),\n                    total=len(file_list),\n                    file=sys.stdout,\n                )\n            )\n\n    write_line(\"uploading training set...\")\n    file_list = glob.glob(dataset_path + \"/train/*.jpg\")\n    parallel_upload(file_list, \"train\")\n\n    write_line(\"uploading validation set...\")\n    file_list = glob.glob(dataset_path + \"/valid/*.jpg\")\n    parallel_upload(file_list, \"valid\")\n\n    write_line(\"uploading test set...\")\n    file_list = glob.glob(dataset_path + \"/test/*.jpg\")\n    parallel_upload(file_list, \"test\")\n</code></pre>"},{"location":"models/classification/","title":"Classification","text":""},{"location":"models/classification/#roboflow.models.classification.ClassificationModel","title":"<code>ClassificationModel</code>","text":"<p>Run inference on a classification model hosted on Roboflow or served through Roboflow Inference.</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>class ClassificationModel:\n\"\"\"\n    Run inference on a classification model hosted on Roboflow or served through Roboflow Inference.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        id: str,\n        name: str = None,\n        version: int = None,\n        local: bool = False,\n        colors: dict = None,\n        preprocessing: dict = None,\n    ):\n\"\"\"\n        Create a ClassificationModel object through which you can run inference.\n\n        Args:\n            api_key (str): private roboflow api key\n            id (str): the workspace/project id\n            name (str): is the name of the project\n            version (int): version number\n            local (bool): whether the image is local or hosted\n            colors (dict): colors to use for the image\n            preprocessing (dict): preprocessing to use for the image\n\n        Returns:\n            ClassificationModel Object\n        \"\"\"\n        # Instantiate different API URL parameters\n        self.__api_key = api_key\n        self.id = id\n        self.name = name\n        self.version = version\n        self.base_url = \"https://classify.roboflow.com/\"\n\n        if self.name is not None and version is not None:\n            self.__generate_url()\n\n        self.colors = {} if colors is None else colors\n        self.preprocessing = {} if preprocessing is None else preprocessing\n\n    def predict(self, image_path, hosted=False):\n\"\"\"\n        Run inference on an image.\n\n        Args:\n            image_path (str): path to the image you'd like to perform prediction on\n            hosted (bool): whether the image you're providing is hosted on Roboflow\n\n        Returns:\n            PredictionGroup Object\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; model = project.version(\"1\").model\n\n            &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n        \"\"\"\n        self.__generate_url()\n        self.__exception_check(image_path_check=image_path)\n        # If image is local image\n        if not hosted:\n            # Open Image in RGB Format\n            image = Image.open(image_path).convert(\"RGB\")\n            # Create buffer\n            buffered = io.BytesIO()\n            image.save(buffered, quality=90, format=\"JPEG\")\n            img_dims = image.size\n            # Base64 encode image\n            img_str = base64.b64encode(buffered.getvalue())\n            img_str = img_str.decode(\"ascii\")\n            # Post to API and return response\n            resp = requests.post(\n                self.api_url,\n                data=img_str,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n        else:\n            # Create API URL for hosted image (slightly different)\n            self.api_url += \"&amp;image=\" + urllib.parse.quote_plus(image_path)\n            # POST to the API\n            resp = requests.post(self.api_url)\n            img_dims = {\"width\": \"0\", \"height\": \"0\"}\n\n        if resp.status_code != 200:\n            raise Exception(resp.text)\n\n        return PredictionGroup.create_prediction_group(\n            resp.json(),\n            image_dims=img_dims,\n            image_path=image_path,\n            prediction_type=CLASSIFICATION_MODEL,\n            colors=self.colors,\n        )\n\n    def load_model(self, name, version):\n\"\"\"\n        Load a model.\n\n        Args:\n            name (str): is the name of the model you'd like to load\n            version (int): version number\n        \"\"\"\n        # Load model based on user defined characteristics\n        self.name = name\n        self.version = version\n        self.__generate_url()\n\n    def __generate_url(self):\n\"\"\"\n        Generate a Roboflow API URL on which to run inference.\n\n        Returns:\n            url (str): the url on which to run inference\n        \"\"\"\n\n        # Generates URL based on all parameters\n        splitted = self.id.rsplit(\"/\")\n        without_workspace = splitted[1]\n\n        self.api_url = \"\".join(\n            [\n                self.base_url + without_workspace + \"/\" + str(self.version),\n                \"?api_key=\" + self.__api_key,\n                \"&amp;name=YOUR_IMAGE.jpg\",\n            ]\n        )\n\n    def __exception_check(self, image_path_check=None):\n\"\"\"\n        Check to see if an image exists.\n\n        Args:\n            image_path_check (str): path to the image to check\n\n        Raises:\n            Exception: if image does not exist\n        \"\"\"\n        # Checks if image exists\n        if image_path_check is not None:\n            if not os.path.exists(image_path_check) and not check_image_url(\n                image_path_check\n            ):\n                raise Exception(\"Image does not exist at \" + image_path_check + \"!\")\n\n    def __str__(self):\n\"\"\"\n        String representation of classification object\n        \"\"\"\n        json_value = {\n            \"name\": self.name,\n            \"version\": self.version,\n            \"base_url\": self.base_url,\n        }\n\n        return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.__exception_check","title":"<code>__exception_check(image_path_check=None)</code>","text":"<p>Check to see if an image exists.</p> <p>Parameters:</p> Name Type Description Default <code>image_path_check</code> <code>str</code> <p>path to the image to check</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>if image does not exist</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def __exception_check(self, image_path_check=None):\n\"\"\"\n    Check to see if an image exists.\n\n    Args:\n        image_path_check (str): path to the image to check\n\n    Raises:\n        Exception: if image does not exist\n    \"\"\"\n    # Checks if image exists\n    if image_path_check is not None:\n        if not os.path.exists(image_path_check) and not check_image_url(\n            image_path_check\n        ):\n            raise Exception(\"Image does not exist at \" + image_path_check + \"!\")\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.__generate_url","title":"<code>__generate_url()</code>","text":"<p>Generate a Roboflow API URL on which to run inference.</p> <p>Returns:</p> Name Type Description <code>url</code> <code>str</code> <p>the url on which to run inference</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def __generate_url(self):\n\"\"\"\n    Generate a Roboflow API URL on which to run inference.\n\n    Returns:\n        url (str): the url on which to run inference\n    \"\"\"\n\n    # Generates URL based on all parameters\n    splitted = self.id.rsplit(\"/\")\n    without_workspace = splitted[1]\n\n    self.api_url = \"\".join(\n        [\n            self.base_url + without_workspace + \"/\" + str(self.version),\n            \"?api_key=\" + self.__api_key,\n            \"&amp;name=YOUR_IMAGE.jpg\",\n        ]\n    )\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.__init__","title":"<code>__init__(api_key, id, name=None, version=None, local=False, colors=None, preprocessing=None)</code>","text":"<p>Create a ClassificationModel object through which you can run inference.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>private roboflow api key</p> required <code>id</code> <code>str</code> <p>the workspace/project id</p> required <code>name</code> <code>str</code> <p>is the name of the project</p> <code>None</code> <code>version</code> <code>int</code> <p>version number</p> <code>None</code> <code>local</code> <code>bool</code> <p>whether the image is local or hosted</p> <code>False</code> <code>colors</code> <code>dict</code> <p>colors to use for the image</p> <code>None</code> <code>preprocessing</code> <code>dict</code> <p>preprocessing to use for the image</p> <code>None</code> <p>Returns:</p> Type Description <p>ClassificationModel Object</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def __init__(\n    self,\n    api_key: str,\n    id: str,\n    name: str = None,\n    version: int = None,\n    local: bool = False,\n    colors: dict = None,\n    preprocessing: dict = None,\n):\n\"\"\"\n    Create a ClassificationModel object through which you can run inference.\n\n    Args:\n        api_key (str): private roboflow api key\n        id (str): the workspace/project id\n        name (str): is the name of the project\n        version (int): version number\n        local (bool): whether the image is local or hosted\n        colors (dict): colors to use for the image\n        preprocessing (dict): preprocessing to use for the image\n\n    Returns:\n        ClassificationModel Object\n    \"\"\"\n    # Instantiate different API URL parameters\n    self.__api_key = api_key\n    self.id = id\n    self.name = name\n    self.version = version\n    self.base_url = \"https://classify.roboflow.com/\"\n\n    if self.name is not None and version is not None:\n        self.__generate_url()\n\n    self.colors = {} if colors is None else colors\n    self.preprocessing = {} if preprocessing is None else preprocessing\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.__str__","title":"<code>__str__()</code>","text":"<p>String representation of classification object</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def __str__(self):\n\"\"\"\n    String representation of classification object\n    \"\"\"\n    json_value = {\n        \"name\": self.name,\n        \"version\": self.version,\n        \"base_url\": self.base_url,\n    }\n\n    return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.load_model","title":"<code>load_model(name, version)</code>","text":"<p>Load a model.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>is the name of the model you'd like to load</p> required <code>version</code> <code>int</code> <p>version number</p> required Source code in <code>roboflow/models/classification.py</code> <pre><code>def load_model(self, name, version):\n\"\"\"\n    Load a model.\n\n    Args:\n        name (str): is the name of the model you'd like to load\n        version (int): version number\n    \"\"\"\n    # Load model based on user defined characteristics\n    self.name = name\n    self.version = version\n    self.__generate_url()\n</code></pre>"},{"location":"models/classification/#roboflow.models.classification.ClassificationModel.predict","title":"<code>predict(image_path, hosted=False)</code>","text":"<p>Run inference on an image.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to the image you'd like to perform prediction on</p> required <code>hosted</code> <code>bool</code> <p>whether the image you're providing is hosted on Roboflow</p> <code>False</code> <p>Returns:</p> Type Description <p>PredictionGroup Object</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>model = project.version(\"1\").model</p> <p>prediction = model.predict(\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/models/classification.py</code> <pre><code>def predict(self, image_path, hosted=False):\n\"\"\"\n    Run inference on an image.\n\n    Args:\n        image_path (str): path to the image you'd like to perform prediction on\n        hosted (bool): whether the image you're providing is hosted on Roboflow\n\n    Returns:\n        PredictionGroup Object\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; model = project.version(\"1\").model\n\n        &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n    \"\"\"\n    self.__generate_url()\n    self.__exception_check(image_path_check=image_path)\n    # If image is local image\n    if not hosted:\n        # Open Image in RGB Format\n        image = Image.open(image_path).convert(\"RGB\")\n        # Create buffer\n        buffered = io.BytesIO()\n        image.save(buffered, quality=90, format=\"JPEG\")\n        img_dims = image.size\n        # Base64 encode image\n        img_str = base64.b64encode(buffered.getvalue())\n        img_str = img_str.decode(\"ascii\")\n        # Post to API and return response\n        resp = requests.post(\n            self.api_url,\n            data=img_str,\n            headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n        )\n    else:\n        # Create API URL for hosted image (slightly different)\n        self.api_url += \"&amp;image=\" + urllib.parse.quote_plus(image_path)\n        # POST to the API\n        resp = requests.post(self.api_url)\n        img_dims = {\"width\": \"0\", \"height\": \"0\"}\n\n    if resp.status_code != 200:\n        raise Exception(resp.text)\n\n    return PredictionGroup.create_prediction_group(\n        resp.json(),\n        image_dims=img_dims,\n        image_path=image_path,\n        prediction_type=CLASSIFICATION_MODEL,\n        colors=self.colors,\n    )\n</code></pre>"},{"location":"models/instance-segmentation/","title":"Instance Segmentation","text":""},{"location":"models/instance-segmentation/#roboflow.models.instance_segmentation.InstanceSegmentationModel","title":"<code>InstanceSegmentationModel</code>","text":"<p>             Bases: <code>InferenceModel</code></p> <p>Run inference on a instance segmentation model hosted on Roboflow or served through Roboflow Inference.</p> Source code in <code>roboflow/models/instance_segmentation.py</code> <pre><code>class InstanceSegmentationModel(InferenceModel):\n\"\"\"\n    Run inference on a instance segmentation model hosted on Roboflow or served through Roboflow Inference.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        version_id: str,\n        colors: dict = None,\n        preprocessing: dict = None,\n        local: bool = None,\n    ):\n\"\"\"\n        Create a InstanceSegmentationModel object through which you can run inference.\n\n        Args:\n            api_key (str): private roboflow api key\n            version_id (str): the workspace/project id\n            colors (dict): colors to use for the image\n            preprocessing (dict): preprocessing to use for the image\n            local (bool): whether the image is local or hosted\n        \"\"\"\n        super(InstanceSegmentationModel, self).__init__(api_key, version_id)\n        if local is None:\n            self.api_url = (\n                f\"{INSTANCE_SEGMENTATION_URL}/{self.dataset_id}/{self.version}\"\n            )\n        else:\n            self.api_url = f\"{local}/{self.dataset_id}/{self.version}\"\n        self.colors = {} if colors is None else colors\n        self.preprocessing = {} if preprocessing is None else preprocessing\n\n    def predict(self, image_path, confidence=40):\n\"\"\"\n        Infers detections based on image from a specified model and image path.\n\n        Args:\n            image_path (str): path to the image you'd like to perform prediction on\n            confidence (int): confidence threshold for predictions, on a scale from 0-100\n\n        Returns:\n            PredictionGroup Object\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; model = project.version(\"1\").model\n\n            &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n        \"\"\"\n        return super(InstanceSegmentationModel, self).predict(\n            image_path,\n            confidence=confidence,\n            prediction_type=INSTANCE_SEGMENTATION_MODEL,\n        )\n\n    def __str__(self):\n        return f\"&lt;{type(self).__name__} id={self.id}, api_url={self.api_url}&gt;\"\n</code></pre>"},{"location":"models/instance-segmentation/#roboflow.models.instance_segmentation.InstanceSegmentationModel.__init__","title":"<code>__init__(api_key, version_id, colors=None, preprocessing=None, local=None)</code>","text":"<p>Create a InstanceSegmentationModel object through which you can run inference.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>private roboflow api key</p> required <code>version_id</code> <code>str</code> <p>the workspace/project id</p> required <code>colors</code> <code>dict</code> <p>colors to use for the image</p> <code>None</code> <code>preprocessing</code> <code>dict</code> <p>preprocessing to use for the image</p> <code>None</code> <code>local</code> <code>bool</code> <p>whether the image is local or hosted</p> <code>None</code> Source code in <code>roboflow/models/instance_segmentation.py</code> <pre><code>def __init__(\n    self,\n    api_key: str,\n    version_id: str,\n    colors: dict = None,\n    preprocessing: dict = None,\n    local: bool = None,\n):\n\"\"\"\n    Create a InstanceSegmentationModel object through which you can run inference.\n\n    Args:\n        api_key (str): private roboflow api key\n        version_id (str): the workspace/project id\n        colors (dict): colors to use for the image\n        preprocessing (dict): preprocessing to use for the image\n        local (bool): whether the image is local or hosted\n    \"\"\"\n    super(InstanceSegmentationModel, self).__init__(api_key, version_id)\n    if local is None:\n        self.api_url = (\n            f\"{INSTANCE_SEGMENTATION_URL}/{self.dataset_id}/{self.version}\"\n        )\n    else:\n        self.api_url = f\"{local}/{self.dataset_id}/{self.version}\"\n    self.colors = {} if colors is None else colors\n    self.preprocessing = {} if preprocessing is None else preprocessing\n</code></pre>"},{"location":"models/instance-segmentation/#roboflow.models.instance_segmentation.InstanceSegmentationModel.predict","title":"<code>predict(image_path, confidence=40)</code>","text":"<p>Infers detections based on image from a specified model and image path.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to the image you'd like to perform prediction on</p> required <code>confidence</code> <code>int</code> <p>confidence threshold for predictions, on a scale from 0-100</p> <code>40</code> <p>Returns:</p> Type Description <p>PredictionGroup Object</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>model = project.version(\"1\").model</p> <p>prediction = model.predict(\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/models/instance_segmentation.py</code> <pre><code>def predict(self, image_path, confidence=40):\n\"\"\"\n    Infers detections based on image from a specified model and image path.\n\n    Args:\n        image_path (str): path to the image you'd like to perform prediction on\n        confidence (int): confidence threshold for predictions, on a scale from 0-100\n\n    Returns:\n        PredictionGroup Object\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; model = project.version(\"1\").model\n\n        &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n    \"\"\"\n    return super(InstanceSegmentationModel, self).predict(\n        image_path,\n        confidence=confidence,\n        prediction_type=INSTANCE_SEGMENTATION_MODEL,\n    )\n</code></pre>"},{"location":"models/object-detection/","title":"Object Detection","text":""},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel","title":"<code>ObjectDetectionModel</code>","text":"<p>Run inference on an object detection model hosted on Roboflow or served through Roboflow Inference.</p> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>class ObjectDetectionModel:\n\"\"\"\n    Run inference on an object detection model hosted on Roboflow or served through Roboflow Inference.\n    \"\"\"\n\n    def __init__(\n        self,\n        api_key,\n        id,\n        name=None,\n        version=None,\n        local=None,\n        classes=None,\n        overlap=30,\n        confidence=40,\n        stroke=1,\n        labels=False,\n        format=\"json\",\n        colors=None,\n        preprocessing=None,\n    ):\n\"\"\"\n        Create a ObjectDetectionModel object through which you can run inference.\n\n        Args:\n            api_key (str): Your API key (obtained via your workspace API settings page).\n            name (str): The url-safe version of the dataset name. You can find it in the web UI by looking at\n                        the URL on the main project view or by clicking the \"Get curl command\" button in the train\n                        results section of your dataset version after training your model.\n            local (str): Address of the local server address if running a local Roboflow deployment server.\n                        Ex. http://localhost:9001/\n            version (str): The version number identifying the version of your dataset.\n            classes (str): Restrict the predictions to only those of certain classes. Provide as a comma-separated string.\n            overlap (int): The maximum percentage (on a scale of 0-100) that bounding box predictions of the same class are\n                        allowed to overlap before being combined into a single box.\n            confidence (int): A threshold for the returned predictions on a scale of 0-100. A lower number will return\n                            more predictions. A higher number will return fewer high-certainty predictions.\n            stroke (int): The width (in pixels) of the bounding box displayed around predictions (only has an effect when\n                        format is image).\n            labels (bool): Whether or not to display text labels on the predictions (only has an effect when format is\n                        image).\n            format (str): The format of the output.\n                        - 'json': returns an array of JSON predictions (See response format tab).\n                        - 'image': returns an image with annotated predictions as a binary blob with a Content-Type\n                                    of image/jpeg.\n        \"\"\"\n        # Instantiate different API URL parameters\n        # To be moved to predict\n        self.__api_key = api_key\n        self.id = id\n        self.name = name\n        self.version = version\n        self.classes = classes\n        self.overlap = overlap\n        self.confidence = confidence\n        self.stroke = stroke\n        self.labels = labels\n        self.format = format\n        self.colors = {} if colors is None else colors\n        self.preprocessing = {} if preprocessing is None else preprocessing\n\n        # local needs to be passed from Project\n        if local is None:\n            self.base_url = OBJECT_DETECTION_URL + \"/\"\n        else:\n            print(\"initalizing local object detection model hosted at :\" + local)\n            self.base_url = local\n\n        # If dataset slug not none, instantiate API URL\n        if name is not None and version is not None:\n            self.__generate_url()\n\n    def load_model(\n        self,\n        name,\n        version,\n        local=None,\n        classes=None,\n        overlap=None,\n        confidence=None,\n        stroke=None,\n        labels=None,\n        format=None,\n    ):\n\"\"\"\n        Loads a Model from on a model endpoint.\n\n        Args:\n            name (str): The url-safe version of the dataset name\n            version (str): The version number identifying the version of your dataset.\n            local (bool): Whether the model is hosted locally or on Roboflow\n        \"\"\"\n        # To load a model manually, they must specify a dataset slug\n        self.name = name\n        self.version = version\n        # Generate URL based on parameters\n        self.__generate_url(\n            local=local,\n            classes=classes,\n            overlap=overlap,\n            confidence=confidence,\n            stroke=stroke,\n            labels=labels,\n            format=format,\n        )\n\n    def predict(\n        self,\n        image_path,\n        hosted=False,\n        format=None,\n        classes=None,\n        overlap=30,\n        confidence=40,\n        stroke=1,\n        labels=False,\n    ):\n\"\"\"\n        Infers detections based on image from specified model and image path.\n\n        Args:\n            image_path (str): path to the image you'd like to perform prediction on\n            hosted (bool): whether the image you're providing is hosted on Roboflow\n            format (str): The format of the output.\n\n        Returns:\n            PredictionGroup Object\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; model = project.version(\"1\").model\n\n            &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n        \"\"\"\n        # Generate url before predicting\n        self.__generate_url(\n            format=format,\n            classes=classes,\n            overlap=overlap,\n            confidence=confidence,\n            stroke=stroke,\n            labels=labels,\n        )\n\n        # Check if image exists at specified path or URL or is an array\n        if hasattr(image_path, \"__len__\") == True:\n            pass\n        else:\n            self.__exception_check(image_path_check=image_path)\n\n        resize = False\n        # If image is local image\n        if not hosted:\n            if type(image_path) is str:\n                image = Image.open(image_path).convert(\"RGB\")\n                dimensions = image.size\n                original_dimensions = copy.deepcopy(dimensions)\n\n                # Here we resize the image to the preprocessing settings before sending it over the wire\n                if \"resize\" in self.preprocessing.keys():\n                    if dimensions[0] &gt; int(\n                        self.preprocessing[\"resize\"][\"width\"]\n                    ) or dimensions[1] &gt; int(self.preprocessing[\"resize\"][\"height\"]):\n                        image = image.resize(\n                            (\n                                int(self.preprocessing[\"resize\"][\"width\"]),\n                                int(self.preprocessing[\"resize\"][\"height\"]),\n                            )\n                        )\n                        dimensions = image.size\n                        resize = True\n\n                # Create buffer\n                buffered = io.BytesIO()\n                image.save(buffered, format=\"PNG\")\n                # Base64 encode image\n                img_str = base64.b64encode(buffered.getvalue())\n                img_str = img_str.decode(\"ascii\")\n                # Post to API and return response\n                resp = requests.post(\n                    self.api_url,\n                    data=img_str,\n                    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                )\n\n                image_dims = {\n                    \"width\": str(original_dimensions[0]),\n                    \"height\": str(original_dimensions[1]),\n                }\n            elif isinstance(image_path, np.ndarray):\n                # Performing inference on a OpenCV2 frame\n                retval, buffer = cv2.imencode(\".jpg\", image_path)\n                # Currently cv2.imencode does not properly return shape\n                dimensions = buffer.shape\n                img_str = base64.b64encode(buffer)\n                img_str = img_str.decode(\"ascii\")\n                resp = requests.post(\n                    self.api_url,\n                    data=img_str,\n                    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                )\n                # Replace with dimensions variable once cv2.imencode shape solution is found\n                image_dims = {\"width\": \"0\", \"height\": \"0\"}\n            else:\n                raise ValueError(\"image_path must be a string or a numpy array.\")\n        else:\n            # Create API URL for hosted image (slightly different)\n            self.api_url += \"&amp;image=\" + urllib.parse.quote_plus(image_path)\n            image_dims = {\"width\": \"0\", \"height\": \"0\"}\n            # POST to the API\n            resp = requests.post(self.api_url)\n\n        resp.raise_for_status()\n        # Return a prediction group if JSON data\n        if self.format == \"json\":\n            resp_json = resp.json()\n\n            if resize:\n                new_preds = []\n                for p in resp_json[\"predictions\"]:\n                    p[\"x\"] = int(\n                        p[\"x\"]\n                        * (\n                            int(original_dimensions[0])\n                            / int(self.preprocessing[\"resize\"][\"width\"])\n                        )\n                    )\n                    p[\"y\"] = int(\n                        p[\"y\"]\n                        * (\n                            int(original_dimensions[1])\n                            / int(self.preprocessing[\"resize\"][\"height\"])\n                        )\n                    )\n                    p[\"width\"] = int(\n                        p[\"width\"]\n                        * (\n                            int(original_dimensions[0])\n                            / int(self.preprocessing[\"resize\"][\"width\"])\n                        )\n                    )\n                    p[\"height\"] = int(\n                        p[\"height\"]\n                        * (\n                            int(original_dimensions[1])\n                            / int(self.preprocessing[\"resize\"][\"height\"])\n                        )\n                    )\n\n                    new_preds.append(p)\n\n                resp_json[\"predictions\"] = new_preds\n\n            return PredictionGroup.create_prediction_group(\n                resp_json,\n                image_path=image_path,\n                prediction_type=OBJECT_DETECTION_MODEL,\n                image_dims=image_dims,\n                colors=self.colors,\n            )\n        # Returns base64 encoded Data\n        elif self.format == \"image\":\n            return resp.content\n\n    def webcam(\n        self,\n        webcam_id=0,\n        inference_engine_url=\"https://detect.roboflow.com/\",\n        within_jupyter=False,\n        confidence=40,\n        overlap=30,\n        stroke=1,\n        labels=False,\n        web_cam_res=(416, 416),\n    ):\n\"\"\"\n        Infers detections based on webcam feed from specified model.\n\n        Args:\n            webcam_id (int): Webcam ID (default 0)\n            inference_engine_url (str): Inference engine address to use (default https://detect.roboflow.com)\n            within_jupyter (bool): Whether or not to display the webcam within Jupyter notebook (default True)\n            confidence (int): Confidence threshold for detections\n            overlap (int): Overlap threshold for detections\n            stroke (int): Stroke width for bounding box\n            labels (bool): Whether to show labels on bounding box\n        \"\"\"\n\n        os.environ[\"OPENCV_VIDEOIO_PRIORITY_MSMF\"] = \"0\"\n\n        # Generate url before predicting\n        self.__generate_url(\n            confidence=confidence,\n            overlap=overlap,\n            stroke=stroke,\n            labels=labels,\n            inference_engine_url=inference_engine_url,\n        )\n\n        def plot_one_box(\n            x, img, color=None, label=None, line_thickness=None, colors=None\n        ):\n            # Plots one bounding box on image img\n\n            self.colors = {} if colors is None else colors\n\n            if label in colors.keys() and label is not None:\n                color = colors[label]\n                color = color.lstrip(\"#\")\n                color = tuple(int(color[i : i + 2], 16) for i in (0, 2, 4))\n            else:\n                color = [random.randint(0, 255) for _ in range(3)]\n\n            tl = (\n                line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1\n            )  # line/font thickness\n\n            c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n\n            cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n            if label:\n                tf = max(tl - 1, 1)  # font thickness\n                t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n                c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n                cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n                cv2.putText(\n                    img,\n                    label,\n                    (c1[0], c1[1] - 2),\n                    0,\n                    tl / 3,\n                    [225, 255, 255],\n                    thickness=tf,\n                    lineType=cv2.LINE_AA,\n                )\n\n        cap = cv2.VideoCapture(webcam_id)\n\n        if cap is None or not cap.isOpened():\n            raise (Exception(\"No webcam available at webcam_id \" + str(webcam_id)))\n\n        cap.set(cv2.CAP_PROP_FRAME_WIDTH, web_cam_res[0])\n        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, web_cam_res[1])\n\n        if within_jupyter:\n            os.environ[\"OPENCV_VIDEOIO_PRIORITY_MSMF\"] = \"0\"\n            print_warn_for_wrong_dependencies_versions([(\"IPython\", \"&gt;=\", \"7.0.0\")])\n            print_warn_for_wrong_dependencies_versions([(\"ipywidgets\", \"&gt;=\", \"7.0.0\")])\n\n            import threading\n\n            import ipywidgets as widgets\n            from IPython.display import Image as IPythonImage\n            from IPython.display import display\n\n            display_handle = display(\"loading Roboflow model...\", display_id=True)\n\n            # Stop button\n            # ================\n            stopButton = widgets.ToggleButton(\n                value=False,\n                description=\"Stop Inference\",\n                disabled=False,\n                button_style=\"danger\",  # 'success', 'info', 'warning', 'danger' or ''\n                tooltip=\"Description\",\n                icon=\"square\",  # (FontAwesome names without the `fa-` prefix)\n            )\n\n        else:\n            cv2.namedWindow(\"Roboflow Webcam Inference\", cv2.WINDOW_NORMAL)\n            cv2.startWindowThread()\n\n            stopButton = None\n\n        def view(button):\n            while True:\n                if stopButton is not None:\n                    if stopButton.value == True:\n                        break\n                else:\n                    if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):  # quit when 'q' is pressed\n                        break\n\n                _, frame = cap.read()\n                frame = cv2.resize(frame, web_cam_res)\n\n                frame = cv2.flip(frame, 1)  # if your camera reverses your image\n\n                _, frame_upload = cv2.imencode(\".jpeg\", frame)\n                img_str = base64.b64encode(frame_upload)\n                img_str = img_str.decode(\"ascii\")\n\n                # post frame to the Roboflow API\n                r = requests.post(\n                    self.api_url,\n                    data=img_str,\n                    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                )\n\n                json = r.json()\n\n                predictions = json[\"predictions\"]\n\n                formatted_predictions = []\n                classes = []\n\n                for pred in predictions:\n                    formatted_pred = [\n                        pred[\"x\"],\n                        pred[\"y\"],\n                        pred[\"x\"],\n                        pred[\"y\"],\n                        pred[\"confidence\"],\n                    ]\n\n                    # convert to top-left x/y from center\n                    formatted_pred[0] = int(formatted_pred[0] - pred[\"width\"] / 2)\n                    formatted_pred[1] = int(formatted_pred[1] - pred[\"height\"] / 2)\n                    formatted_pred[2] = int(formatted_pred[2] + pred[\"width\"] / 2)\n                    formatted_pred[3] = int(formatted_pred[3] + pred[\"height\"] / 2)\n\n                    formatted_predictions.append(formatted_pred)\n                    classes.append(pred[\"class\"])\n\n                    plot_one_box(\n                        formatted_pred,\n                        frame,\n                        label=pred[\"class\"],\n                        line_thickness=2,\n                        colors=self.colors,\n                    )\n\n                _, frame_display = cv2.imencode(\".jpeg\", frame)\n\n                if within_jupyter:\n                    display_handle.update(IPythonImage(data=frame_display.tobytes()))\n                else:\n                    cv2.imshow(\"Roboflow Webcam Inference\", frame)\n                    if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):  # quit when 'q' is pressed\n                        cap.release()\n                        break\n\n            cap.release()\n            if not within_jupyter:\n                cv2.destroyWindow(\"Roboflow Webcam Inference\")\n                cv2.destroyAllWindows()\n                cv2.waitKey(1)\n\n            return\n\n        if within_jupyter:\n            display(stopButton)\n            thread = threading.Thread(target=view, args=(stopButton,))\n            thread.start()\n        else:\n            view(stopButton)\n\n    def download(self, format=\"pt\", location=\".\"):\n\"\"\"\n        Download the weights associated with a model.\n\n        Args:\n            format (str): The format of the output.\n                        - 'pt': returns a PyTorch weights file\n            location (str): The location to save the weights file to\n        \"\"\"\n        supported_formats = [\"pt\"]\n        if format not in supported_formats:\n            raise Exception(\n                f\"Unsupported format {format}. Must be one of {supported_formats}\"\n            )\n\n        workspace, project, version = self.id.rsplit(\"/\")\n\n        # get pt url\n        pt_api_url = f\"{API_URL}/{workspace}/{project}/{self.version}/ptFile\"\n\n        r = requests.get(pt_api_url, params={\"api_key\": self.__api_key})\n\n        r.raise_for_status()\n\n        pt_weights_url = r.json()[\"weightsUrl\"]\n\n        def bar_progress(current, total, width=80):\n            progress_message = (\n                \"Downloading weights to \"\n                + location\n                + \"/weights.pt\"\n                + \": %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n            )\n            sys.stdout.write(\"\\r\" + progress_message)\n            sys.stdout.flush()\n\n        wget.download(pt_weights_url, out=location + \"/weights.pt\", bar=bar_progress)\n\n        return\n\n    def __exception_check(self, image_path_check=None):\n        # Check if Image path exists exception check (for both hosted URL and local image)\n        if image_path_check is not None:\n            if not os.path.exists(image_path_check) and not check_image_url(\n                image_path_check\n            ):\n                raise Exception(\"Image does not exist at \" + image_path_check + \"!\")\n\n    def __generate_url(\n        self,\n        local=None,\n        classes=None,\n        overlap=None,\n        confidence=None,\n        stroke=None,\n        labels=None,\n        format=None,\n        inference_engine_url=None,\n    ):\n\"\"\"\n        Generate the URL to run inference on.\n        \"\"\"\n        # Reassign parameters if any parameters are changed\n        if local is not None:\n            if not local:\n                self.base_url = OBJECT_DETECTION_URL + \"/\"\n            else:\n                self.base_url = \"http://localhost:9001/\"\n\n        if inference_engine_url is not None:\n            self.base_url = inference_engine_url\n\n        # Change any variables that the user wants to change\n        if classes is not None:\n            self.classes = classes\n        if overlap is not None:\n            self.overlap = overlap\n        if confidence is not None:\n            self.confidence = confidence\n        if stroke is not None:\n            self.stroke = stroke\n        if labels is not None:\n            self.labels = labels\n        if format is not None:\n            self.format = format\n\n        # Create the new API URL\n        splitted = self.id.rsplit(\"/\")\n        without_workspace = splitted[1]\n\n        self.api_url = \"\".join(\n            [\n                self.base_url + without_workspace + \"/\" + str(self.version),\n                \"?api_key=\" + self.__api_key,\n                \"&amp;name=YOUR_IMAGE.jpg\",\n                \"&amp;overlap=\" + str(self.overlap),\n                \"&amp;confidence=\" + str(self.confidence),\n                \"&amp;stroke=\" + str(self.stroke),\n                \"&amp;labels=\" + str(self.labels).lower(),\n                \"&amp;format=\" + self.format,\n            ]\n        )\n        # add classes parameter to api\n        if self.classes is not None:\n            self.api_url += \"&amp;classes=\" + self.classes\n\n    def __str__(self):\n        # Create the new API URL\n        splitted = self.id.rsplit(\"/\")\n        without_workspace = splitted[1]\n\n        json_value = {\n            \"id\": without_workspace + \"/\" + str(self.version),\n            \"name\": self.name,\n            \"version\": self.version,\n            \"classes\": self.classes,\n            \"overlap\": self.overlap,\n            \"confidence\": self.confidence,\n            \"stroke\": self.stroke,\n            \"labels\": self.labels,\n            \"format\": self.format,\n            \"base_url\": self.base_url,\n        }\n\n        return json.dumps(json_value, indent=2)\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.__generate_url","title":"<code>__generate_url(local=None, classes=None, overlap=None, confidence=None, stroke=None, labels=None, format=None, inference_engine_url=None)</code>","text":"<p>Generate the URL to run inference on.</p> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def __generate_url(\n    self,\n    local=None,\n    classes=None,\n    overlap=None,\n    confidence=None,\n    stroke=None,\n    labels=None,\n    format=None,\n    inference_engine_url=None,\n):\n\"\"\"\n    Generate the URL to run inference on.\n    \"\"\"\n    # Reassign parameters if any parameters are changed\n    if local is not None:\n        if not local:\n            self.base_url = OBJECT_DETECTION_URL + \"/\"\n        else:\n            self.base_url = \"http://localhost:9001/\"\n\n    if inference_engine_url is not None:\n        self.base_url = inference_engine_url\n\n    # Change any variables that the user wants to change\n    if classes is not None:\n        self.classes = classes\n    if overlap is not None:\n        self.overlap = overlap\n    if confidence is not None:\n        self.confidence = confidence\n    if stroke is not None:\n        self.stroke = stroke\n    if labels is not None:\n        self.labels = labels\n    if format is not None:\n        self.format = format\n\n    # Create the new API URL\n    splitted = self.id.rsplit(\"/\")\n    without_workspace = splitted[1]\n\n    self.api_url = \"\".join(\n        [\n            self.base_url + without_workspace + \"/\" + str(self.version),\n            \"?api_key=\" + self.__api_key,\n            \"&amp;name=YOUR_IMAGE.jpg\",\n            \"&amp;overlap=\" + str(self.overlap),\n            \"&amp;confidence=\" + str(self.confidence),\n            \"&amp;stroke=\" + str(self.stroke),\n            \"&amp;labels=\" + str(self.labels).lower(),\n            \"&amp;format=\" + self.format,\n        ]\n    )\n    # add classes parameter to api\n    if self.classes is not None:\n        self.api_url += \"&amp;classes=\" + self.classes\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.__init__","title":"<code>__init__(api_key, id, name=None, version=None, local=None, classes=None, overlap=30, confidence=40, stroke=1, labels=False, format='json', colors=None, preprocessing=None)</code>","text":"<p>Create a ObjectDetectionModel object through which you can run inference.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>Your API key (obtained via your workspace API settings page).</p> required <code>name</code> <code>str</code> <p>The url-safe version of the dataset name. You can find it in the web UI by looking at         the URL on the main project view or by clicking the \"Get curl command\" button in the train         results section of your dataset version after training your model.</p> <code>None</code> <code>local</code> <code>str</code> <p>Address of the local server address if running a local Roboflow deployment server.         Ex. http://localhost:9001/</p> <code>None</code> <code>version</code> <code>str</code> <p>The version number identifying the version of your dataset.</p> <code>None</code> <code>classes</code> <code>str</code> <p>Restrict the predictions to only those of certain classes. Provide as a comma-separated string.</p> <code>None</code> <code>overlap</code> <code>int</code> <p>The maximum percentage (on a scale of 0-100) that bounding box predictions of the same class are         allowed to overlap before being combined into a single box.</p> <code>30</code> <code>confidence</code> <code>int</code> <p>A threshold for the returned predictions on a scale of 0-100. A lower number will return             more predictions. A higher number will return fewer high-certainty predictions.</p> <code>40</code> <code>stroke</code> <code>int</code> <p>The width (in pixels) of the bounding box displayed around predictions (only has an effect when         format is image).</p> <code>1</code> <code>labels</code> <code>bool</code> <p>Whether or not to display text labels on the predictions (only has an effect when format is         image).</p> <code>False</code> <code>format</code> <code>str</code> <p>The format of the output.         - 'json': returns an array of JSON predictions (See response format tab).         - 'image': returns an image with annotated predictions as a binary blob with a Content-Type                     of image/jpeg.</p> <code>'json'</code> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def __init__(\n    self,\n    api_key,\n    id,\n    name=None,\n    version=None,\n    local=None,\n    classes=None,\n    overlap=30,\n    confidence=40,\n    stroke=1,\n    labels=False,\n    format=\"json\",\n    colors=None,\n    preprocessing=None,\n):\n\"\"\"\n    Create a ObjectDetectionModel object through which you can run inference.\n\n    Args:\n        api_key (str): Your API key (obtained via your workspace API settings page).\n        name (str): The url-safe version of the dataset name. You can find it in the web UI by looking at\n                    the URL on the main project view or by clicking the \"Get curl command\" button in the train\n                    results section of your dataset version after training your model.\n        local (str): Address of the local server address if running a local Roboflow deployment server.\n                    Ex. http://localhost:9001/\n        version (str): The version number identifying the version of your dataset.\n        classes (str): Restrict the predictions to only those of certain classes. Provide as a comma-separated string.\n        overlap (int): The maximum percentage (on a scale of 0-100) that bounding box predictions of the same class are\n                    allowed to overlap before being combined into a single box.\n        confidence (int): A threshold for the returned predictions on a scale of 0-100. A lower number will return\n                        more predictions. A higher number will return fewer high-certainty predictions.\n        stroke (int): The width (in pixels) of the bounding box displayed around predictions (only has an effect when\n                    format is image).\n        labels (bool): Whether or not to display text labels on the predictions (only has an effect when format is\n                    image).\n        format (str): The format of the output.\n                    - 'json': returns an array of JSON predictions (See response format tab).\n                    - 'image': returns an image with annotated predictions as a binary blob with a Content-Type\n                                of image/jpeg.\n    \"\"\"\n    # Instantiate different API URL parameters\n    # To be moved to predict\n    self.__api_key = api_key\n    self.id = id\n    self.name = name\n    self.version = version\n    self.classes = classes\n    self.overlap = overlap\n    self.confidence = confidence\n    self.stroke = stroke\n    self.labels = labels\n    self.format = format\n    self.colors = {} if colors is None else colors\n    self.preprocessing = {} if preprocessing is None else preprocessing\n\n    # local needs to be passed from Project\n    if local is None:\n        self.base_url = OBJECT_DETECTION_URL + \"/\"\n    else:\n        print(\"initalizing local object detection model hosted at :\" + local)\n        self.base_url = local\n\n    # If dataset slug not none, instantiate API URL\n    if name is not None and version is not None:\n        self.__generate_url()\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.download","title":"<code>download(format='pt', location='.')</code>","text":"<p>Download the weights associated with a model.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>The format of the output.         - 'pt': returns a PyTorch weights file</p> <code>'pt'</code> <code>location</code> <code>str</code> <p>The location to save the weights file to</p> <code>'.'</code> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def download(self, format=\"pt\", location=\".\"):\n\"\"\"\n    Download the weights associated with a model.\n\n    Args:\n        format (str): The format of the output.\n                    - 'pt': returns a PyTorch weights file\n        location (str): The location to save the weights file to\n    \"\"\"\n    supported_formats = [\"pt\"]\n    if format not in supported_formats:\n        raise Exception(\n            f\"Unsupported format {format}. Must be one of {supported_formats}\"\n        )\n\n    workspace, project, version = self.id.rsplit(\"/\")\n\n    # get pt url\n    pt_api_url = f\"{API_URL}/{workspace}/{project}/{self.version}/ptFile\"\n\n    r = requests.get(pt_api_url, params={\"api_key\": self.__api_key})\n\n    r.raise_for_status()\n\n    pt_weights_url = r.json()[\"weightsUrl\"]\n\n    def bar_progress(current, total, width=80):\n        progress_message = (\n            \"Downloading weights to \"\n            + location\n            + \"/weights.pt\"\n            + \": %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n        )\n        sys.stdout.write(\"\\r\" + progress_message)\n        sys.stdout.flush()\n\n    wget.download(pt_weights_url, out=location + \"/weights.pt\", bar=bar_progress)\n\n    return\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.load_model","title":"<code>load_model(name, version, local=None, classes=None, overlap=None, confidence=None, stroke=None, labels=None, format=None)</code>","text":"<p>Loads a Model from on a model endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The url-safe version of the dataset name</p> required <code>version</code> <code>str</code> <p>The version number identifying the version of your dataset.</p> required <code>local</code> <code>bool</code> <p>Whether the model is hosted locally or on Roboflow</p> <code>None</code> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def load_model(\n    self,\n    name,\n    version,\n    local=None,\n    classes=None,\n    overlap=None,\n    confidence=None,\n    stroke=None,\n    labels=None,\n    format=None,\n):\n\"\"\"\n    Loads a Model from on a model endpoint.\n\n    Args:\n        name (str): The url-safe version of the dataset name\n        version (str): The version number identifying the version of your dataset.\n        local (bool): Whether the model is hosted locally or on Roboflow\n    \"\"\"\n    # To load a model manually, they must specify a dataset slug\n    self.name = name\n    self.version = version\n    # Generate URL based on parameters\n    self.__generate_url(\n        local=local,\n        classes=classes,\n        overlap=overlap,\n        confidence=confidence,\n        stroke=stroke,\n        labels=labels,\n        format=format,\n    )\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.predict","title":"<code>predict(image_path, hosted=False, format=None, classes=None, overlap=30, confidence=40, stroke=1, labels=False)</code>","text":"<p>Infers detections based on image from specified model and image path.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to the image you'd like to perform prediction on</p> required <code>hosted</code> <code>bool</code> <p>whether the image you're providing is hosted on Roboflow</p> <code>False</code> <code>format</code> <code>str</code> <p>The format of the output.</p> <code>None</code> <p>Returns:</p> Type Description <p>PredictionGroup Object</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>model = project.version(\"1\").model</p> <p>prediction = model.predict(\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def predict(\n    self,\n    image_path,\n    hosted=False,\n    format=None,\n    classes=None,\n    overlap=30,\n    confidence=40,\n    stroke=1,\n    labels=False,\n):\n\"\"\"\n    Infers detections based on image from specified model and image path.\n\n    Args:\n        image_path (str): path to the image you'd like to perform prediction on\n        hosted (bool): whether the image you're providing is hosted on Roboflow\n        format (str): The format of the output.\n\n    Returns:\n        PredictionGroup Object\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; model = project.version(\"1\").model\n\n        &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n    \"\"\"\n    # Generate url before predicting\n    self.__generate_url(\n        format=format,\n        classes=classes,\n        overlap=overlap,\n        confidence=confidence,\n        stroke=stroke,\n        labels=labels,\n    )\n\n    # Check if image exists at specified path or URL or is an array\n    if hasattr(image_path, \"__len__\") == True:\n        pass\n    else:\n        self.__exception_check(image_path_check=image_path)\n\n    resize = False\n    # If image is local image\n    if not hosted:\n        if type(image_path) is str:\n            image = Image.open(image_path).convert(\"RGB\")\n            dimensions = image.size\n            original_dimensions = copy.deepcopy(dimensions)\n\n            # Here we resize the image to the preprocessing settings before sending it over the wire\n            if \"resize\" in self.preprocessing.keys():\n                if dimensions[0] &gt; int(\n                    self.preprocessing[\"resize\"][\"width\"]\n                ) or dimensions[1] &gt; int(self.preprocessing[\"resize\"][\"height\"]):\n                    image = image.resize(\n                        (\n                            int(self.preprocessing[\"resize\"][\"width\"]),\n                            int(self.preprocessing[\"resize\"][\"height\"]),\n                        )\n                    )\n                    dimensions = image.size\n                    resize = True\n\n            # Create buffer\n            buffered = io.BytesIO()\n            image.save(buffered, format=\"PNG\")\n            # Base64 encode image\n            img_str = base64.b64encode(buffered.getvalue())\n            img_str = img_str.decode(\"ascii\")\n            # Post to API and return response\n            resp = requests.post(\n                self.api_url,\n                data=img_str,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n\n            image_dims = {\n                \"width\": str(original_dimensions[0]),\n                \"height\": str(original_dimensions[1]),\n            }\n        elif isinstance(image_path, np.ndarray):\n            # Performing inference on a OpenCV2 frame\n            retval, buffer = cv2.imencode(\".jpg\", image_path)\n            # Currently cv2.imencode does not properly return shape\n            dimensions = buffer.shape\n            img_str = base64.b64encode(buffer)\n            img_str = img_str.decode(\"ascii\")\n            resp = requests.post(\n                self.api_url,\n                data=img_str,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n            # Replace with dimensions variable once cv2.imencode shape solution is found\n            image_dims = {\"width\": \"0\", \"height\": \"0\"}\n        else:\n            raise ValueError(\"image_path must be a string or a numpy array.\")\n    else:\n        # Create API URL for hosted image (slightly different)\n        self.api_url += \"&amp;image=\" + urllib.parse.quote_plus(image_path)\n        image_dims = {\"width\": \"0\", \"height\": \"0\"}\n        # POST to the API\n        resp = requests.post(self.api_url)\n\n    resp.raise_for_status()\n    # Return a prediction group if JSON data\n    if self.format == \"json\":\n        resp_json = resp.json()\n\n        if resize:\n            new_preds = []\n            for p in resp_json[\"predictions\"]:\n                p[\"x\"] = int(\n                    p[\"x\"]\n                    * (\n                        int(original_dimensions[0])\n                        / int(self.preprocessing[\"resize\"][\"width\"])\n                    )\n                )\n                p[\"y\"] = int(\n                    p[\"y\"]\n                    * (\n                        int(original_dimensions[1])\n                        / int(self.preprocessing[\"resize\"][\"height\"])\n                    )\n                )\n                p[\"width\"] = int(\n                    p[\"width\"]\n                    * (\n                        int(original_dimensions[0])\n                        / int(self.preprocessing[\"resize\"][\"width\"])\n                    )\n                )\n                p[\"height\"] = int(\n                    p[\"height\"]\n                    * (\n                        int(original_dimensions[1])\n                        / int(self.preprocessing[\"resize\"][\"height\"])\n                    )\n                )\n\n                new_preds.append(p)\n\n            resp_json[\"predictions\"] = new_preds\n\n        return PredictionGroup.create_prediction_group(\n            resp_json,\n            image_path=image_path,\n            prediction_type=OBJECT_DETECTION_MODEL,\n            image_dims=image_dims,\n            colors=self.colors,\n        )\n    # Returns base64 encoded Data\n    elif self.format == \"image\":\n        return resp.content\n</code></pre>"},{"location":"models/object-detection/#roboflow.models.object_detection.ObjectDetectionModel.webcam","title":"<code>webcam(webcam_id=0, inference_engine_url='https://detect.roboflow.com/', within_jupyter=False, confidence=40, overlap=30, stroke=1, labels=False, web_cam_res=(416, 416))</code>","text":"<p>Infers detections based on webcam feed from specified model.</p> <p>Parameters:</p> Name Type Description Default <code>webcam_id</code> <code>int</code> <p>Webcam ID (default 0)</p> <code>0</code> <code>inference_engine_url</code> <code>str</code> <p>Inference engine address to use (default https://detect.roboflow.com)</p> <code>'https://detect.roboflow.com/'</code> <code>within_jupyter</code> <code>bool</code> <p>Whether or not to display the webcam within Jupyter notebook (default True)</p> <code>False</code> <code>confidence</code> <code>int</code> <p>Confidence threshold for detections</p> <code>40</code> <code>overlap</code> <code>int</code> <p>Overlap threshold for detections</p> <code>30</code> <code>stroke</code> <code>int</code> <p>Stroke width for bounding box</p> <code>1</code> <code>labels</code> <code>bool</code> <p>Whether to show labels on bounding box</p> <code>False</code> Source code in <code>roboflow/models/object_detection.py</code> <pre><code>def webcam(\n    self,\n    webcam_id=0,\n    inference_engine_url=\"https://detect.roboflow.com/\",\n    within_jupyter=False,\n    confidence=40,\n    overlap=30,\n    stroke=1,\n    labels=False,\n    web_cam_res=(416, 416),\n):\n\"\"\"\n    Infers detections based on webcam feed from specified model.\n\n    Args:\n        webcam_id (int): Webcam ID (default 0)\n        inference_engine_url (str): Inference engine address to use (default https://detect.roboflow.com)\n        within_jupyter (bool): Whether or not to display the webcam within Jupyter notebook (default True)\n        confidence (int): Confidence threshold for detections\n        overlap (int): Overlap threshold for detections\n        stroke (int): Stroke width for bounding box\n        labels (bool): Whether to show labels on bounding box\n    \"\"\"\n\n    os.environ[\"OPENCV_VIDEOIO_PRIORITY_MSMF\"] = \"0\"\n\n    # Generate url before predicting\n    self.__generate_url(\n        confidence=confidence,\n        overlap=overlap,\n        stroke=stroke,\n        labels=labels,\n        inference_engine_url=inference_engine_url,\n    )\n\n    def plot_one_box(\n        x, img, color=None, label=None, line_thickness=None, colors=None\n    ):\n        # Plots one bounding box on image img\n\n        self.colors = {} if colors is None else colors\n\n        if label in colors.keys() and label is not None:\n            color = colors[label]\n            color = color.lstrip(\"#\")\n            color = tuple(int(color[i : i + 2], 16) for i in (0, 2, 4))\n        else:\n            color = [random.randint(0, 255) for _ in range(3)]\n\n        tl = (\n            line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1\n        )  # line/font thickness\n\n        c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n\n        cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n        if label:\n            tf = max(tl - 1, 1)  # font thickness\n            t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n            c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n            cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n            cv2.putText(\n                img,\n                label,\n                (c1[0], c1[1] - 2),\n                0,\n                tl / 3,\n                [225, 255, 255],\n                thickness=tf,\n                lineType=cv2.LINE_AA,\n            )\n\n    cap = cv2.VideoCapture(webcam_id)\n\n    if cap is None or not cap.isOpened():\n        raise (Exception(\"No webcam available at webcam_id \" + str(webcam_id)))\n\n    cap.set(cv2.CAP_PROP_FRAME_WIDTH, web_cam_res[0])\n    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, web_cam_res[1])\n\n    if within_jupyter:\n        os.environ[\"OPENCV_VIDEOIO_PRIORITY_MSMF\"] = \"0\"\n        print_warn_for_wrong_dependencies_versions([(\"IPython\", \"&gt;=\", \"7.0.0\")])\n        print_warn_for_wrong_dependencies_versions([(\"ipywidgets\", \"&gt;=\", \"7.0.0\")])\n\n        import threading\n\n        import ipywidgets as widgets\n        from IPython.display import Image as IPythonImage\n        from IPython.display import display\n\n        display_handle = display(\"loading Roboflow model...\", display_id=True)\n\n        # Stop button\n        # ================\n        stopButton = widgets.ToggleButton(\n            value=False,\n            description=\"Stop Inference\",\n            disabled=False,\n            button_style=\"danger\",  # 'success', 'info', 'warning', 'danger' or ''\n            tooltip=\"Description\",\n            icon=\"square\",  # (FontAwesome names without the `fa-` prefix)\n        )\n\n    else:\n        cv2.namedWindow(\"Roboflow Webcam Inference\", cv2.WINDOW_NORMAL)\n        cv2.startWindowThread()\n\n        stopButton = None\n\n    def view(button):\n        while True:\n            if stopButton is not None:\n                if stopButton.value == True:\n                    break\n            else:\n                if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):  # quit when 'q' is pressed\n                    break\n\n            _, frame = cap.read()\n            frame = cv2.resize(frame, web_cam_res)\n\n            frame = cv2.flip(frame, 1)  # if your camera reverses your image\n\n            _, frame_upload = cv2.imencode(\".jpeg\", frame)\n            img_str = base64.b64encode(frame_upload)\n            img_str = img_str.decode(\"ascii\")\n\n            # post frame to the Roboflow API\n            r = requests.post(\n                self.api_url,\n                data=img_str,\n                headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n            )\n\n            json = r.json()\n\n            predictions = json[\"predictions\"]\n\n            formatted_predictions = []\n            classes = []\n\n            for pred in predictions:\n                formatted_pred = [\n                    pred[\"x\"],\n                    pred[\"y\"],\n                    pred[\"x\"],\n                    pred[\"y\"],\n                    pred[\"confidence\"],\n                ]\n\n                # convert to top-left x/y from center\n                formatted_pred[0] = int(formatted_pred[0] - pred[\"width\"] / 2)\n                formatted_pred[1] = int(formatted_pred[1] - pred[\"height\"] / 2)\n                formatted_pred[2] = int(formatted_pred[2] + pred[\"width\"] / 2)\n                formatted_pred[3] = int(formatted_pred[3] + pred[\"height\"] / 2)\n\n                formatted_predictions.append(formatted_pred)\n                classes.append(pred[\"class\"])\n\n                plot_one_box(\n                    formatted_pred,\n                    frame,\n                    label=pred[\"class\"],\n                    line_thickness=2,\n                    colors=self.colors,\n                )\n\n            _, frame_display = cv2.imencode(\".jpeg\", frame)\n\n            if within_jupyter:\n                display_handle.update(IPythonImage(data=frame_display.tobytes()))\n            else:\n                cv2.imshow(\"Roboflow Webcam Inference\", frame)\n                if cv2.waitKey(1) &amp; 0xFF == ord(\"q\"):  # quit when 'q' is pressed\n                    cap.release()\n                    break\n\n        cap.release()\n        if not within_jupyter:\n            cv2.destroyWindow(\"Roboflow Webcam Inference\")\n            cv2.destroyAllWindows()\n            cv2.waitKey(1)\n\n        return\n\n    if within_jupyter:\n        display(stopButton)\n        thread = threading.Thread(target=view, args=(stopButton,))\n        thread.start()\n    else:\n        view(stopButton)\n</code></pre>"},{"location":"models/semantic-segmentation/","title":"Semantic Segmentation","text":""},{"location":"models/semantic-segmentation/#roboflow.models.semantic_segmentation.SemanticSegmentationModel","title":"<code>SemanticSegmentationModel</code>","text":"<p>             Bases: <code>InferenceModel</code></p> <p>Run inference on a semantic segmentation model hosted on Roboflow or served through Roboflow Inference.</p> Source code in <code>roboflow/models/semantic_segmentation.py</code> <pre><code>class SemanticSegmentationModel(InferenceModel):\n\"\"\"\n    Run inference on a semantic segmentation model hosted on Roboflow or served through Roboflow Inference.\n    \"\"\"\n\n    def __init__(self, api_key: str, version_id: str):\n\"\"\"\n        Create a SemanticSegmentationModel object through which you can run inference.\n\n        Args:\n            api_key (str): private roboflow api key\n            version_id (str): the workspace/project id\n        \"\"\"\n        super(SemanticSegmentationModel, self).__init__(api_key, version_id)\n        self.api_url = f\"{SEMANTIC_SEGMENTATION_URL}/{self.dataset_id}/{self.version}\"\n\n    def predict(self, image_path: str, confidence: int = 50):\n\"\"\"\n        Infers detections based on image from a specified model and image path.\n\n        Args:\n            image_path (str): path to the image you'd like to perform prediction on\n            confidence (int): confidence threshold for predictions, on a scale from 0-100\n\n        Returns:\n            PredictionGroup Object\n\n        Example:\n            &gt;&gt;&gt; import roboflow\n\n            &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n            &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n            &gt;&gt;&gt; model = project.version(\"1\").model\n\n            &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n        \"\"\"\n        return super(SemanticSegmentationModel, self).predict(\n            image_path,\n            confidence=confidence,\n            prediction_type=SEMANTIC_SEGMENTATION_MODEL,\n        )\n\n    def __str__(self):\n        return f\"&lt;{type(self).__name__} id={self.id}, api_url={self.api_url}&gt;\"\n</code></pre>"},{"location":"models/semantic-segmentation/#roboflow.models.semantic_segmentation.SemanticSegmentationModel.__init__","title":"<code>__init__(api_key, version_id)</code>","text":"<p>Create a SemanticSegmentationModel object through which you can run inference.</p> <p>Parameters:</p> Name Type Description Default <code>api_key</code> <code>str</code> <p>private roboflow api key</p> required <code>version_id</code> <code>str</code> <p>the workspace/project id</p> required Source code in <code>roboflow/models/semantic_segmentation.py</code> <pre><code>def __init__(self, api_key: str, version_id: str):\n\"\"\"\n    Create a SemanticSegmentationModel object through which you can run inference.\n\n    Args:\n        api_key (str): private roboflow api key\n        version_id (str): the workspace/project id\n    \"\"\"\n    super(SemanticSegmentationModel, self).__init__(api_key, version_id)\n    self.api_url = f\"{SEMANTIC_SEGMENTATION_URL}/{self.dataset_id}/{self.version}\"\n</code></pre>"},{"location":"models/semantic-segmentation/#roboflow.models.semantic_segmentation.SemanticSegmentationModel.predict","title":"<code>predict(image_path, confidence=50)</code>","text":"<p>Infers detections based on image from a specified model and image path.</p> <p>Parameters:</p> Name Type Description Default <code>image_path</code> <code>str</code> <p>path to the image you'd like to perform prediction on</p> required <code>confidence</code> <code>int</code> <p>confidence threshold for predictions, on a scale from 0-100</p> <code>50</code> <p>Returns:</p> Type Description <p>PredictionGroup Object</p> Example <p>import roboflow</p> <p>rf = roboflow.Roboflow(api_key=\"\")</p> <p>project = rf.workspace().project(\"PROJECT_ID\")</p> <p>model = project.version(\"1\").model</p> <p>prediction = model.predict(\"YOUR_IMAGE.jpg\")</p> Source code in <code>roboflow/models/semantic_segmentation.py</code> <pre><code>def predict(self, image_path: str, confidence: int = 50):\n\"\"\"\n    Infers detections based on image from a specified model and image path.\n\n    Args:\n        image_path (str): path to the image you'd like to perform prediction on\n        confidence (int): confidence threshold for predictions, on a scale from 0-100\n\n    Returns:\n        PredictionGroup Object\n\n    Example:\n        &gt;&gt;&gt; import roboflow\n\n        &gt;&gt;&gt; rf = roboflow.Roboflow(api_key=\"\")\n\n        &gt;&gt;&gt; project = rf.workspace().project(\"PROJECT_ID\")\n\n        &gt;&gt;&gt; model = project.version(\"1\").model\n\n        &gt;&gt;&gt; prediction = model.predict(\"YOUR_IMAGE.jpg\")\n    \"\"\"\n    return super(SemanticSegmentationModel, self).predict(\n        image_path,\n        confidence=confidence,\n        prediction_type=SEMANTIC_SEGMENTATION_MODEL,\n    )\n</code></pre>"}]}